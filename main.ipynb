{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义函数信道等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding:utf-8\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"  # 使用第二块GPU（从0开始）\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "import argparse\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from math import *\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator, FormatStrFormatter\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "C_dim = 64  # 语义编码的通道数\n",
    "n_class   = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NMSE(x_hat,x):\n",
    "    x = torch.reshape(x, (len(x), -1))\n",
    "    x_hat = torch.reshape(x_hat, (len(x_hat), -1))\n",
    "    \n",
    "    power = torch.sum(abs(x) ** 2, axis=1)\n",
    "    mse = torch.sum(abs(x - x_hat) ** 2, axis=1)\n",
    "    nmse = torch.mean(mse / power)\n",
    "    return nmse\n",
    "def Hermitian(X):#torch矩阵共轭转置\n",
    "    X = torch.real(X) - 1j*torch.imag(X)\n",
    "    return X.transpose(-1,-2)\n",
    "def kron(a,b):\n",
    "    #a与b维度为[batch,N],输出应为[batch,N*N]\n",
    "    batch = a.shape[0]\n",
    "    a = a.reshape(batch,-1,1)\n",
    "    b = b.reshape(batch,1,-1)\n",
    "    c = a @ b\n",
    "    return c.reshape(batch,-1) #输出的维度a在前，b在后\n",
    "def kron_add(a,b):\n",
    "    #a与b维度为[batch,N],输出应为[batch,N*N]\n",
    "    batch = a.shape[0]\n",
    "    a = a.reshape(batch,-1,1)\n",
    "    b = b.reshape(batch,1,-1)\n",
    "    c = a + b\n",
    "    return c.reshape(batch,-1) #输出的维度a在前，b在后\n",
    "\n",
    "def DFT_matrix(N):\n",
    "    n = torch.arange(N).reshape(N,1).cuda()\n",
    "    k = torch.arange(N).reshape(1,N).cuda()\n",
    "    W = torch.exp(-1j*2*pi*n*k/N)/sqrt(N)\n",
    "    return W\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc  = 28e9\n",
    "c = 3e8\n",
    "# v_max_km = 120  #120km/h\n",
    "\n",
    "def SV_Channel_set(batch,Nc,N,Nt,Nr,sigma_2_alpha,v_max_km):\n",
    "    #Nc代表载波数 N代表路径数 sigma_2_alph每条路径能量 sigma_angle角度均匀分布的幅度 Nt=[Nx,Ny]是UPA天线数,t表示\n",
    "    v_max = v_max_km*1000/3600\n",
    "    fd_max = fc*v_max/c\n",
    "\n",
    "    Tau = 10  #最大路径时延\n",
    "    tau = torch.rand(batch,1,N).cuda()*Tau\n",
    "    N_r = Nr[0]*Nr[1]\n",
    "    N_t = Nt[0]*Nt[1]\n",
    "    fait = torch.rand(batch,1,N).cuda()*2*pi\n",
    "    fair = torch.rand(batch,1,N).cuda()*2*pi\n",
    "    theatt = torch.rand(batch,1,N).cuda()*2*pi\n",
    "    theatr = torch.rand(batch,1,N).cuda()*2*pi\n",
    "    A_t = torch.zeros(batch,N_t,N).cuda() +0j\n",
    "    A_r = torch.zeros(batch,N_r,N).cuda() +0j\n",
    "    alpha = torch.zeros(batch,1,N).cuda() +0j\n",
    "    n_t1 = torch.arange(Nt[0]).reshape(1,Nt[0],1).cuda()\n",
    "    n_t2 = torch.arange(Nt[1]).reshape(1,Nt[1],1).cuda()\n",
    "    n_r1 = torch.arange(Nr[0]).reshape(1,Nr[0],1).cuda()\n",
    "    n_r2 = torch.arange(Nr[1]).reshape(1,Nr[1],1).cuda()\n",
    "    for i in range(N):\n",
    "        at1 = torch.exp(-2j*pi*0.5*n_t1*torch.cos(fait[:,:,i:(i+1)])*torch.sin(theatt[:,:,i:(i+1)]))\n",
    "        at2 = torch.exp(-2j*pi*0.5*n_t2*torch.sin(fait[:,:,i:(i+1)]))\n",
    "        A_t[:,:,i] = kron(at1,at2)\n",
    "\n",
    "        ar1 = torch.exp(-2j*pi*0.5*n_r1*torch.cos(fair[:,:,i:(i+1)])*torch.sin(theatr[:,:,i:(i+1)]))\n",
    "        ar2 = torch.exp(-2j*pi*0.5*n_r2*torch.sin(fair[:,:,i:(i+1)]))\n",
    "        A_r[:,:,i] = kron(ar1,ar2)\n",
    "\n",
    "        aa = (torch.randn(batch,1)+1j*torch.randn(batch,1))*sqrt(sigma_2_alpha/2)\n",
    "        # if i == 0:\n",
    "        #     aa = (torch.randn(batch,1)+1j*torch.randn(batch,1))*sqrt(sigma_2_alpha/2) \n",
    "        # else:\n",
    "        #     aa = (torch.randn(batch,1)+1j*torch.randn(batch,1))*sqrt(sigma_2_alpha/2)*0.1\n",
    "        alpha[:,:,i] = aa[:,:]\n",
    "\n",
    "    fd = fd_max * torch.rand(batch,N).cuda()\n",
    "    return alpha,A_r,A_t,fd,tau\n",
    "\n",
    "def SV_Channel_final(batch,Nc,N,Nt,Nr,sigma_2_alpha,t,alpha,A_r,A_t,fd,tau):\n",
    "    #Nc代表载波数 N代表路径数 sigma_2_alph每条路径能量 sigma_angle角度均匀分布的幅度 Nt=[Nx,Ny]是UPA天线数,t表示时间\n",
    "    d=0.5\n",
    "    #print(check)\n",
    "    \n",
    "\n",
    "    N_r = Nr[0]*Nr[1]\n",
    "    N_t = Nt[0]*Nt[1]\n",
    "    \n",
    "    H_f = torch.zeros(batch,Nc,N_r,N_t).cuda() +0j\n",
    "    alpha_dop = torch.zeros(batch,1,N).cuda() +0j\n",
    "    for i in range(N):\n",
    "        \n",
    "        \n",
    "        phi_d = torch.exp(-2j*pi*fd[:,i].reshape(batch,1)*t)\n",
    "        aa = alpha[:,:,i]*phi_d\n",
    "        # if i == 0:\n",
    "        #     aa = (torch.randn(batch,1)+1j*torch.randn(batch,1))*sqrt(sigma_2_alpha/2) \n",
    "        # else:\n",
    "        #     aa = (torch.randn(batch,1)+1j*torch.randn(batch,1))*sqrt(sigma_2_alpha/2)*0.1\n",
    "        alpha_dop[:,:,i] = aa[:,:]\n",
    "\n",
    "\n",
    "    for k in range(Nc):\n",
    "        P = alpha_dop*torch.exp(-1j*2*pi*tau*k/Nc)\n",
    "        P = torch.diag_embed(P).reshape(batch,N,N)\n",
    "        H_f[:,k,:,:] = torch.matmul(torch.matmul(A_r,P),Hermitian(A_t))\n",
    "        \n",
    "    return H_f   #【batch,Nc,N_r,N_t】N_r是基站接收天线，N_t是用户发送天先\n",
    "\n",
    "def calculate_average_channel_capacity(H, F, W, SNR_dB): # Pt代表总发射功率 snr代表总发射功率与每一根接收天线噪声功率之比\n",
    "    #H [batch,Nc,N_r,N_t]     F[batch,Nc,N_t,Ns]  W[batch,Nc,N_r_RF,N_r]\n",
    "    batch_size, Nc, N_r, N_t = H.shape\n",
    "    Ns = F.shape[-1]\n",
    "    N_r_RF = W.shape[2]\n",
    "\n",
    "    N0 = 1\n",
    "    Pt = 10**(SNR_dB/10)\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    norm_factor = torch.sqrt(torch.sum(torch.abs(F)**2, dim=(-2, -1), keepdim=True))\n",
    "    F = F / norm_factor * torch.sqrt(torch.tensor(Ns, dtype=H.dtype, device=H.device))\n",
    "\n",
    "    norm_factor = torch.sqrt(torch.sum(torch.abs(W)**2, dim=(-2, -1), keepdim=True))\n",
    "    W = W / norm_factor * torch.sqrt(torch.tensor(N_r_RF, dtype=H.dtype, device=H.device))\n",
    "    \n",
    "    # Calculate power per stream\n",
    "    P_per_stream = Pt / Ns\n",
    "    \n",
    "    # Calculate effective channel\n",
    "    H_eff = W @ H @ F  #H [batch,Nc,N_r_RF,Ns]\n",
    "    \n",
    "    # Calculate the identity matrix\n",
    "    identity_matrix = torch.eye(N_r_RF, dtype=H.dtype, device=H.device).expand(batch_size, Nc, N_r_RF, N_r_RF)\n",
    "    \n",
    "    # Calculate the covariance matrix\n",
    "    covariance_matrix = torch.matmul(H_eff, H_eff.conj().transpose(-1, -2))\n",
    "    \n",
    "    # Calculate the determinant part\n",
    "    det_part = torch.det(identity_matrix + (P_per_stream / N0) * covariance_matrix)\n",
    "    \n",
    "    # Calculate the capacity\n",
    "    capacity = torch.log2(det_part).real  #[b,Nc]\n",
    "    \n",
    "    # Calculate average capacity\n",
    "    average_capacity = capacity.mean(1) # b\n",
    "    \n",
    "    return average_capacity # b\n",
    "\n",
    "#这个函数计算T个时隙的平均谱效\n",
    "def calculate_average_channel_capacity_T(H, F, W, SNR_dB): # Pt代表总发射功率 snr代表总发射功率与每一根接收天线噪声功率之比\n",
    "    #H [batch,T, Nc,N_r,N_t]     F[batch,T, Nc,N_t,Ns]  W[batch,T, Nc,N_r_RF,N_r]\n",
    "    batch_size, T, Nc, N_r, N_t = H.shape\n",
    "    Ns = F.shape[-1]\n",
    "    N_r_RF = W.shape[-2]\n",
    "\n",
    "    N0 = 1\n",
    "    Pt = 10**(SNR_dB/10)\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    norm_factor = torch.sqrt(torch.sum(torch.abs(F)**2, dim=(-2, -1), keepdim=True))\n",
    "    F = F / norm_factor * torch.sqrt(torch.tensor(Ns, dtype=H.dtype, device=H.device))\n",
    "\n",
    "    norm_factor = torch.sqrt(torch.sum(torch.abs(W)**2, dim=(-2, -1), keepdim=True))\n",
    "    W = W / norm_factor * torch.sqrt(torch.tensor(N_r_RF, dtype=H.dtype, device=H.device))\n",
    "    \n",
    "    # Calculate power per stream\n",
    "    P_per_stream = Pt / Ns\n",
    "    \n",
    "    # Calculate effective channel\n",
    "    H_eff = W @ H @ F  #H [batch,T, Nc,N_r_RF,Ns]\n",
    "    \n",
    "    # Calculate the identity matrix\n",
    "    identity_matrix = torch.eye(N_r_RF, dtype=H.dtype, device=H.device).expand(batch_size, T, Nc, N_r_RF, N_r_RF)\n",
    "    \n",
    "    # Calculate the covariance matrix\n",
    "    covariance_matrix = torch.matmul(H_eff, H_eff.conj().transpose(-1, -2))\n",
    "    \n",
    "    # Calculate the determinant part\n",
    "    det_part = torch.det(identity_matrix + (P_per_stream / N0) * covariance_matrix)\n",
    "    \n",
    "    # Calculate the capacity\n",
    "    capacity = torch.log2(det_part).real  #[b,Nc]\n",
    "    \n",
    "    # Calculate average capacity\n",
    "    average_capacity = capacity.mean(1) # b\n",
    "    \n",
    "    return average_capacity # b\n",
    "\n",
    "def calculate_average_channel_capacity_OMA(H_1, H_2, F_1, F_2, W, SNR_dB): # Pt代表总发射功率 snr代表总发射功率与每一根接收天线噪声功率之比\n",
    "    #H [batch,Nc,N_r,N_t]     F[batch,Nc,N_t,1]  W[batch,Nc,N_r_RF,N_r]\n",
    "    batch_size, Nc, N_r, N_t = H_1.shape\n",
    "    Ns = F_1.shape[-1]\n",
    "    N_r_RF = W.shape[2]\n",
    "\n",
    "    N0 = 1\n",
    "    Pt = 10**(SNR_dB/10)\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    norm_factor = torch.sqrt(torch.sum(torch.abs(F_1)**2, dim=(-2, -1), keepdim=True))\n",
    "    F_1 = F_1 / norm_factor * torch.sqrt(torch.tensor(Ns, dtype=H_1.dtype, device=H_1.device))\n",
    "    norm_factor = torch.sqrt(torch.sum(torch.abs(F_2)**2, dim=(-2, -1), keepdim=True))\n",
    "    F_2 = F_2 / norm_factor * torch.sqrt(torch.tensor(Ns, dtype=H_1.dtype, device=H_1.device))\n",
    "\n",
    "\n",
    "\n",
    "    norm_factor = torch.sqrt(torch.sum(torch.abs(W)**2, dim=(-2, -1), keepdim=True))\n",
    "    W = W / norm_factor * torch.sqrt(torch.tensor(N_r_RF, dtype=H_1.dtype, device=H_1.device))\n",
    "    \n",
    "    # Calculate power per stream\n",
    "    P_per_stream = Pt / Ns\n",
    "    \n",
    "    # Calculate effective channel\n",
    "    W_1 = W[:,:,0:1,:] # [batch,Nc,1,N_r]\n",
    "    W_2 = W[:,:,1:2,:] # [batch,Nc,1,N_r]\n",
    "    H_eff_11 = W_1 @ H_1 @ F_1  #H [batch,Nc,1,1]\n",
    "    H_eff_12 = W_2 @ H_1 @ F_1  #H [batch,Nc,1,1]\n",
    "    H_eff_21 = W_1 @ H_2 @ F_2  #H [batch,Nc,1,1]\n",
    "    H_eff_22 = W_2 @ H_2 @ F_2  #H [batch,Nc,1,1]\n",
    "\n",
    "\n",
    "    signal_1 = (P_per_stream ) * H_eff_11 @ H_eff_11.mH\n",
    "    inter_1 = N0 + (P_per_stream ) * H_eff_21 @ H_eff_21.mH\n",
    "    capacity_1 = torch.log2(1 + signal_1/inter_1).real.mean(1)  #[b]\n",
    "\n",
    "    signal_2 = (P_per_stream ) * H_eff_22 @ H_eff_22.mH\n",
    "    inter_2 = N0 + (P_per_stream ) * H_eff_12 @ H_eff_12.mH\n",
    "    capacity_2 = torch.log2(1 + signal_2/inter_2).real.mean(1)  #[b]\n",
    "    \n",
    "    \n",
    "    \n",
    "    return torch.min(capacity_1,capacity_2).mean() \n",
    "\n",
    "\n",
    "def calculate_average_channel_capacity_OMA_woInt(H_1, H_2, F_1, F_2, W, SNR_dB): # Pt代表总发射功率 snr代表总发射功率与每一根接收天线噪声功率之比\n",
    "    #H [batch,Nc,N_r,N_t]     F[batch,Nc,N_t,1]  W[batch,Nc,N_r_RF,N_r]\n",
    "    batch_size, Nc, N_r, N_t = H_1.shape\n",
    "    Ns = F_1.shape[-1]\n",
    "    N_r_RF = W.shape[2]\n",
    "\n",
    "    N0 = 1\n",
    "    Pt = 10**(SNR_dB/10)\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    norm_factor = torch.sqrt(torch.sum(torch.abs(F_1)**2, dim=(-2, -1), keepdim=True))\n",
    "    F_1 = F_1 / norm_factor * torch.sqrt(torch.tensor(Ns, dtype=H_1.dtype, device=H_1.device))\n",
    "    norm_factor = torch.sqrt(torch.sum(torch.abs(F_2)**2, dim=(-2, -1), keepdim=True))\n",
    "    F_2 = F_2 / norm_factor * torch.sqrt(torch.tensor(Ns, dtype=H_1.dtype, device=H_1.device))\n",
    "\n",
    "\n",
    "\n",
    "    norm_factor = torch.sqrt(torch.sum(torch.abs(W)**2, dim=(-2, -1), keepdim=True))\n",
    "    W = W / norm_factor * torch.sqrt(torch.tensor(N_r_RF, dtype=H_1.dtype, device=H_1.device))\n",
    "    \n",
    "    # Calculate power per stream\n",
    "    P_per_stream = Pt / Ns\n",
    "    \n",
    "    # Calculate effective channel\n",
    "    W_1 = W[:,:,0:1,:] # [batch,Nc,1,N_r]\n",
    "    W_2 = W[:,:,1:2,:] # [batch,Nc,1,N_r]\n",
    "    H_eff_11 = W_1 @ H_1 @ F_1  #H [batch,Nc,1,1]\n",
    "    # H_eff_12 = W_2 @ H_1 @ F_1  #H [batch,Nc,1,1]\n",
    "    # H_eff_21 = W_1 @ H_2 @ F_2  #H [batch,Nc,1,1]\n",
    "    H_eff_22 = W_2 @ H_2 @ F_2  #H [batch,Nc,1,1]\n",
    "\n",
    "\n",
    "    signal_1 = (P_per_stream ) * H_eff_11 @ H_eff_11.mH\n",
    "    inter_1 = N0\n",
    "    capacity_1 = torch.log2(1 + signal_1/inter_1).real.mean(1)  #[b]\n",
    "\n",
    "    signal_2 = (P_per_stream ) * H_eff_22 @ H_eff_22.mH\n",
    "    inter_2 = N0\n",
    "    capacity_2 = torch.log2(1 + signal_2/inter_2).real.mean(1)  #[b]\n",
    "    \n",
    "    \n",
    "    \n",
    "    return torch.min(capacity_1,capacity_2).mean() \n",
    "\n",
    "def save_images(tensor, fpath_out):\n",
    "    \"\"\"\n",
    "    保存4通道张量为RGB图像和灰度图像\n",
    "    \n",
    "    参数:\n",
    "        tensor: PyTorch张量, shape [b, 4, H, W]\n",
    "        fpath_out: 包含b个输出路径的列表, 每个以'.png'结尾\n",
    "    \"\"\"\n",
    "    # 确保输入张量在CPU上\n",
    "    tensor = tensor.cpu()\n",
    "    \n",
    "    # 检查输入是否有效\n",
    "    assert tensor.size(1) == 4, \"输入张量必须有4个通道\"\n",
    "    assert len(fpath_out) == tensor.size(0), \"路径数量必须与批次大小匹配\"\n",
    "    \n",
    "    for i in range(tensor.size(0)):\n",
    "        # 获取当前图像的路径\n",
    "        original_path = fpath_out[i]\n",
    "        \n",
    "        # 检查路径是否以.png结尾\n",
    "        assert original_path.endswith('.png'), \"路径必须以'.png'结尾\"\n",
    "        \n",
    "        # 创建RGB路径(在.png前插入'_rgb')\n",
    "        base, ext = os.path.splitext(original_path)\n",
    "        rgb_path = f\"{base}_rgb{ext}\"\n",
    "        \n",
    "        # 创建灰度路径(在.png前插入'_inf')\n",
    "        inf_path = f\"{base}_inf{ext}\"\n",
    "        \n",
    "        # 获取当前图像的4个通道 [4, H, W]\n",
    "        img_data = tensor[i]\n",
    "        \n",
    "        # 保存RGB图像(前3个通道)\n",
    "        rgb_img = img_data[:3]  # [3, H, W]\n",
    "        rgb_img = (rgb_img.permute(1, 2, 0).numpy() * 255).astype('uint8')  # 转换为HWC numpy数组\n",
    "        rgb_pil = Image.fromarray(rgb_img)\n",
    "        rgb_pil.save(rgb_path)\n",
    "        \n",
    "        # 保存灰度图像(第4个通道)\n",
    "        inf_img = img_data[3]  # [H, W]\n",
    "        inf_img = (inf_img.numpy() * 255).astype('uint8')  # 转换为numpy数组\n",
    "        inf_pil = Image.fromarray(inf_img, mode='L')  # 'L'表示灰度模式\n",
    "        inf_pil.save(inf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#==================================================================================#\n",
    "# quant\n",
    "#==================================================================================#\n",
    "#=======================================================================================================================\n",
    "#=======================================================================================================================\n",
    "# Number to Bit Function Defining\n",
    "def Num2Bit(Num, B):\n",
    "    Num_ = Num.type(torch.uint8)\n",
    "    def integer2bit(integer, num_bits=B):\n",
    "        dtype = integer.type()\n",
    "        device = integer.device;\n",
    "        exponent_bits = -torch.arange(1-B, 1).type(dtype).to(device);\n",
    "        exponent_bits = exponent_bits.repeat(integer.shape + (1,))\n",
    "        out = integer.unsqueeze(-1) // 2 ** exponent_bits\n",
    "        return out% 2\n",
    "    bit = integer2bit(Num_)\n",
    "    bit = bit.reshape(-1, Num_.shape[1] * B)\n",
    "    return bit.type(torch.float32)\n",
    "def Bit2Num(Bit, B):\n",
    "    device=Bit.device;\n",
    "    Bit_ = Bit.type(torch.float32)\n",
    "    Bit_ = torch.reshape(Bit_, [-1, int(Bit_.shape[1] / B), B])\n",
    "    num = torch.zeros(Bit_[:, :, 0].shape).to(device)\n",
    "    for i in range(B):\n",
    "        num = num + Bit_[:, :, i] * 2 ** (B - 1 - i)\n",
    "    return num\n",
    "#=======================================================================================================================\n",
    "#=======================================================================================================================\n",
    "# Quantization and Dequantization Layers Defining\n",
    "class Quantization(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, x, B):\n",
    "        ctx.constant = B\n",
    "        step = 2**B-1e-6;\n",
    "        out = torch.round(x*step-0.5);\n",
    "        out = Num2Bit(out, B)\n",
    "        return out.type(x.type())\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        # return as many input gradients as there were arguments.\n",
    "        # Gradients of constant arguments to forward must be None.\n",
    "        # Gradient of a number is the sum of its B bits.\n",
    "        b, _ = grad_output.shape\n",
    "        grad_num = torch.sum(grad_output.reshape(b, -1, ctx.constant), dim=2) / ctx.constant\n",
    "        return grad_num, None\n",
    "class Dequantization(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, x, B):\n",
    "        ctx.constant = B\n",
    "        step = 2**B;\n",
    "        out = Bit2Num(x, B)\n",
    "        out = (out+0.5)/step;\n",
    "        return out.type(x.type())\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        # return as many input gradients as there were arguments.\n",
    "        # Gradients of non-Tensor arguments to forward must be None.\n",
    "        # repeat the gradient of a Num for B time.\n",
    "        b, c = grad_output.shape\n",
    "        grad_output = grad_output.unsqueeze(2) / ctx.constant\n",
    "        grad_bit = grad_output.expand(b, c, ctx.constant)\n",
    "        return torch.reshape(grad_bit, (-1, c * ctx.constant)), None\n",
    "class QuantizationLayer(nn.Module):\n",
    "    def __init__(self, B):\n",
    "        super(QuantizationLayer, self).__init__()\n",
    "        self.B = B\n",
    "    def forward(self, x):\n",
    "        out = Quantization.apply(x, self.B)\n",
    "        return out\n",
    "class DequantizationLayer(nn.Module):\n",
    "    def __init__(self, B):\n",
    "        super(DequantizationLayer, self).__init__()\n",
    "        self.B = B\n",
    "    def forward(self, x):\n",
    "        out = Dequantization.apply(x, self.B)\n",
    "        return out\n",
    "\n",
    "\n",
    "#==================================================================================#\n",
    "# utils\n",
    "#==================================================================================#\n",
    "class TransposeLayer(nn.Module):\n",
    "    def __init__(\n",
    "            self, \n",
    "            i, \n",
    "            j, \n",
    "        ):\n",
    "        super().__init__();\n",
    "        self.i=i;\n",
    "        self.j=j;\n",
    "\n",
    "    def forward(\n",
    "            self, \n",
    "            x, \n",
    "        ):\n",
    "        return x.transpose(self.i, self.j);\n",
    "\n",
    "\n",
    "\n",
    "class MergeLayer(nn.Module):\n",
    "    def __init__(\n",
    "            self, \n",
    "            i, \n",
    "        ):\n",
    "        super().__init__();\n",
    "        self.i=i;\n",
    "\n",
    "    def forward(\n",
    "            self, \n",
    "            x, \n",
    "        ):\n",
    "        assert self.i!=-1;\n",
    "        assert self.i!=x.shape[-1];\n",
    "        if self.i!=-2:\n",
    "            return x.reshape(*x.shape[:self.i], -1, *x.shape[self.i+2:]);\n",
    "        else:\n",
    "            return x.reshape(*x.shape[:self.i], -1);\n",
    "\n",
    "\n",
    "\n",
    "class SplitLayer(nn.Module):\n",
    "    def __init__(\n",
    "            self, \n",
    "            i, \n",
    "            n1=None, \n",
    "            n2=None, \n",
    "        ):\n",
    "        super().__init__();\n",
    "        assert (n1 is not None and n2 is None) or (n1 is None and n2 is not None);\n",
    "        self.i=i;\n",
    "        self.n1=n1;\n",
    "        self.n2=n2;\n",
    "\n",
    "    def forward(\n",
    "            self, \n",
    "            x, \n",
    "        ):\n",
    "        if self.i!=-1:\n",
    "            if self.n2 is None:\n",
    "                return x.reshape(*x.shape[:self.i], self.n1, -1, *x.shape[self.i+1:]);\n",
    "            else:\n",
    "                return x.reshape(*x.shape[:self.i], -1, self.n2, *x.shape[self.i+1:]);\n",
    "        else:\n",
    "            if self.n2 is None:\n",
    "                return x.reshape(*x.shape[:self.i], self.n1, -1);\n",
    "            else:\n",
    "                return x.reshape(*x.shape[:self.i], -1, self.n2);\n",
    "\n",
    "\n",
    "\n",
    "class PermuteLayer(nn.Module):\n",
    "    def __init__(\n",
    "            self, \n",
    "            permute_order, \n",
    "        ):\n",
    "        super().__init__();\n",
    "        self.permute_order=permute_order;\n",
    "    \n",
    "    def forward(\n",
    "            self, \n",
    "            x, \n",
    "        ):\n",
    "        return x.permute(self.permute_order);\n",
    "\n",
    "\n",
    "\n",
    "class ReshapeLayer(nn.Module):\n",
    "    def __init__(\n",
    "            self, \n",
    "            shape, \n",
    "        ):\n",
    "        super().__init__();\n",
    "        self.shape=shape;\n",
    "    \n",
    "    def forward(\n",
    "            self, \n",
    "            x, \n",
    "        ):\n",
    "        return x.reshape(self.shape);\n",
    "\n",
    "\n",
    "\n",
    "class NormLayer(nn.Module):\n",
    "    def __init__(\n",
    "            self, \n",
    "            d, \n",
    "            c_index=-1, \n",
    "        ):\n",
    "        super().__init__();\n",
    "        self.norm=nn.Sequential(\n",
    "            TransposeLayer(c_index, -1), \n",
    "            nn.LayerNorm(d), \n",
    "            TransposeLayer(c_index, -1), \n",
    "        );\n",
    "    \n",
    "    def forward(\n",
    "            self, \n",
    "            x, \n",
    "        ):\n",
    "        return self.norm(x);\n",
    "\n",
    "\n",
    "\n",
    "class Residual(nn.Module):\n",
    "    def __init__(\n",
    "            self, \n",
    "            func, \n",
    "        ):\n",
    "        super().__init__();\n",
    "        self.func=func;\n",
    "    \n",
    "    def forward(\n",
    "            self, \n",
    "            x, \n",
    "        ):\n",
    "        return self.func(x)+x;\n",
    "\n",
    "\n",
    "#==================================================================================#\n",
    "# Gated Mlp Block\n",
    "#==================================================================================#\n",
    "class SpatialGatingUnit(nn.Module):\n",
    "    def __init__(\n",
    "            self, \n",
    "            n, \n",
    "            d, \n",
    "            head, \n",
    "        ):\n",
    "        super().__init__();\n",
    "        dim_out=d//2;\n",
    "        self.head=head;\n",
    "\n",
    "        self.norm=nn.LayerNorm(dim_out);\n",
    "        #self.proj=nn.Conv1d(n, n, 1);\n",
    "        self.proj_w=nn.Parameter(torch.Tensor(head, n, n));\n",
    "        self.proj_b=nn.Parameter(torch.Tensor(head, n, 1));\n",
    "        \n",
    "        self.reset_parameters();\n",
    "    \n",
    "    def reset_parameters(self):\n",
    "        nn.init.normal_(self.proj_w, mean=0, std=1e-2);\n",
    "        nn.init.ones_(self.proj_b);\n",
    "    \n",
    "    def forward(\n",
    "            self, \n",
    "            x, \n",
    "        ):\n",
    "        b, n, _=x.shape;\n",
    "\n",
    "        res, gate=x.chunk(2, dim=-1);\n",
    "        gate=self.norm(gate);\n",
    "        res=res.reshape(b, n, self.head, -1).transpose(1, 2);\n",
    "        gate=gate.reshape(b, n, self.head, -1).transpose(1, 2);\n",
    "        gate=self.proj_w@gate+self.proj_b;\n",
    "        x=(gate*res).transpose(1, 2).reshape(b, n, -1);\n",
    "        return x;\n",
    "\n",
    "\n",
    "\n",
    "class Channel_Attention(nn.Module):\n",
    "    def __init__(self, n_embd, dim_ffn):\n",
    "        super().__init__()\n",
    "        self.n_embd = n_embd\n",
    "        self.dim_ffn = dim_ffn\n",
    "\n",
    "        self.key = nn.Linear(self.n_embd, self.dim_ffn)\n",
    "        self.receptance = nn.Linear(self.n_embd, self.n_embd)\n",
    "        self.value = nn.Linear(self.dim_ffn, self.n_embd)\n",
    "\n",
    "        self.norm = nn.LayerNorm(n_embd)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        \n",
    "        x_ini = x+0\n",
    "        x = self.norm(x)\n",
    "        k = self.key(x)\n",
    "        k = torch.relu(k) ** 2\n",
    "        kv = self.value(k)\n",
    "        return torch.sigmoid(self.receptance(x)) * kv + x_ini\n",
    "\n",
    "\n",
    "\n",
    "class GMlpBlock(nn.Module):\n",
    "    def __init__(\n",
    "            self, \n",
    "            n, \n",
    "            d, \n",
    "            d_hidden, \n",
    "            dropout=0., \n",
    "        ):\n",
    "        super().__init__();\n",
    "        self.proj_in=nn.Sequential(\n",
    "            nn.LayerNorm(d), \n",
    "            nn.Linear(d, d_hidden), \n",
    "            nn.GELU(), \n",
    "        );\n",
    "        self.sgu=SpatialGatingUnit(n, d_hidden, head=1);\n",
    "        self.proj_out=nn.Sequential(\n",
    "            nn.Linear(d_hidden//2, d), \n",
    "            nn.Dropout(dropout), \n",
    "        );\n",
    "\n",
    "    def forward(\n",
    "            self, \n",
    "            x, \n",
    "        ):\n",
    "        shortcut=x;\n",
    "        x=self.proj_in(x);\n",
    "        x=self.sgu(x);\n",
    "        x=self.proj_out(x);\n",
    "        x=x+shortcut;\n",
    "        return x;\n",
    "\n",
    "\n",
    "\n",
    "class MAXIMBlock(nn.Module):\n",
    "    def __init__(\n",
    "            self, \n",
    "            n1, \n",
    "            n2, \n",
    "            d, \n",
    "            d_hidden, \n",
    "            dropout=0., \n",
    "        ):\n",
    "        super().__init__();\n",
    "        self.proj_in=nn.Sequential(\n",
    "            nn.LayerNorm(d), \n",
    "            nn.Linear(d, 2*d), \n",
    "            nn.GELU(), \n",
    "        );\n",
    "        self.gmlp1=GMlpBlock(\n",
    "            n=n2, \n",
    "            d=d, \n",
    "            d_hidden=d_hidden, \n",
    "            dropout=dropout, \n",
    "        );\n",
    "        self.gmlp2=GMlpBlock(\n",
    "            n=n1, \n",
    "            d=d, \n",
    "            d_hidden=d_hidden, \n",
    "            dropout=dropout, \n",
    "        );\n",
    "        self.proj_out=nn.Sequential(\n",
    "            nn.Linear(2*d, d), \n",
    "            nn.Dropout(dropout), \n",
    "        );\n",
    "        self.CA=Channel_Attention(\n",
    "            n_embd=d, \n",
    "            dim_ffn=d_hidden, \n",
    "        );\n",
    "\n",
    "    def forward(\n",
    "            self, \n",
    "            x, \n",
    "        ):\n",
    "        b, n1, n2, d=x.shape;\n",
    "\n",
    "        shortcut=x;\n",
    "\n",
    "        x=self.proj_in(x);  # b, n1, n2, 2*d\n",
    "        u, v=x.chunk(2, dim=-1);  # b, n1, n2, d\n",
    "\n",
    "        u=u.reshape(b*n1, n2, d);\n",
    "        u=self.gmlp1(u);\n",
    "        u=u.reshape(b, n1, n2, d);\n",
    "\n",
    "        v=v.transpose(1, 2).reshape(b*n2, n1, d);\n",
    "        v=self.gmlp2(v);\n",
    "        v=v.reshape(b, n2, n1, d).transpose(1, 2);\n",
    "        \n",
    "        x=torch.cat((u, v), dim=-1);  # b, n1, n2, 2*d\n",
    "        x=self.proj_out(x);\n",
    "\n",
    "        x=x+shortcut;\n",
    "        \n",
    "        x=self.CA(x);\n",
    "\n",
    "        return x;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 提出的E2E非正交"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 阶段0：预训练语义提取与融合"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 预训练1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "维度为C_dim乘30乘40，其中30作为子载波数，C_dim之后经过语义融合输出维度可以自定义到C_out，那么Q的数量为C_out/2/N_rf*40，我们可以考虑多射频传输多个流，所以要除以射频数再除以实虚部2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBnLeakyRelu2d(nn.Module):\n",
    "    # convolution\n",
    "    # batch normalization\n",
    "    # leaky relu\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, padding=1, stride=1, dilation=1, groups=1):\n",
    "        super(ConvBnLeakyRelu2d, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, padding=padding, stride=stride, dilation=dilation, groups=groups)\n",
    "        self.bn   = nn.BatchNorm2d(out_channels)\n",
    "    def forward(self, x):\n",
    "        return F.leaky_relu(self.bn(self.conv(x)), negative_slope=0.2)\n",
    "\n",
    "\n",
    "class MiniInception(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(MiniInception, self).__init__()\n",
    "        self.conv1_left  = ConvBnLeakyRelu2d(in_channels,   out_channels//2)\n",
    "        self.conv1_right = ConvBnLeakyRelu2d(in_channels,   out_channels//2, padding=2, dilation=2)\n",
    "        self.conv2_left  = ConvBnLeakyRelu2d(out_channels,  out_channels//2)\n",
    "        self.conv2_right = ConvBnLeakyRelu2d(out_channels,  out_channels//2, padding=2, dilation=2)\n",
    "        self.conv3_left  = ConvBnLeakyRelu2d(out_channels,  out_channels//2)\n",
    "        self.conv3_right = ConvBnLeakyRelu2d(out_channels,  out_channels//2, padding=2, dilation=2)\n",
    "    def forward(self,x):\n",
    "        x = torch.cat((self.conv1_left(x), self.conv1_right(x)), dim=1)\n",
    "        x = torch.cat((self.conv2_left(x), self.conv2_right(x)), dim=1)\n",
    "        x = torch.cat((self.conv3_left(x), self.conv3_right(x)), dim=1)\n",
    "        return x\n",
    "\n",
    "\n",
    "class MFNet_Enc_rgb(nn.Module):\n",
    "\n",
    "    def __init__(self, ):\n",
    "        super(MFNet_Enc_rgb, self).__init__()\n",
    "        rgb_ch = [16,48,48,96,192]\n",
    "        # self.pho = 2\n",
    "        # inf_ch = [16,48,48,96,96]\n",
    "        # 压缩后的每个样本维度为[2，30，40]我们正好可以设置为单流2个实虚部组成的2、30个子载波和40个OFDM符号\n",
    "        compress_ch = [192,96,96,C_dim]\n",
    "        self.compress_ch = compress_ch\n",
    "        out_dim = 2400\n",
    "\n",
    "        self.conv1_rgb   = ConvBnLeakyRelu2d(3, rgb_ch[0])\n",
    "        self.conv2_1_rgb = ConvBnLeakyRelu2d(rgb_ch[0], rgb_ch[1])\n",
    "        self.conv2_2_rgb = ConvBnLeakyRelu2d(rgb_ch[1], rgb_ch[1])\n",
    "        self.conv3_1_rgb = ConvBnLeakyRelu2d(rgb_ch[1], rgb_ch[2])\n",
    "        self.conv3_2_rgb = ConvBnLeakyRelu2d(rgb_ch[2], rgb_ch[2])\n",
    "        self.conv4_rgb   = MiniInception(rgb_ch[2], rgb_ch[3])\n",
    "        self.conv5_rgb   = MiniInception(rgb_ch[3], rgb_ch[4])\n",
    "        self.compress_1_rgb = ConvBnLeakyRelu2d(compress_ch[0], compress_ch[1])\n",
    "        self.compress_2_rgb = ConvBnLeakyRelu2d(compress_ch[1], compress_ch[2])\n",
    "        self.compress_3_rgb = ConvBnLeakyRelu2d(compress_ch[2], compress_ch[3])\n",
    "    def forward(self, x):\n",
    "        # split data into RGB and INF\n",
    "        x_rgb = x[:,:3]\n",
    "\n",
    "        # encode\n",
    "        x_rgb    = self.conv1_rgb(x_rgb)\n",
    "        x_rgb    = F.max_pool2d(x_rgb, kernel_size=2, stride=2) # pool1\n",
    "        x_rgb    = self.conv2_1_rgb(x_rgb)\n",
    "        x_rgb_p2 = self.conv2_2_rgb(x_rgb)\n",
    "        x_rgb    = F.max_pool2d(x_rgb_p2, kernel_size=2, stride=2) # pool2\n",
    "        x_rgb    = self.conv3_1_rgb(x_rgb)\n",
    "        x_rgb_p3 = self.conv3_2_rgb(x_rgb)\n",
    "        x_rgb    = F.max_pool2d(x_rgb_p3, kernel_size=2, stride=2) # pool3\n",
    "        x_rgb_p4 = self.conv4_rgb(x_rgb)\n",
    "        x_rgb    = F.max_pool2d(x_rgb_p4, kernel_size=2, stride=2) # pool4 #[batch,2,30,40]\n",
    "        x_rgb    = self.conv5_rgb(x_rgb)  #[batch,96,30,40]\n",
    "        x_rgb    = F.max_pool2d(x_rgb, kernel_size=(3,4), stride=(3,4)) # pool5  \n",
    "\n",
    "        x_rgb    = self.compress_1_rgb(x_rgb)  \n",
    "        x_rgb    = self.compress_2_rgb(x_rgb)\n",
    "        x_rgb    = self.compress_3_rgb(x_rgb) #[batch,C_dim,10,10]\n",
    "        return x_rgb\n",
    "\n",
    "\n",
    "class MFNet_Enc_inf(nn.Module):\n",
    "\n",
    "    def __init__(self, ):\n",
    "        super(MFNet_Enc_inf, self).__init__()\n",
    "        rgb_ch = [16,48,48,96,192]\n",
    "        # self.pho = 2\n",
    "        # inf_ch = [16,48,48,96,96]\n",
    "        # 压缩后的每个样本维度为[2，30，40]我们正好可以设置为单流2个实虚部组成的2、30个子载波和40个OFDM符号\n",
    "        compress_ch = [192,96,96,C_dim]\n",
    "        self.compress_ch = compress_ch\n",
    "        out_dim = 2400\n",
    "\n",
    "        self.conv1_inf   = ConvBnLeakyRelu2d(1, rgb_ch[0])\n",
    "        self.conv2_1_inf = ConvBnLeakyRelu2d(rgb_ch[0], rgb_ch[1])\n",
    "        self.conv2_2_inf = ConvBnLeakyRelu2d(rgb_ch[1], rgb_ch[1])\n",
    "        self.conv3_1_inf = ConvBnLeakyRelu2d(rgb_ch[1], rgb_ch[2])\n",
    "        self.conv3_2_inf = ConvBnLeakyRelu2d(rgb_ch[2], rgb_ch[2])\n",
    "        self.conv4_inf   = MiniInception(rgb_ch[2], rgb_ch[3])\n",
    "        self.conv5_inf   = MiniInception(rgb_ch[3], rgb_ch[4])\n",
    "        self.compress_1_inf = ConvBnLeakyRelu2d(compress_ch[0], compress_ch[1])\n",
    "        self.compress_2_inf = ConvBnLeakyRelu2d(compress_ch[1], compress_ch[2])\n",
    "        self.compress_3_inf = ConvBnLeakyRelu2d(compress_ch[2], compress_ch[3])\n",
    "    def forward(self, x):\n",
    "        # split data into RGB and INF\n",
    "        x_inf = x[:,3:]\n",
    "\n",
    "        # encode\n",
    "        x_inf    = self.conv1_inf(x_inf)\n",
    "        x_inf    = F.max_pool2d(x_inf, kernel_size=2, stride=2) # pool1\n",
    "        x_inf    = self.conv2_1_inf(x_inf)\n",
    "        x_inf_p2 = self.conv2_2_inf(x_inf)\n",
    "        x_inf    = F.max_pool2d(x_inf_p2, kernel_size=2, stride=2) # pool2\n",
    "        x_inf    = self.conv3_1_inf(x_inf)\n",
    "        x_inf_p3 = self.conv3_2_inf(x_inf)\n",
    "        x_inf    = F.max_pool2d(x_inf_p3, kernel_size=2, stride=2) # pool3\n",
    "        x_inf_p4 = self.conv4_inf(x_inf)\n",
    "        x_inf    = F.max_pool2d(x_inf_p4, kernel_size=2, stride=2) # pool4 #[batch,96,30,40]\n",
    "        x_inf    = self.conv5_inf(x_inf)\n",
    "        x_inf    = F.max_pool2d(x_inf, kernel_size=(3,4), stride=(3,4)) # pool5  \n",
    "\n",
    "        x_inf    = self.compress_1_inf(x_inf)  \n",
    "        x_inf    = self.compress_2_inf(x_inf)  \n",
    "        x_inf    = self.compress_3_inf(x_inf)    #[batch,C_dim,10,10]\n",
    "        return x_inf\n",
    "\n",
    "class MFNet_Dec(nn.Module):\n",
    "\n",
    "    def __init__(self, n_class):\n",
    "        super(MFNet_Dec, self).__init__()\n",
    "        rgb_ch = [16,48,48,96,192]\n",
    "        # self.pho = 2\n",
    "        # inf_ch = [16,48,48,96,96]\n",
    "        # 压缩后的每个样本维度为 #[C_dim,10,10]我们keyi\n",
    "        compress_ch = [192,96,96,C_dim]\n",
    "        self.compress_ch = compress_ch\n",
    "        out_dim = 2400\n",
    "\n",
    "        self.decompress_3 = ConvBnLeakyRelu2d(compress_ch[3], compress_ch[2])\n",
    "        self.decompress_2 = ConvBnLeakyRelu2d(compress_ch[2], compress_ch[1])\n",
    "        self.decompress_1 = ConvBnLeakyRelu2d(compress_ch[1], compress_ch[0])\n",
    "\n",
    "\n",
    "        self.decode5     = ConvBnLeakyRelu2d(rgb_ch[4], rgb_ch[3])\n",
    "        self.decode4     = ConvBnLeakyRelu2d(rgb_ch[3], rgb_ch[2])\n",
    "        self.decode3     = ConvBnLeakyRelu2d(rgb_ch[2], rgb_ch[1])\n",
    "        self.decode2     = ConvBnLeakyRelu2d(rgb_ch[1], rgb_ch[0])\n",
    "        self.decode1     = ConvBnLeakyRelu2d(rgb_ch[0], n_class)\n",
    "    def forward(self, x):\n",
    "        #[batch,8,30,40]\n",
    "        # x = self.decompress_4(x)\n",
    "        # x = x.reshape(-1,8,self.pho,15,20).permute(0,2,1,3,4)\n",
    "        # x = x.reshape(-1,self.pho*8,15,20)\n",
    "        # x = self.decompress_4(x.permute(0,1,3,2)).permute(0,1,3,2)\n",
    "        x = self.decompress_3(x)\n",
    "        x = self.decompress_2(x)\n",
    "        x = self.decompress_1(x) #[batch,96,30,40]\n",
    "\n",
    "        # decode\n",
    "        x = F.interpolate(x, scale_factor=(3,4), mode='nearest')# unpool5\n",
    "        x = self.decode5(x)\n",
    "        x = F.upsample(x, scale_factor=2, mode='nearest') # unpool4\n",
    "        x = self.decode4(x)\n",
    "        x = F.upsample(x, scale_factor=2, mode='nearest') # unpool3\n",
    "        x = self.decode3(x)\n",
    "        x = F.upsample(x, scale_factor=2, mode='nearest') # unpool2\n",
    "        x = self.decode2(x)\n",
    "        x = F.upsample(x, scale_factor=2, mode='nearest') # unpool1\n",
    "        x = self.decode1(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "class MFNet_NOMA(nn.Module):\n",
    "\n",
    "    def __init__(self, n_class):\n",
    "        super(MFNet_NOMA, self).__init__()\n",
    "        self.enc_rgb = MFNet_Enc_rgb()\n",
    "        self.enc_inf = MFNet_Enc_inf()\n",
    "        self.dec = MFNet_Dec(n_class)\n",
    "        \n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x_rgb = self.enc_rgb(x)\n",
    "        x_inf = self.enc_inf(x)\n",
    "        x = x_rgb + x_inf \n",
    "        x = self.dec(x)\n",
    "        return x\n",
    "        # x_rgb = self.enc_rgb(x) \n",
    "        # x_rgb = x_rgb[:,0] + 1j*x_rgb[:,1]\n",
    "        # x_rgb = x_rgb * (torch.randn(x.shape[0],1,40) + 1j*torch.randn(x.shape[0],1,40)).cuda()\n",
    "        # x_inf = self.enc_inf(x)\n",
    "        # x_inf = x_inf[:,0] + 1j*x_inf[:,1]\n",
    "        # x_inf = x_inf * (torch.randn(x.shape[0],1,40) + 1j*torch.randn(x.shape[0],1,40)).cuda()\n",
    "        # x = x_rgb + x_inf \n",
    "        # x = x.reshape(-1,1,30,40)\n",
    "        # x = torch.cat([x.real,x.imag],dim=1)\n",
    "        # x = self.dec(x)\n",
    "        # return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding:utf-8\n",
    "import os\n",
    "import argparse\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from util.MF_dataset import MF_dataset\n",
    "from util.util import calculate_accuracy, calculate_result\n",
    "from util.augmentation import RandomFlip, RandomCrop, RandomCropOut, RandomBrightness, RandomNoise\n",
    "from model import MFNet, SegNet\n",
    "\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# config\n",
    "n_class   = 9\n",
    "data_dir  = './ir_seg_dataset/'\n",
    "model_dir = 'weights/'\n",
    "augmentation_methods = [\n",
    "    RandomFlip(prob=0.5),\n",
    "    RandomCrop(crop_rate=0.1, prob=1.0), \n",
    "    # RandomCropOut(crop_rate=0.2, prob=1.0),\n",
    "    # RandomBrightness(bright_range=0.15, prob=0.9),\n",
    "    # RandomNoise(noise_range=5, prob=0.9),\n",
    "]\n",
    "lr_start  = 0.01\n",
    "lr_decay  = 0.95\n",
    "\n",
    "\n",
    "def train(epo, model, train_loader, optimizer):\n",
    "\n",
    "    lr_this_epo = lr_start * lr_decay**(epo-1)\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr_this_epo\n",
    "\n",
    "    loss_avg = 0.\n",
    "    acc_avg  = 0.\n",
    "    start_t = t = time.time()\n",
    "    model.train()\n",
    "\n",
    "    for it, (images, labels, names) in enumerate(train_loader):\n",
    "        images = Variable(images).cuda(args.gpu) \n",
    "        labels = Variable(labels).cuda(args.gpu)\n",
    "        # if args.gpu >= 0:\n",
    "        #     images = images.cuda(args.gpu)\n",
    "        #     labels = labels.cuda(args.gpu)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(images)\n",
    "        # print(labels.min(), labels.max())\n",
    "\n",
    "        loss = F.cross_entropy(logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        acc = calculate_accuracy(logits, labels)\n",
    "        loss_avg += float(loss.item())\n",
    "        acc_avg  += float(acc)\n",
    "\n",
    "        # cur_t = time.time()\n",
    "        # if cur_t-t > 5:\n",
    "        #     print('|- epo %s/%s. train iter %s/%s. %.2f img/sec loss: %.4f, acc: %.4f' \\\n",
    "        #         % (epo, args.epoch_max, it+1, train_loader.n_iter, (it+1)*args.batch_size/(cur_t-start_t), float(loss), float(acc)))\n",
    "        #     t += 5\n",
    "\n",
    "    content = '| epo:%s/%s lr:%.4f train_loss_avg:%.4f train_acc_avg:%.4f ' \\\n",
    "            % (epo, args.epoch_max, lr_this_epo, loss_avg/train_loader.n_iter, acc_avg/train_loader.n_iter)\n",
    "    print(content)\n",
    "    with open(log_file, 'a') as appender:\n",
    "        appender.write(content)\n",
    "\n",
    "\n",
    "def validation(epo, model, val_loader):\n",
    "\n",
    "    loss_avg = 0.\n",
    "    acc_avg  = 0.\n",
    "    start_t = time.time()\n",
    "    model.eval()\n",
    "\n",
    "    cf = np.zeros((n_class, n_class))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for it, (images, labels, names) in enumerate(val_loader):\n",
    "            images = Variable(images)\n",
    "            labels = Variable(labels)\n",
    "            if args.gpu >= 0:\n",
    "                images = images.cuda(args.gpu)\n",
    "                labels = labels.cuda(args.gpu)\n",
    "\n",
    "            logits = model(images)\n",
    "            loss = F.cross_entropy(logits, labels)\n",
    "            acc = calculate_accuracy(logits, labels)\n",
    "            loss_avg += float(loss)\n",
    "            acc_avg  += float(acc)\n",
    "\n",
    "            # cur_t = time.time()\n",
    "            # print('|- epo %s/%s. val iter %s/%s. %.2f img/sec loss: %.4f, acc: %.4f' \\\n",
    "            #         % (epo, args.epoch_max, it+1, val_loader.n_iter, (it+1)*args.batch_size/(cur_t-start_t), float(loss), float(acc)))\n",
    "\n",
    "            predictions = logits.argmax(1)\n",
    "            for gtcid in range(n_class): \n",
    "                for pcid in range(n_class):\n",
    "                    gt_mask      = labels == gtcid \n",
    "                    pred_mask    = predictions == pcid\n",
    "                    intersection = gt_mask * pred_mask\n",
    "                    cf[gtcid, pcid] += int(intersection.sum())\n",
    "        overall_acc, acc, IoU = calculate_result(cf)\n",
    "\n",
    "    content = '| val_loss_avg:%.4f val_acc_avg:%.4f' \\\n",
    "            % (loss_avg/val_loader.n_iter, acc_avg/val_loader.n_iter)\n",
    "    print(content)\n",
    "    content = '| class accuracy avg:%.4f class IoU avg:%.4f\\n' \\\n",
    "                % (acc.mean(), IoU.mean())\n",
    "    print(content)\n",
    "    \n",
    "    # with open(log_file, 'a') as appender:\n",
    "    #     appender.write(content)\n",
    "\n",
    "\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "from ipdb import set_trace as st\n",
    "class MF_dataset(Dataset):\n",
    "\n",
    "    def __init__(self, data_dir, split, have_label, input_h=480, input_w=640 ,transform=[]):\n",
    "        super(MF_dataset, self).__init__()\n",
    "\n",
    "        # assert split in ['train', 'val', 'test'], 'split must be \"train\"|\"val\"|\"test\"'\n",
    "\n",
    "        with open(os.path.join(data_dir, split+'.txt'), 'r') as f:\n",
    "            self.names = [name.strip() for name in f.readlines()]\n",
    "\n",
    "        self.data_dir  = data_dir\n",
    "        self.split     = split\n",
    "        self.input_h   = input_h\n",
    "        self.input_w   = input_w\n",
    "        self.transform = transform\n",
    "        self.is_train  = have_label\n",
    "        self.n_data    = len(self.names)\n",
    "\n",
    "\n",
    "    def read_image(self, name, folder):\n",
    "        file_path = os.path.join(self.data_dir, '%s/%s.png' % (folder, name))\n",
    "        image     = np.asarray(Image.open(file_path)) # (w,h,c)\n",
    "        image = np.require(image, dtype='f4', requirements=['O', 'W'])\n",
    "        image.flags.writeable = True\n",
    "        return image\n",
    "\n",
    "    def get_train_item(self, index):\n",
    "        name  = self.names[index]\n",
    "        image = self.read_image(name, 'images')\n",
    "        label = self.read_image(name, 'labels')\n",
    "\n",
    "        for func in self.transform:\n",
    "            image, label = func(image, label)\n",
    "\n",
    "        image = np.asarray(Image.fromarray(np.uint8(image)).resize((self.input_w, self.input_h)), dtype=np.float32).transpose((2,0,1))/255\n",
    "        # label = np.asarray(Image.fromarray(label).resize((self.input_w, self.input_h)), dtype=np.int64)\n",
    "        label = np.asarray(Image.fromarray(label).resize((self.input_w, self.input_h), Image.NEAREST), dtype=np.int64)\n",
    "\n",
    "        return torch.tensor(image), torch.tensor(label), name\n",
    "\n",
    "    def get_test_item(self, index):\n",
    "        name  = self.names[index]\n",
    "        image = self.read_image(name, 'images')\n",
    "        image = np.asarray(Image.fromarray(image).resize((self.input_w, self.input_h)), dtype=np.float32).transpose((2,0,1))/255\n",
    "\n",
    "        return torch.tensor(image), name\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        if self.is_train is True:\n",
    "            return self.get_train_item(index)\n",
    "        else: \n",
    "            return self.get_test_item (index)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.argv = ['run.py']\n",
    "parser = argparse.ArgumentParser(description='Train MFNet with pytorch')\n",
    "parser.add_argument('--model_name',  '-M',  type=str, default='MFNet_NOMA')\n",
    "parser.add_argument('--batch_size',  '-B',  type=int, default=8)\n",
    "\n",
    "parser.add_argument('--epoch_max' ,  '-E',  type=int, default=100)\n",
    "# parser.add_argument('--epoch_max' ,  '-E',  type=int, default=2)\n",
    "\n",
    "parser.add_argument('--epoch_from',  '-EF', type=int, default=1)\n",
    "parser.add_argument('--gpu',         '-G',  type=int, default=0)\n",
    "parser.add_argument('--num_workers', '-j',  type=int, default=0)\n",
    "args = parser.parse_args()\n",
    "model_dir = 'weights/'\n",
    "model_dir = os.path.join(model_dir, args.model_name)\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "checkpoint_model_file = os.path.join(model_dir, 'tmp_pretrain1.pth')\n",
    "checkpoint_optim_file = os.path.join(model_dir, 'tmp_pretrain1.optim')\n",
    "final_model_file      = os.path.join(model_dir, 'final_pretrain1_C4.pth')\n",
    "log_file              = os.path.join(model_dir, 'log_pretrain1.txt')\n",
    "\n",
    "print('| training %s on GPU #%d with pytorch' % (args.model_name, args.gpu))\n",
    "print('| from epoch %d / %s' % (args.epoch_from, args.epoch_max))\n",
    "print('| model will be saved in: %s' % model_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = eval(args.model_name)(n_class=n_class)\n",
    "if args.gpu >= 0: model.cuda(args.gpu)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr_start, momentum=0.9, weight_decay=0.0005) \n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=lr_start)\n",
    "\n",
    "if args.epoch_from > 1:\n",
    "    print('| loading checkpoint file %s... ' % checkpoint_model_file, end='')\n",
    "    model.load_state_dict(torch.load(checkpoint_model_file, map_location='cuda:0'))\n",
    "    optimizer.load_state_dict(torch.load(checkpoint_optim_file))\n",
    "    print('done!')\n",
    "\n",
    "train_dataset = MF_dataset(data_dir, 'train', have_label=True, transform=augmentation_methods)\n",
    "val_dataset  = MF_dataset(data_dir, 'val', have_label=True)\n",
    "\n",
    "train_loader  = DataLoader(\n",
    "    dataset     = train_dataset,\n",
    "    batch_size  = args.batch_size,\n",
    "    shuffle     = True,\n",
    "    num_workers = args.num_workers,\n",
    "    pin_memory  = True,\n",
    "    drop_last   = True\n",
    ")\n",
    "val_loader  = DataLoader(\n",
    "    dataset     = val_dataset,\n",
    "    batch_size  = args.batch_size,\n",
    "    shuffle     = False,\n",
    "    num_workers = args.num_workers,\n",
    "    pin_memory  = True,\n",
    "    drop_last   = False\n",
    ")\n",
    "train_loader.n_iter = len(train_loader)\n",
    "val_loader.n_iter   = len(val_loader)\n",
    "\n",
    "for epo in (range(args.epoch_from, args.epoch_max+1)):\n",
    "    print('\\n| epo #%s begin...' % epo)\n",
    "\n",
    "    train(epo, model, train_loader, optimizer)\n",
    "    validation(epo, model, val_loader)\n",
    "\n",
    "    # save check point model\n",
    "    # print('| saving check point model file... ', end='')\n",
    "    torch.save(model.state_dict(), checkpoint_model_file)\n",
    "    torch.save(optimizer.state_dict(), checkpoint_optim_file)\n",
    "    # print('done!')\n",
    "if os.path.exists(final_model_file):\n",
    "    os.remove(final_model_file) # 删除已存在的文件\n",
    "os.rename(checkpoint_model_file, final_model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 测试"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.util import visualize\n",
    "import sys\n",
    "\n",
    "sys.argv = ['run.py']\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Run MFNet demo with pytorch')\n",
    "parser.add_argument('--model_name', '-M',  type=str, default='MFNet_NOMA')\n",
    "parser.add_argument('--gpu',        '-G',  type=int, default=0)\n",
    "args = parser.parse_args()\n",
    "model_dir = 'weights/'\n",
    "model_dir = os.path.join(model_dir, args.model_name)\n",
    "\n",
    "checkpoint_model_file = os.path.join(model_dir, 'tmp_pretrain1.pth')\n",
    "final_model_file      = os.path.join(model_dir, 'final_pretrain1_C4.pth')\n",
    "print('| running %s demo on GPU #%d with pytorch' % (args.model_name, args.gpu))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = eval(args.model_name)(n_class=n_class)\n",
    "if args.gpu >= 0: model.cuda(args.gpu)\n",
    "if os.path.exists(final_model_file):\n",
    "    model.load_state_dict(torch.load(final_model_file, map_location='cuda:0'))\n",
    "elif os.path.exists(checkpoint_model_file):\n",
    "    model.load_state_dict(torch.load(checkpoint_model_file, map_location='cuda:0'))\n",
    "else:\n",
    "    raise Exception('| model file do not exists in %s' % model_dir)\n",
    "print('| model loaded!')\n",
    "\n",
    "\n",
    "files = os.listdir('image')\n",
    "images = []\n",
    "fpath  = []\n",
    "fpath_out = []\n",
    "fpath_original = []\n",
    "for file in files:\n",
    "    if file[-3:] != 'png': continue\n",
    "    fpath.append('image/'+file)\n",
    "    fpath_out.append('seg_MFNet/'+file)\n",
    "    fpath_original.append('image_original/'+file)\n",
    "    images.append( np.asarray(Image.open('image/'+file)) )\n",
    "images = np.asarray(images, dtype=np.float32).transpose((0,3,1,2))/255.\n",
    "images = Variable(torch.tensor(images))\n",
    "if args.gpu >= 0: images = images.cuda(args.gpu)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    logits = model(images)\n",
    "    predictions = logits.argmax(1)\n",
    "    save_images(images, fpath_original)  #保存原始图像\n",
    "    visualize(fpath_out, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 性能指标"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.util import calculate_accuracy, calculate_result\n",
    "import sys\n",
    "\n",
    "sys.argv = ['run.py']\n",
    "\n",
    "\n",
    "cf = np.zeros((n_class, n_class))\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Test MFNet with pytorch')\n",
    "parser.add_argument('--model_name', '-M',  type=str, default='MFNet_NOMA')\n",
    "parser.add_argument('--batch_size',  '-B',  type=int, default=16)\n",
    "parser.add_argument('--gpu',        '-G',  type=int, default=0)\n",
    "parser.add_argument('--num_workers', '-j',  type=int, default=0)\n",
    "\n",
    "\n",
    "\n",
    "args = parser.parse_args()\n",
    "model_dir = 'weights/'\n",
    "model_dir = os.path.join(model_dir, args.model_name)\n",
    "\n",
    "checkpoint_model_file = os.path.join(model_dir, 'tmp_pretrain1.pth')\n",
    "final_model_file      = os.path.join(model_dir, 'final_pretrain1_C4.pth')\n",
    "print('| testing %s on GPU #%d with pytorch' % (args.model_name, args.gpu))\n",
    "\n",
    "model = eval(args.model_name)(n_class=n_class)\n",
    "if args.gpu >= 0: model.cuda(args.gpu)\n",
    "if os.path.exists(final_model_file):\n",
    "    model.load_state_dict(torch.load(final_model_file, map_location='cuda:0'))\n",
    "elif os.path.exists(checkpoint_model_file):\n",
    "    model.load_state_dict(torch.load(checkpoint_model_file, map_location='cuda:0'))\n",
    "else:\n",
    "    raise Exception('| model file do not exists in %s' % model_dir)\n",
    "print('| model loaded!')\n",
    "\n",
    "\n",
    "test_dataset  = MF_dataset(data_dir, 'test', have_label=True)\n",
    "test_loader  = DataLoader(\n",
    "    dataset     = test_dataset,\n",
    "    batch_size  = args.batch_size,\n",
    "    shuffle     = False,\n",
    "    num_workers = args.num_workers,\n",
    "    pin_memory  = True,\n",
    "    drop_last   = False\n",
    ")\n",
    "test_loader.n_iter = len(test_loader)\n",
    "\n",
    "loss_avg = 0.\n",
    "acc_avg  = 0.\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for it, (images, labels, names) in enumerate(test_loader):\n",
    "        images = Variable(images)\n",
    "        labels = Variable(labels)\n",
    "        if args.gpu >= 0:\n",
    "            images = images.cuda(args.gpu)\n",
    "            labels = labels.cuda(args.gpu)\n",
    "\n",
    "        logits = model(images)\n",
    "        loss = F.cross_entropy(logits, labels)\n",
    "        acc = calculate_accuracy(logits, labels)\n",
    "        loss_avg += float(loss)\n",
    "        acc_avg  += float(acc)\n",
    "\n",
    "        print('|- test iter %s/%s. loss: %.4f, acc: %.4f' \\\n",
    "                % (it+1, test_loader.n_iter, float(loss), float(acc)))\n",
    "\n",
    "        predictions = logits.argmax(1)\n",
    "        for gtcid in range(n_class): \n",
    "            for pcid in range(n_class):\n",
    "                gt_mask      = labels == gtcid \n",
    "                pred_mask    = predictions == pcid\n",
    "                intersection = gt_mask * pred_mask\n",
    "                cf[gtcid, pcid] += int(intersection.sum())\n",
    "\n",
    "overall_acc, acc, IoU = calculate_result(cf)\n",
    "\n",
    "print('| overall accuracy:', overall_acc)\n",
    "print('| accuracy of each class:', acc)\n",
    "print('| class accuracy avg:', acc.mean())\n",
    "print('| IoU:', IoU)\n",
    "print('| class IoU avg:', IoU.mean())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 阶段1：预训练上行导频发送、模拟合并器和上行预编码"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 网络定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from tqdm import trange\n",
    "from time import sleep\n",
    "from my_log import logger, rmLogger\n",
    "# 三个可学习的导频，分别是基站端两个发送导频 用户端模拟合并\n",
    "# Transformer1：用户端输入接收导频输出输出混合预编码矩阵 （两个用户用不同的参数）\n",
    "# Transformer2: 用户输入接收导频输出反馈比特 （两个用户用不同的参数）\n",
    "# Transformer3：基站输入反馈比特，输出模拟合并矩阵\n",
    "# 拆分成4个网络，三个Transformer分成3个类，最后一个总的里面也包含三个导频\n",
    "# 考虑信道时变，那么损失函数用导频之后的第L+1信道的频谱效率\n",
    "\n",
    "\n",
    "d_sem = 192 #语义特征维度\n",
    "\n",
    "# 可训练的三个导频\n",
    "class Pilot_trans(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            Nc,     #子载波数\n",
    "            N_r,    #基站接收天线数\n",
    "            N_r_RF, #基站射频数\n",
    "            N_t,    #用户发送天线数\n",
    "            N_t_RF, #用户发送射频数\n",
    "            L,      #导频OFDM符号数\n",
    "        ):\n",
    "        super().__init__();\n",
    "\n",
    "        self.N_r = N_r\n",
    "        self.L = L\n",
    "        self.N_t = N_t\n",
    "        self.N_t_RF = N_t_RF\n",
    "\n",
    "        # self.p_UE_1 = nn.Parameter(torch.randn(1, Nc, L, N_t, 1) + 1j*torch.randn(1, Nc, L, N_t, 1))\n",
    "        # self.p_UE_2 = nn.Parameter(torch.randn(1, Nc, L, N_t, 1) + 1j*torch.randn(1, Nc, L, N_t, 1))\n",
    "\n",
    "        # self.p_UE_1 = nn.Parameter(torch.randn(1, 1, L, N_t, 1) + 1j*torch.randn(1, 1, L, N_t, 1))\n",
    "        # self.p_UE_2 = nn.Parameter(torch.randn(1, 1, L, N_t, 1) + 1j*torch.randn(1, 1, L, N_t, 1))\n",
    "\n",
    "        self.p_BS_RF = nn.Parameter(torch.randn(1, 1, L, N_r, N_r_RF) + 1j*torch.randn(1, 1, L, N_r, N_r_RF))\n",
    "        self.p_BS_BB = nn.Parameter(torch.randn(1, Nc, L, N_r_RF, 1) + 1j*torch.randn(1, Nc, L, N_r_RF, 1))\n",
    "\n",
    "        self.p_UE = nn.Parameter(torch.randn(1, 1, L, N_t_RF, N_t) + 1j*torch.randn(1, 1, L, N_t_RF, N_t))\n",
    "\n",
    "    def forward(\n",
    "            self, \n",
    "            H_batch_1,  # b,T, Nc, N_r, N_t\n",
    "            H_batch_2,  # b,T, Nc, N_r, N_t\n",
    "        ):\n",
    "\n",
    "\n",
    "        b,T, Nc, N_r, N_t = H_batch_1.shape\n",
    "        N_t_RF = self.N_t_RF\n",
    "        L = self.L\n",
    "        H_batch_1 = H_batch_1[:,0:L].permute(0,2,1,4,3) # b, Nc, L, N_t, N_r\n",
    "        H_batch_2 = H_batch_2[:,0:L].permute(0,2,1,4,3) # b, Nc, L, N_t, N_r\n",
    "\n",
    "\n",
    "        p_UE = self.p_UE/torch.abs(self.p_UE)/sqrt(self.N_t)\n",
    "        p_BS = self.p_BS_RF @ self.p_BS_BB\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        received_pilot_1 = p_UE @ (H_batch_1 @ p_BS) # b, Nc, L, N_t_RF, 1\n",
    "        received_pilot_2 = p_UE @ (H_batch_2 @ p_BS) # b, Nc, L, N_t_RF, 1\n",
    "\n",
    "\n",
    "        norm_factor = torch.sqrt(torch.sum(torch.abs(received_pilot_1)**2, dim=(-4,-3,-2, -1), keepdim=True))\n",
    "        received_pilot_1 = received_pilot_1 / norm_factor * torch.sqrt(torch.tensor(Nc*L*N_t_RF, dtype=received_pilot_1.dtype, device=received_pilot_1.device))\n",
    "\n",
    "        norm_factor = torch.sqrt(torch.sum(torch.abs(received_pilot_2)**2, dim=(-4,-3,-2, -1), keepdim=True))\n",
    "        received_pilot_2 = received_pilot_2 / norm_factor * torch.sqrt(torch.tensor(Nc*L*N_t_RF, dtype=received_pilot_2.dtype, device=received_pilot_2.device))\n",
    "\n",
    "\n",
    "        return received_pilot_1,received_pilot_2   \n",
    "\n",
    "\n",
    "class pilot2sem(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            Nc,     #子载波数\n",
    "            N_r,    #基站接收天线数\n",
    "            N_r_RF, #基站射频数\n",
    "            N_t,    #用户发送天线数\n",
    "            N_t_RF, #用户发送射频数\n",
    "            L,      #导频OFDM符号数\n",
    "        ):\n",
    "        super().__init__();\n",
    "\n",
    "        self.d_model = 192\n",
    "        self.B = 4  #量化精度\n",
    "\n",
    "        # self.trans  = TRANS_BLOCK(tx*2,tx*2,512,4)\n",
    "\n",
    "        self.embed= nn.Linear(2*N_t_RF*L, self.d_model) \n",
    "        self.positional_embedding=nn.Parameter(torch.zeros(1, Nc, self.d_model));\n",
    "\n",
    "        self.backbone=nn.Sequential(  # b, K*T, d_model\n",
    "            *[nn.Sequential(\n",
    "                nn.TransformerEncoderLayer(\n",
    "                    d_model=self.d_model, \n",
    "                    nhead=8, \n",
    "                    dim_feedforward=4*self.d_model, \n",
    "                    dropout=0.0, \n",
    "                    activation=\"gelu\", \n",
    "                    batch_first=True,\n",
    "                    norm_first = True, \n",
    "                ), \n",
    "            ) for _ in range(2)], \n",
    "            nn.LayerNorm(self.d_model),\n",
    "        );  # b, K*T, d_model\n",
    "\n",
    "        self.head=nn.Sequential(  \n",
    "            nn.Linear(self.d_model, d_sem),  # b, Nc, d_sem\n",
    "        );\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    def forward(\n",
    "            self, \n",
    "            received_pilot,  # b, Nc, L, N_t_RF, 1\n",
    "        ):\n",
    "        # b = H_DL_batch.shape[0]\n",
    "        # H_DL_batch_1 = H_DL_batch.reshape(b, 48, 4, 128,2,2)[:,:,:,:,0,:].conj() #这里加了conj是因为上下行信道之间有个共轭转置，所以共轭这部分需要conj回去消除掉\n",
    "        # H_DL_batch_2 = H_DL_batch.reshape(b, 48, 4, 128,2,2)[:,:,:,:,1,:].conj()\n",
    "\n",
    "        # H_DL_batch_beam_1 = (H_DL_batch_1*np.exp(1j*pi/2 * 0) + H_DL_batch_2*np.exp(1j*pi/2 * 0)).reshape(b,1,48,4,256)\n",
    "\n",
    "        b, Nc, L, N_t_RF, _ = received_pilot.shape\n",
    "\n",
    "\n",
    "        y_cat = received_pilot.reshape(b,Nc,L*N_t_RF) \n",
    "        y_cat=torch.cat([y_cat.real, y_cat.imag], dim=-1);  # b,Nc,2*L*N_t_RF\n",
    "\n",
    "        x = self.embed(y_cat) + self.positional_embedding  # b,Nc,d_model\n",
    "\n",
    "        x = self.backbone(x)   # b,Nc,d_model\n",
    "        CSI_sem_UE = self.head(x)   #b, Nc, d_sem\n",
    "        return CSI_sem_UE     #b, Nc, d_sem\n",
    "\n",
    "class sem2precoding(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            Nc,     #子载波数\n",
    "            N_r,    #基站接收天线数\n",
    "            N_r_RF, #基站射频数\n",
    "            N_t,    #用户发送天线数\n",
    "            N_t_RF, #用户发送射频数\n",
    "            L,      #导频OFDM符号数\n",
    "        ):\n",
    "        super().__init__();\n",
    "\n",
    "        self.d_model = 192\n",
    "        self.N_t = N_t\n",
    "        self.N_t_RF = N_t_RF\n",
    "        self.Nc = Nc\n",
    "        self.N_r = N_r\n",
    "        self.N_r_RF = N_r_RF\n",
    "\n",
    "\n",
    "        # self.trans  = TRANS_BLOCK(tx*2,tx*2,512,4)\n",
    "\n",
    "        self.embed=nn.Sequential(  \n",
    "            nn.Linear(d_sem, self.d_model),  \n",
    "            NormLayer(self.d_model), \n",
    "        );\n",
    "        self.backbone=nn.Sequential(  # b, K*T, d_model\n",
    "            *[nn.Sequential(\n",
    "                nn.TransformerEncoderLayer(\n",
    "                    d_model=self.d_model, \n",
    "                    nhead=8, \n",
    "                    dim_feedforward=4*self.d_model, \n",
    "                    dropout=0.0, \n",
    "                    activation=\"gelu\", \n",
    "                    batch_first=True,\n",
    "                    norm_first = True, \n",
    "                ), \n",
    "            ) for _ in range(2)], \n",
    "            nn.LayerNorm(self.d_model),\n",
    "        );  # b, K*T, d_model\n",
    "\n",
    "        self.head_RF=nn.Sequential(  \n",
    "            ReshapeLayer([-1, Nc*self.d_model]),  \n",
    "            nn.Linear(Nc*self.d_model, 2*N_t_RF*N_t),  \n",
    "        );\n",
    "        # self.head_BB=nn.Sequential(  \n",
    "        #     nn.Linear(self.d_model, 2*N_t_RF*N_t_RF),  \n",
    "        # );\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    def forward(\n",
    "            self, \n",
    "            CSI_sem_UE,  # b, Nc, d_sem\n",
    "        ):\n",
    "\n",
    "        N_t = self.N_t\n",
    "        N_t_RF = self.N_t_RF\n",
    "        Nc = self.Nc\n",
    "        N_r = self.N_r\n",
    "        N_r_RF = self.N_r_RF\n",
    "        b = CSI_sem_UE.shape[0]\n",
    "\n",
    "\n",
    "\n",
    "        x = self.embed(CSI_sem_UE)\n",
    "\n",
    "        x = self.backbone(x)   # b,Nc,d_model\n",
    "\n",
    "        F = self.head_RF(x)\n",
    "        F = F.reshape(b,1,N_t,N_t_RF,2) # b,1,N_t,N_t_RF,2\n",
    "        F = F[:,:,:,:,0] + 1j*F[:,:,:,:,1]\n",
    "        F = F/torch.abs(F)/sqrt(N_t) #[batch, 1,N_t,N_t_RF]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        return F     #[batch, 1,N_t,N_t_RF]\n",
    "\n",
    "class sem2bits(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            Nc,     #子载波数\n",
    "            N_r,    #基站接收天线数\n",
    "            N_r_RF, #基站射频数\n",
    "            N_t,    #用户发送天线数\n",
    "            N_t_RF, #用户发送射频数\n",
    "            L,      #导频OFDM符号数\n",
    "            feedback_bits,  #反馈比特数\n",
    "        ):\n",
    "        super().__init__();\n",
    "\n",
    "        self.d_model = 192\n",
    "        self.B = 4  #量化精度\n",
    "\n",
    "        # self.trans  = TRANS_BLOCK(tx*2,tx*2,512,4)\n",
    "\n",
    "        self.N_t = N_t\n",
    "        self.N_t_RF = N_t_RF\n",
    "        self.Nc = Nc\n",
    "        self.N_r = N_r\n",
    "        self.N_r_RF = N_r_RF\n",
    "\n",
    "        self.embed=nn.Sequential(  \n",
    "            nn.Linear(d_sem, self.d_model),  \n",
    "            NormLayer(self.d_model), \n",
    "        );\n",
    "        self.backbone=nn.Sequential(  # b, K*T, d_model\n",
    "            *[nn.Sequential(\n",
    "                nn.TransformerEncoderLayer(\n",
    "                    d_model=self.d_model, \n",
    "                    nhead=8, \n",
    "                    dim_feedforward=4*self.d_model, \n",
    "                    dropout=0.0, \n",
    "                    activation=\"gelu\", \n",
    "                    batch_first=True,\n",
    "                    norm_first = True, \n",
    "                ), \n",
    "            ) for _ in range(2)], \n",
    "            nn.LayerNorm(self.d_model),\n",
    "        );  # b, K*T, d_model\n",
    "\n",
    "\n",
    "        self.quan=nn.Sequential(  \n",
    "            ReshapeLayer([-1, Nc*self.d_model]),\n",
    "            nn.Linear(Nc*self.d_model, feedback_bits//self.B),  # b, feedback_bits//self.B\n",
    "            nn.BatchNorm1d(feedback_bits//self.B), \n",
    "            nn.Sigmoid(), \n",
    "            QuantizationLayer(self.B),  # b, feedback_bits\n",
    "        );\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    def forward(\n",
    "            self, \n",
    "            CSI_sem_UE,  # b, Nc, d_sem\n",
    "        ):\n",
    "\n",
    "        N_t = self.N_t\n",
    "        N_t_RF = self.N_t_RF\n",
    "        Nc = self.Nc\n",
    "        N_r = self.N_r\n",
    "        N_r_RF = self.N_r_RF\n",
    "        b = CSI_sem_UE.shape[0]\n",
    "\n",
    "        x = self.embed(CSI_sem_UE)\n",
    "        x = self.backbone(x)\n",
    "        out = self.quan(x)   #[batch, Bits]\n",
    "        return out     #[batch, Bits]\n",
    "\n",
    "\n",
    "class bits2sem(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            Nc,     #子载波数\n",
    "            N_r,    #基站接收天线数\n",
    "            N_r_RF, #基站射频数\n",
    "            N_t,    #用户发送天线数\n",
    "            N_t_RF, #用户发送射频数\n",
    "            L,      #导频OFDM符号数\n",
    "            feedback_bits,  #反馈比特数\n",
    "        ):\n",
    "        super().__init__();\n",
    "\n",
    "        self.d_model = 192\n",
    "        self.B = 4  #量化精度\n",
    "        self.feedback_bits = feedback_bits\n",
    "\n",
    "        self.Nc = Nc\n",
    "        self.N_r = N_r\n",
    "        self.N_r_RF = N_r_RF\n",
    "\n",
    "        # self.trans  = TRANS_BLOCK(tx*2,tx*2,512,4)\n",
    "        self.Dequan=nn.Sequential(  \n",
    "            DequantizationLayer(self.B),  \n",
    "        );\n",
    "\n",
    "        self.embed=nn.Sequential(  \n",
    "            nn.Linear(2*feedback_bits//self.B, Nc*self.d_model),  \n",
    "            ReshapeLayer([-1, Nc,self.d_model]),  \n",
    "            NormLayer(self.d_model), \n",
    "        );\n",
    "\n",
    "        self.backbone=nn.Sequential(  # b, K*T, d_model\n",
    "            *[nn.Sequential(\n",
    "                nn.TransformerEncoderLayer(\n",
    "                    d_model=self.d_model, \n",
    "                    nhead=8, \n",
    "                    dim_feedforward=4*self.d_model, \n",
    "                    dropout=0.0, \n",
    "                    activation=\"gelu\", \n",
    "                    batch_first=True,\n",
    "                    norm_first = True, \n",
    "                ), \n",
    "            ) for _ in range(2)], \n",
    "            nn.LayerNorm(self.d_model),\n",
    "        );  # b, K*T, d_model\n",
    "\n",
    "        # self.head=nn.Sequential(  \n",
    "        #     nn.Linear(self.d_model, N_t*2),  \n",
    "        # );\n",
    "        self.head=nn.Sequential(  \n",
    "            nn.Linear(self.d_model, d_sem),  \n",
    "        );\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    def forward(\n",
    "            self, \n",
    "            x1,  # b, feedback_bits   #反馈比特\n",
    "            x2,  # b, feedback_bits   #反馈比特\n",
    "        ):\n",
    "        # b = H_DL_batch.shape[0]\n",
    "        # H_DL_batch_1 = H_DL_batch.reshape(b, 48, 4, 128,2,2)[:,:,:,:,0,:].conj() #这里加了conj是因为上下行信道之间有个共轭转置，所以共轭这部分需要conj回去消除掉\n",
    "        # H_DL_batch_2 = H_DL_batch.reshape(b, 48, 4, 128,2,2)[:,:,:,:,1,:].conj()\n",
    "\n",
    "        # H_DL_batch_beam_1 = (H_DL_batch_1*np.exp(1j*pi/2 * 0) + H_DL_batch_2*np.exp(1j*pi/2 * 0)).reshape(b,1,48,4,256)\n",
    "\n",
    "        b = x1.shape[0]\n",
    "\n",
    "        x1 = self.Dequan(x1) # b,feedback_bits//self.B\n",
    "        x2 = self.Dequan(x2) # b,feedback_bits//self.B\n",
    "        x = torch.cat([x1,x2],dim=-1) # b,2*feedback_bits//self.B\n",
    "\n",
    "        out = self.embed(x) # b,Nc,d_model\n",
    "        out = self.backbone(out)# b,Nc,d_model\n",
    "        CSI_sem_BS = self.head(out)   # b,Nc, d_sem\n",
    "\n",
    "\n",
    "\n",
    "        return CSI_sem_BS     #b,Nc, d_sem\n",
    "\n",
    "class sem2combiner(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            Nc,     #子载波数\n",
    "            N_r,    #基站接收天线数\n",
    "            N_r_RF, #基站射频数\n",
    "            N_t,    #用户发送天线数\n",
    "            N_t_RF, #用户发送射频数\n",
    "            L,      #导频OFDM符号数\n",
    "        ):\n",
    "        super().__init__();\n",
    "\n",
    "        self.d_model = 192\n",
    "        self.B = 4  #量化精度\n",
    "\n",
    "        self.Nc = Nc\n",
    "        self.N_r = N_r\n",
    "        self.N_r_RF = N_r_RF\n",
    "\n",
    "        # self.trans  = TRANS_BLOCK(tx*2,tx*2,512,4)\n",
    "\n",
    "\n",
    "        self.embed=nn.Sequential(  \n",
    "            nn.Linear(d_sem, self.d_model),  \n",
    "            NormLayer(self.d_model), \n",
    "        );\n",
    "\n",
    "        self.backbone=nn.Sequential(  # b, K*T, d_model\n",
    "            *[nn.Sequential(\n",
    "                nn.TransformerEncoderLayer(\n",
    "                    d_model=self.d_model, \n",
    "                    nhead=8, \n",
    "                    dim_feedforward=4*self.d_model, \n",
    "                    dropout=0.0, \n",
    "                    activation=\"gelu\", \n",
    "                    batch_first=True,\n",
    "                    norm_first = True, \n",
    "                ), \n",
    "            ) for _ in range(2)], \n",
    "            nn.LayerNorm(self.d_model),\n",
    "        );  # b, K*T, d_model\n",
    "\n",
    "        # self.head=nn.Sequential(  \n",
    "        #     nn.Linear(self.d_model, N_t*2),  \n",
    "        # );\n",
    "        self.head=nn.Sequential(  \n",
    "            ReshapeLayer([-1, Nc*self.d_model]),  \n",
    "            nn.Linear(Nc*self.d_model, 2*N_r*N_r_RF),  \n",
    "        );\n",
    "\n",
    "    \n",
    "    \n",
    "    def forward(\n",
    "            self, \n",
    "            CSI_sem_BS\n",
    "        ):\n",
    "        # b = H_DL_batch.shape[0]\n",
    "        # H_DL_batch_1 = H_DL_batch.reshape(b, 48, 4, 128,2,2)[:,:,:,:,0,:].conj() #这里加了conj是因为上下行信道之间有个共轭转置，所以共轭这部分需要conj回去消除掉\n",
    "        # H_DL_batch_2 = H_DL_batch.reshape(b, 48, 4, 128,2,2)[:,:,:,:,1,:].conj()\n",
    "\n",
    "        # H_DL_batch_beam_1 = (H_DL_batch_1*np.exp(1j*pi/2 * 0) + H_DL_batch_2*np.exp(1j*pi/2 * 0)).reshape(b,1,48,4,256)\n",
    "\n",
    "        b = CSI_sem_BS.shape[0]\n",
    "\n",
    "        \n",
    "\n",
    "        out = self.embed(CSI_sem_BS) # b,Nc,d_model\n",
    "        out = self.backbone(out)# b,Nc,d_model\n",
    "        out = self.head(out)   # b,N_t*2\n",
    "        # F = out.reshape(b,1,self.N_t,N_t_RF,2) # b,1,N_t,N_t_RF,2\n",
    "        # F = F[:,:,:,:,0] + 1j*F[:,:,:,:,1]\n",
    "        # F = F/torch.abs(F)/sqrt(self.N_t) #[batch, 1,N_t,N_t_RF]\n",
    "\n",
    "        W = out.reshape(b,1,self.N_r_RF,self.N_r,2)\n",
    "        W = W[:,:,:,:,0] + 1j*W[:,:,:,:,1]\n",
    "        W = W/torch.abs(W)/sqrt(self.N_r)  #b,1,self.N_r_RF,self.N_r\n",
    "\n",
    "\n",
    "        return W     #[b,1,N_r_RF,N_r]\n",
    "\n",
    "class physical_E2E(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            Nc,     #子载波数\n",
    "            N_r,    #基站接收天线数\n",
    "            N_r_RF, #基站射频数\n",
    "            N_t,    #用户发送天线数\n",
    "            N_t_RF, #用户发送射频数\n",
    "            L,      #导频OFDM符号数\n",
    "            feedback_bits,  #反馈比特数\n",
    "        ):\n",
    "        super().__init__();\n",
    "\n",
    "        self.pilot2sem_1 = pilot2sem(Nc,N_r,N_r_RF,N_t,N_t_RF,L)\n",
    "        self.sem2precoding_1 = sem2precoding(Nc,N_r,N_r_RF,N_t,N_t_RF,L)\n",
    "        self.sem2bits_1 = sem2bits(Nc,N_r,N_r_RF,N_t,N_t_RF,L,feedback_bits)\n",
    "\n",
    "        self.pilot2sem_2 = pilot2sem(Nc,N_r,N_r_RF,N_t,N_t_RF,L)\n",
    "        self.sem2precoding_2 = sem2precoding(Nc,N_r,N_r_RF,N_t,N_t_RF,L)\n",
    "        self.sem2bits_2 = sem2bits(Nc,N_r,N_r_RF,N_t,N_t_RF,L,feedback_bits)\n",
    "\n",
    "\n",
    "        self.bits2sem   = bits2sem(Nc,N_r,N_r_RF,N_t,N_t_RF,L,feedback_bits)\n",
    "        self.sem2combiner   = sem2combiner(Nc,N_r,N_r_RF,N_t,N_t_RF,L)\n",
    "        self.Pilot_trans = Pilot_trans(Nc,N_r,N_r_RF,N_t,N_t_RF,L)\n",
    "\n",
    "       \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    def forward(\n",
    "            self, \n",
    "            H_batch_1,  # b,T, Nc, N_r, N_t 用户1\n",
    "            H_batch_2,  # b,T, Nc, N_r, N_t 用户2\n",
    "        ):\n",
    "        received_pilot_1,received_pilot_2 = self.Pilot_trans(H_batch_1,H_batch_2)\n",
    "        CSI_sem_UE_1 = self.pilot2sem_1(received_pilot_1)\n",
    "        CSI_sem_UE_2 = self.pilot2sem_2(received_pilot_2)\n",
    "\n",
    "        F_1 = self.sem2precoding_1(CSI_sem_UE_1)\n",
    "        F_2 = self.sem2precoding_2(CSI_sem_UE_2)\n",
    "\n",
    "\n",
    "        bits_1 = self.sem2bits_1(CSI_sem_UE_1)\n",
    "        bits_2 = self.sem2bits_2(CSI_sem_UE_2)\n",
    "\n",
    "        CSI_sem_BS = self.bits2sem(bits_1,bits_2)\n",
    "\n",
    "\n",
    "        W = self.sem2combiner(CSI_sem_BS)\n",
    "        return W,F_1,F_2,CSI_sem_UE_1,CSI_sem_UE_2,CSI_sem_BS\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 训练函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_physical_E2E(N,Nc,Nr,N_r_RF,Nt,N_t_RF,L,feedback_bits,SNR_dB,v_max_km,feedback_bits_pre = None,v_max_km_pre=None,ITERS=20_000,b=32,acc_num=1):\n",
    "    # N代表路径数\n",
    "    \n",
    "    N_t = Nt[0]*Nt[1]\n",
    "    N_r = Nr[0]*Nr[1]\n",
    "    device=0;\n",
    "    lr=1e-4;\n",
    "    log_interval=100; # 每100个输出保存一下许训练记录\n",
    "    save_interval=10*log_interval; # 每1000个测试一下保存记录\n",
    "    iter_begin=0;   #从第0个开始训练 如果不是0就读取之前训练过的check points\n",
    "    save_path=\"./weights/\";\n",
    "    best_loss=0;\n",
    "\n",
    "    model_name = 'physical_E2E' + str(feedback_bits)+'_L' + str(L)+'_v' + str(v_max_km)\n",
    "\n",
    "    dec=physical_E2E(Nc=Nc,N_r=N_r,N_r_RF=N_r_RF,N_t=N_t,N_t_RF=N_t_RF,L=L,feedback_bits=feedback_bits).cuda()\n",
    "    \n",
    "    opt_dec=torch.optim.AdamW(\n",
    "        dec.parameters(), \n",
    "        lr=lr, \n",
    "    )\n",
    "    T = L+1\n",
    "    load_path=save_path+\"physical_E2E\"+\"/\";\n",
    "    if feedback_bits_pre == None:\n",
    "        print('从头训练')\n",
    "    else:\n",
    "        dec_dict = dec.state_dict()\n",
    "        model_name_pre = 'physical_E2E' + str(feedback_bits_pre)+'_L' + str(L)+'_v' + str(v_max_km_pre)\n",
    "        dec_load_path=load_path+model_name_pre+\"_model.pth.tar\";\n",
    "        ckpt=torch.load(dec_load_path, map_location=\"cuda:\"+str(device));\n",
    "        pretrained_dict=ckpt['state_dict'];\n",
    "        pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in dec_dict and \".quan\" not in k and \".Dequan\" not in k}\n",
    "        dec_dict.update(pretrained_dict);\n",
    "        dec.load_state_dict(dec_dict);\n",
    "        print('全部预训练参数读取成功')\n",
    "\n",
    "    def step(step_id):\n",
    "        dec.train();\n",
    "        opt_dec.zero_grad();\n",
    "        loss_acc=0;\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        for _ in range(acc_num):\n",
    "            alpha,A_r,A_t,fd,tau = SV_Channel_set(2*b,Nc,N,Nt,Nr,1,v_max_km)\n",
    "            H_batch = torch.zeros(2*b,T, Nc, N_r, N_t).cuda() + 0j\n",
    "\n",
    "            for i in range(T):\n",
    "                t = i*1/14000/8 #i就表示第i个OFDM符号，每个subframe时间是1ms，每个slot包含14个OFDM符号，当子载波间隔15kHz对应一个frame包含1个slot，30kHz对应2个，60kHz->4,120kHz->8,这里采用120kHz间隔所以除以8\n",
    "                H = SV_Channel_final(2*b,Nc,N,Nt,Nr,1,t,alpha,A_r,A_t,fd,tau)\n",
    "                H_batch[:,i] = H\n",
    "            H_batch_1 = H_batch[0:b]\n",
    "            H_batch_2 = H_batch[b:2*b]\n",
    "\n",
    "            \n",
    "\n",
    "            \n",
    "            W,F_1,F_2,CSI_sem_UE_1,CSI_sem_UE_2,CSI_sem_BS=dec(\n",
    "                    H_batch_1 = H_batch_1,  # b,T, Nc, N_r, N_t 用户1\n",
    "                    H_batch_2 = H_batch_2,  # b,T, Nc, N_r, N_t 用户2\n",
    "                );\n",
    "\n",
    "\n",
    "\n",
    "            # loss_SE = -calculate_average_channel_capacity(H_DL_batch_beam[:,0:1], F, Pt,N0)/acc_num\n",
    "\n",
    "            loss = -torch.min(calculate_average_channel_capacity(H_batch_1[:,L], F_1, W, SNR_dB),calculate_average_channel_capacity(H_batch_2[:,L], F_2, W, SNR_dB))/acc_num\n",
    "            loss = loss.mean()\n",
    "            loss_acc += loss.item()\n",
    "\n",
    "            loss.backward();\n",
    "        \n",
    "\n",
    "        opt_dec.step();\n",
    "\n",
    "        return loss_acc\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def evaluate(step_id):\n",
    "        global loader_test;\n",
    "        dec.eval();\n",
    "        loss_acc=0;\n",
    "        val_num = 10\n",
    "        b = 64\n",
    "        with torch.no_grad():\n",
    "            for i in range(val_num):\n",
    "\n",
    "                alpha,A_r,A_t,fd,tau = SV_Channel_set(2*b,Nc,N,Nt,Nr,1,v_max_km)\n",
    "                H_batch = torch.zeros(2*b,T, Nc, N_r, N_t).cuda() + 0j\n",
    "\n",
    "                for i in range(T):\n",
    "                    t = i*1/14000/8\n",
    "                    H = SV_Channel_final(2*b,Nc,N,Nt,Nr,1,t,alpha,A_r,A_t,fd,tau)\n",
    "                    H_batch[:,i] = H\n",
    "                H_batch_1 = H_batch[0:b]\n",
    "                H_batch_2 = H_batch[b:2*b]\n",
    "\n",
    "\n",
    "                \n",
    "                W,F_1,F_2,CSI_sem_UE_1,CSI_sem_UE_2,CSI_sem_BS=dec(\n",
    "                        H_batch_1 = H_batch_1,  # b,T, Nc, N_r, N_t 用户1\n",
    "                        H_batch_2 = H_batch_2,  # b,T, Nc, N_r, N_t 用户2\n",
    "                    );\n",
    "                loss = -torch.min(calculate_average_channel_capacity(H_batch_1[:,L], F_1, W, SNR_dB),calculate_average_channel_capacity(H_batch_2[:,L], F_2, W, SNR_dB))/val_num\n",
    "                loss = loss.mean()\n",
    "                loss_acc += loss.item()\n",
    "\n",
    "        return loss_acc\n",
    "\n",
    "    def save_ckpt(folder_name):\n",
    "        folder_path=save_path+folder_name+\"/\";\n",
    "        if not os.path.exists(folder_path):\n",
    "            os.makedirs(folder_path);\n",
    "\n",
    "        torch.save({'state_dict': dec.state_dict()}, folder_path+model_name+\"_model.pth.tar\");\n",
    "        torch.save({'best_loss': best_loss, \n",
    "                    'opt_dec_dict': opt_dec.state_dict(), \n",
    "                    }, folder_path+model_name+\"_opt.pth.tar\");\n",
    "\n",
    "    loss_SE_log=0;\n",
    "    t1=time.time();\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    with trange(iter_begin, iter_begin+ITERS) as t:\n",
    "        for i in t:            \n",
    "            loss_SE = step(i);\n",
    "            loss_SE_log+=loss_SE/log_interval;\n",
    "\n",
    "            if (i+1)%log_interval==0:\n",
    "                loss_SE = evaluate(i);\n",
    "                \n",
    "                logger(\"\");\n",
    "                if loss_SE<best_loss:\n",
    "                    best_loss=loss_SE;\n",
    "                    save_ckpt(\"physical_E2E\");\n",
    "                    logger(\"\\nbest - SE = {}\".format(-best_loss));\n",
    "                \n",
    "                logger(\"log - iter[{}] - train - SE = {}\".format(i, -loss_SE_log));\n",
    "                logger(\"log - iter[{}] - test - SE = {}\".format(i, -loss_SE));\n",
    "\n",
    "                \n",
    "\n",
    "                logger(\"time: {} s\".format(time.time()-t1));\n",
    "                t1=time.time();\n",
    "\n",
    "                if (i+1)%save_interval==0:\n",
    "                    logger(\"\");\n",
    "                    logger(\"save - iter[{}] - test - SE = {}\".format(i, -loss_SE));\n",
    "                    logger(\"save - iter[{}] - best - SE = {}\".format(i, -best_loss));\n",
    "\n",
    "                    \n",
    "\n",
    "                t.set_postfix(train_SE=-loss_SE_log,test_SE=-loss_SE,best_SE=-best_loss)\n",
    "\n",
    "                loss_SE_log=0;\n",
    "    rmLogger();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_physical_E2E(N,Nc,Nr,N_r_RF,Nt,N_t_RF,L,feedback_bits,SNR_dB,v_max_km):\n",
    "    # N代表路径数\n",
    "    \n",
    "    N_t = Nt[0]*Nt[1]\n",
    "    N_r = Nr[0]*Nr[1]\n",
    "    device=0;\n",
    "    lr=1e-4;\n",
    "    log_interval=100; # 每100个输出保存一下许训练记录\n",
    "    save_interval=10*log_interval; # 每1000个测试一下保存记录\n",
    "    iter_begin=0;   #从第0个开始训练 如果不是0就读取之前训练过的check points\n",
    "    save_path=\"./weights/\";\n",
    "    best_loss=0;\n",
    "\n",
    "    model_name = 'physical_E2E' + str(feedback_bits)+'_L' + str(L)+'_v' + str(v_max_km)\n",
    "\n",
    "    dec=physical_E2E(Nc=Nc,N_r=N_r,N_r_RF=N_r_RF,N_t=N_t,N_t_RF=N_t_RF,L=L,feedback_bits=feedback_bits).cuda()\n",
    "    \n",
    "   \n",
    "    T = L+1\n",
    "    load_path=save_path+\"physical_E2E\"+\"/\";\n",
    "   \n",
    "    dec_dict = dec.state_dict()\n",
    "    dec_load_path=load_path+model_name+\"_model.pth.tar\";\n",
    "    ckpt=torch.load(dec_load_path, map_location=\"cuda:\"+str(device));\n",
    "    pretrained_dict=ckpt['state_dict'];\n",
    "    pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in dec_dict}\n",
    "    dec_dict.update(pretrained_dict);\n",
    "    dec.load_state_dict(dec_dict);\n",
    "\n",
    "    def evaluate(step_id):\n",
    "        global loader_test;\n",
    "        dec.eval();\n",
    "        loss_acc=0;\n",
    "        val_num = 10\n",
    "        b = 64\n",
    "        with torch.no_grad():\n",
    "            for i in range(val_num):\n",
    "\n",
    "                alpha,A_r,A_t,fd,tau = SV_Channel_set(2*b,Nc,N,Nt,Nr,1,v_max_km)\n",
    "                H_batch = torch.zeros(2*b,T, Nc, N_r, N_t).cuda() + 0j\n",
    "\n",
    "                for i in range(T):\n",
    "                    t = i*1/14000/8\n",
    "                    H = SV_Channel_final(2*b,Nc,N,Nt,Nr,1,t,alpha,A_r,A_t,fd,tau)\n",
    "                    H_batch[:,i] = H\n",
    "                H_batch_1 = H_batch[0:b]\n",
    "                H_batch_2 = H_batch[b:2*b]\n",
    "\n",
    "\n",
    "                \n",
    "                W,F_1,F_2,CSI_sem_UE_1,CSI_sem_UE_2,CSI_sem_BS=dec(\n",
    "                        H_batch_1 = H_batch_1,  # b,T, Nc, N_r, N_t 用户1\n",
    "                        H_batch_2 = H_batch_2,  # b,T, Nc, N_r, N_t 用户2\n",
    "                    );\n",
    "                loss = -torch.min(calculate_average_channel_capacity(H_batch_1[:,L], F_1, W, SNR_dB),calculate_average_channel_capacity(H_batch_2[:,L], F_2, W, SNR_dB))/val_num\n",
    "                loss = loss.mean()\n",
    "                loss_acc += loss.item()\n",
    "\n",
    "        return loss_acc\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    loss_SE = evaluate(0);\n",
    "    print(\"SE：\",-loss_SE)\n",
    "    return -loss_SE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 0\n",
    "Nc = 100\n",
    "N = 2\n",
    "Nt = [1,8]\n",
    "Nr = [1,64]\n",
    "N_r_RF = 2\n",
    "N_t_RF = 2\n",
    "\n",
    "L = 8\n",
    "\n",
    "feedback_bits_pre = None\n",
    "v_max_km_pre = None\n",
    "\n",
    "feedback_bits = 1024\n",
    "SNR_dB = 10\n",
    "v_max_km = 120\n",
    "for L in [4,1,2,8]:\n",
    "# for L in [16]:\n",
    "    train_physical_E2E(N,Nc,Nr,N_r_RF,Nt,N_r_RF,L,feedback_bits,SNR_dB,v_max_km,feedback_bits_pre,v_max_km_pre,ITERS=100_000,b=128,acc_num=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 0\n",
    "Nc = 100\n",
    "N = 2\n",
    "Nt = [1,8]\n",
    "Nr = [1,64]\n",
    "N_r_RF = 2\n",
    "N_t_RF = 2\n",
    "\n",
    "L = 8\n",
    "\n",
    "feedback_bits_pre = None\n",
    "v_max_km_pre = None\n",
    "\n",
    "feedback_bits = 1024\n",
    "SNR_dB = 10\n",
    "v_max_km = 120\n",
    "# for feedback_bits in [4,16,64,256]:\n",
    "for feedback_bits in [64,256]:\n",
    "    train_physical_E2E(N,Nc,Nr,N_r_RF,Nt,N_r_RF,L,feedback_bits,SNR_dB,v_max_km,feedback_bits_pre,v_max_km_pre,ITERS=100_000,b=128,acc_num=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 开始测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 0\n",
    "Nc = 100\n",
    "N = 2\n",
    "Nt = [1,8]\n",
    "Nr = [1,64]\n",
    "N_r_RF = 2\n",
    "N_t_RF = 2\n",
    "\n",
    "L = 8\n",
    "\n",
    "feedback_bits_pre = None\n",
    "v_max_km_pre = None\n",
    "\n",
    "feedback_bits = 1024\n",
    "SNR_dB = 10\n",
    "v_max_km = 120\n",
    "for L in [1,2,4,8]:\n",
    "    test_physical_E2E(N,Nc,Nr,N_r_RF,Nt,N_r_RF,L,feedback_bits,SNR_dB,v_max_km)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 0\n",
    "Nc = 100\n",
    "N = 2\n",
    "Nt = [1,8]\n",
    "Nr = [1,64]\n",
    "N_r_RF = 2\n",
    "N_t_RF = 2\n",
    "\n",
    "L = 8\n",
    "\n",
    "feedback_bits_pre = None\n",
    "v_max_km_pre = None\n",
    "\n",
    "feedback_bits = 1024\n",
    "SNR_dB = 10\n",
    "v_max_km = 120\n",
    "for feedback_bits in [4,16,64,256,1024]:\n",
    "    test_physical_E2E(N,Nc,Nr,N_r_RF,Nt,N_r_RF,L,feedback_bits,SNR_dB,v_max_km)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 阶段2：信源信道语义融合联合训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 网络定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sem_fusion(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            C_out,     #输出通道数\n",
    "        ):\n",
    "        super(Sem_fusion, self).__init__()\n",
    "    \n",
    "        self.B = 4  #量化精度\n",
    "        self.C_out = C_out\n",
    "        self.CSI_dim = 16\n",
    "        self.d_model = 128\n",
    "\n",
    "\n",
    "\n",
    "        # self.trans  = TRANS_BLOCK(tx*2,tx*2,512,4)\n",
    "\n",
    "        self.embed_CSI=nn.Sequential(  \n",
    "            ReshapeLayer([-1, Nc*d_sem]),  \n",
    "            nn.Linear(Nc*d_sem, self.CSI_dim),  \n",
    "        );\n",
    "\n",
    "\n",
    "        \n",
    "    \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(in_features=C_dim+self.CSI_dim, out_features=C_dim),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(in_features=C_dim, out_features=C_dim),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "        self.head=nn.Sequential(  \n",
    "            nn.Linear(C_dim, C_out),\n",
    "\n",
    "        );\n",
    "    \n",
    "    \n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "    def forward(\n",
    "            self, \n",
    "            x_sem,   # b， C_dim, 10, 10  #语义编码结果\n",
    "            CSI_sem,  # b, Nc, d_sem   #反馈比特\n",
    "        ):\n",
    "        x_CSI = self.embed_CSI(CSI_sem) # b, 16\n",
    "        x_ini = torch.mean(x_sem, dim=(2, 3)) # b, C_dim\n",
    "        context_input = torch.cat([x_CSI,x_ini],dim=1) # b, C_dim + 16\n",
    "\n",
    "        mask = self.layers(context_input).view(-1, C_dim, 1, 1)\n",
    "\n",
    "        x = mask * x_sem  # b， C_dim, 10, 10  #语义编码结果\n",
    "\n",
    "        x = x.permute(0,2,3,1) # b, 10, 10, C_dim\n",
    "        x = self.head(x)     # b, 10, 10, C_out\n",
    "        # x = x.permute(0,3,1,2) # b, C_out, 30, 40\n",
    "        \n",
    "\n",
    "        return x # b, 10, 10, C_out  #语义融合结果\n",
    "\n",
    "# Q的数量为C_out/2/N_rf*40，根据要的Q以及N_rf反推出所需的C_out\n",
    "\n",
    "class Sem_E2E(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            Nc,     #子载波数\n",
    "            N_r,    #基站接收天线数\n",
    "            N_r_RF, #基站射频数\n",
    "            N_t,    #用户发送天线数\n",
    "            N_t_RF, #用户发送射频数\n",
    "            L,      #导频OFDM符号数\n",
    "            feedback_bits,  #反馈比特数\n",
    "            n_class,#类别数\n",
    "            Q,      #传输数据符号数\n",
    "        ):\n",
    "        super(Sem_E2E, self).__init__()\n",
    "        self.N_r_RF = N_r_RF\n",
    "        self.N_t_RF = N_t_RF\n",
    "        self.Nc = Nc\n",
    "\n",
    "        self.Q = Q\n",
    "        self.C_out = Q*2*N_t_RF\n",
    "        self.MFNet = MFNet_NOMA(n_class)\n",
    "        self.physical = physical_E2E(Nc,N_r, N_r_RF,N_t,N_t_RF,L,feedback_bits)\n",
    "        self.fusion_1 = Sem_fusion(self.C_out)\n",
    "        self.fusion_2 = Sem_fusion(self.C_out)\n",
    "\n",
    "        self.Dembed=nn.Linear(Q*2*N_r_RF, C_dim)\n",
    "        self.fusion_3 = Sem_fusion(C_dim)\n",
    "        \n",
    "\n",
    "    def forward(\n",
    "            self, \n",
    "            H_batch_1,  # b,T, Nc, N_r, N_t  T就是L+Q\n",
    "            H_batch_2,  # b,T, Nc, N_r, N_t\n",
    "            SNR_dB_Sem, \n",
    "            x, # \n",
    "        ):\n",
    "        Q = self.Q\n",
    "        Nc = self.Nc\n",
    "        C_out = self.C_out\n",
    "        N_t_RF = self.N_t_RF\n",
    "        # split data into RGB and INF\n",
    "        x_rgb = self.MFNet.enc_rgb(x) # [batch,C_dim,10,10]\n",
    "        x_inf = self.MFNet.enc_inf(x) # [batch,C_dim,10,10]\n",
    "\n",
    "        \n",
    "\n",
    "        W,F_1,F_2,CSI_sem_UE_1,CSI_sem_UE_2,CSI_sem_BS = self.physical(H_batch_1,H_batch_2)\n",
    "\n",
    "\n",
    "        # Calculate effective channel\n",
    "        b,_,N_r_RF,N_r = W.shape\n",
    "        N_t = F_1.shape[2]\n",
    "        H_eff_1 = W.reshape(b,1,1,N_r_RF,N_r) @ H_batch_1[:,L:(L+Q)] @ F_1.reshape(b,1,1,N_t,N_t_RF) #H [batch,Q,Nc,N_r_RF,N_t_RF]\n",
    "        H_eff_2 = W.reshape(b,1,1,N_r_RF,N_r) @ H_batch_2[:,L:(L+Q)] @ F_2.reshape(b,1,1,N_t,N_t_RF) #H [batch,Q,Nc,N_r_RF,N_t_RF]\n",
    "\n",
    "        #把bits和x融合\n",
    "        x_1 = self.fusion_1(x_rgb,CSI_sem_UE_1)  # [batch,10,10,C_out]\n",
    "        x_2 = self.fusion_2(x_inf,CSI_sem_UE_2)  # [batch,10,10,C_out]\n",
    "\n",
    "\n",
    "\n",
    "        x1 = x_1.reshape(b,Nc,Q,N_t_RF,1,2) #b,Nc,Q,N_t_RF,1,2\n",
    "        x1 = x1.permute(0,2,1,3,4,5)  #b,Q,Nc,N_t_RF,1,2\n",
    "        x1 = x1[:,:,:,:,:,0] + 1j*x1[:,:,:,:,:,0] #b,Q,Nc,N_t_RF,1\n",
    "        norm_factor = torch.sqrt(torch.sum(torch.abs(x1)**2, dim=(-4,-3,-2, -1), keepdim=True))\n",
    "        x1 = x1 / norm_factor * torch.sqrt(torch.tensor(Q*Nc*N_t_RF, dtype=H_batch_1.dtype, device=H_batch_1.device))\n",
    "        x1 = H_eff_1 @ x1           #b,Q,Nc,N_r_RF,1\n",
    "\n",
    "        x2 = x_2.reshape(b,Nc,Q,N_t_RF,1,2) #b,Nc,Q,N_t_RF,1,2\n",
    "        x2 = x2.permute(0,2,1,3,4,5)  #b,Q,Nc,N_t_RF,1,2\n",
    "        x2 = x2[:,:,:,:,:,0] + 1j*x2[:,:,:,:,:,0] #b,Q,Nc,N_t_RF,1\n",
    "        norm_factor = torch.sqrt(torch.sum(torch.abs(x2)**2, dim=(-4,-3,-2, -1), keepdim=True))\n",
    "        x2 = x2 / norm_factor * torch.sqrt(torch.tensor(Q*Nc*N_t_RF, dtype=H_batch_1.dtype, device=H_batch_1.device))\n",
    "        x2 = H_eff_2 @ x2           #b,Q,Nc,N_r_RF,1\n",
    "\n",
    "        sigma = 10**(-SNR_dB_Sem/10)\n",
    "\n",
    "        n = (torch.randn(b,Q,Nc,N_r_RF,1).cuda() + 1j*torch.randn(b,Q,Nc,N_r_RF,1).cuda())/sqrt(2)*sqrt(sigma)\n",
    "        x = x1 + x2 + n # b,Q,Nc,N_r_RF,1\n",
    "\n",
    "        norm_factor = torch.sqrt(torch.sum(torch.abs(x)**2, dim=(-4,-3,-2, -1), keepdim=True))\n",
    "        x = x / norm_factor * torch.sqrt(torch.tensor(Q*Nc*N_r_RF, dtype=H_batch_1.dtype, device=H_batch_1.device)) # b,Q,Nc,N_r_RF,1\n",
    "\n",
    "        \n",
    "        x = torch.cat([x.real,x.imag],dim=-1) # b,Q,Nc,N_r_RF,2\n",
    "        x = x.permute(0,2,1,3,4) # b,Nc,Q,N_r_RF,2\n",
    "        x = x.reshape(b,10,10,Q*2*N_r_RF)\n",
    "        x = self.Dembed(x) #b, 10,10,C_dim\n",
    "        x = x.permute(0,3,1,2) #b,C_dim,10,10\n",
    "        ####接收端融合####\n",
    "        x = self.fusion_3(x,CSI_sem_BS)  #b,10,10,C_dim\n",
    "        x = x.permute(0,3,1,2) #b,C_dim,10,10\n",
    "        #################\n",
    "        x = self.MFNet.dec(x)\n",
    "\n",
    "        power_signal = torch.sqrt(torch.sum(torch.abs(x1 + x2)**2))/b\n",
    "\n",
    "        return x,power_signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 训练函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_Sem_E2E(N,Nc,Nr,N_r_RF,Nt,N_t_RF,L,feedback_bits,SNR_dB,v_max_km,Q,NOMA_pre = True,Phy_pre = True,feedback_bits_pre = None,SNR_dB_pre = None,v_max_km_pre=None,Q_pre=None,ITERS=20_000,b=8):\n",
    "    # N代表路径数\n",
    "    \n",
    "    N_t = Nt[0]*Nt[1]\n",
    "    N_r = Nr[0]*Nr[1]\n",
    "    device=0;\n",
    "    lr=1e-4;\n",
    "    log_interval=100; # 每100个输出保存一下许训练记录\n",
    "    save_interval=10*log_interval; # 每1000个测试一下保存记录\n",
    "    iter_begin=0;   #从第0个开始训练 如果不是0就读取之前训练过的check points\n",
    "    save_path=\"./weights/\";\n",
    "    best_loss=0;\n",
    "\n",
    "    model_name_physical = 'physical_E2E'+ str(feedback_bits)+'_L' + str(L)+'_v' + str(v_max_km)\n",
    "    model_name = 'Sem_E2E'+str(SNR_dB) + '_' + str(feedback_bits)+'_L' + str(L)+'_v' + str(v_max_km)+'_Q' + str(Q)\n",
    "\n",
    "    dec=Sem_E2E(Nc=Nc,N_r=N_r,N_r_RF=N_r_RF,N_t=N_t,N_t_RF=N_t_RF,L=L,feedback_bits=feedback_bits,n_class=n_class,Q=Q).cuda()\n",
    "    \n",
    "    opt_dec=torch.optim.AdamW(\n",
    "        dec.parameters(), \n",
    "        lr=lr, \n",
    "    )\n",
    "    T = L+Q\n",
    "    load_path=save_path+\"Sem_E2E\"+\"/\";\n",
    "    load_path_physical = save_path+\"physical_E2E\"+\"/\";\n",
    "    if feedback_bits_pre == None:\n",
    "        if Phy_pre == True:\n",
    "            dec_load_path=load_path_physical+model_name_physical+\"_model.pth.tar\";\n",
    "            ckpt=torch.load(dec_load_path, map_location=\"cuda:\"+str(device));\n",
    "            pretrained_dict=ckpt['state_dict'];\n",
    "            model_dict=dec.physical.state_dict();\n",
    "            pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict.keys()};\n",
    "            model_dict.update(pretrained_dict);\n",
    "            dec.physical.load_state_dict(model_dict);\n",
    "            print('物理层预训练网络读取成功')\n",
    "        if NOMA_pre == True:\n",
    "            model_dir_pre = 'weights/'\n",
    "            model_dir_pre = os.path.join(model_dir_pre, 'MFNet_NOMA')\n",
    "            # os.makedirs(model_dir_pre, exist_ok=True)\n",
    "            final_model_file_pre      = os.path.join(model_dir_pre, 'final_pretrain1_C4.pth')\n",
    "            dec.MFNet.load_state_dict(torch.load(final_model_file_pre, map_location='cuda:0'))\n",
    "            print('语义编码预训练网络读取成功')\n",
    "    else:\n",
    "        dec_dict = dec.state_dict()\n",
    "        model_name_pre = 'Sem_E2E'+str(SNR_dB_pre) + '_' + str(feedback_bits_pre)+'_L' + str(L)+'_v' + str(v_max_km_pre)+'_Q' + str(Q_pre)\n",
    "        dec_load_path=load_path+model_name_pre+\"_model.pth.tar\";\n",
    "        ckpt=torch.load(dec_load_path, map_location=\"cuda:\"+str(device));\n",
    "        pretrained_dict=ckpt['state_dict'];\n",
    "        pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in dec_dict and \".quan\" not in k and \".Dequan\" not in k and \".fusion_1.head\" not in k and \".fusion_2.head\" not in k  and \".Dembed\" not in k}\n",
    "        dec_dict.update(pretrained_dict);\n",
    "        dec.load_state_dict(dec_dict);\n",
    "        print('全部预训练参数读取成功')\n",
    "\n",
    "###################################################################\n",
    "    def train(epo, model, train_loader, optimizer):\n",
    "\n",
    "\n",
    "        loss_avg = 0.\n",
    "        acc_avg  = 0.\n",
    "        start_t = t = time.time()\n",
    "        model.train()\n",
    "\n",
    "        for it, (images, labels, names) in enumerate(tqdm(train_loader, desc=\"Training\", leave=True)):\n",
    "            images = Variable(images).cuda(args.gpu) \n",
    "            labels = Variable(labels).cuda(args.gpu)\n",
    "\n",
    "            b = images.shape[0]\n",
    "            alpha,A_r,A_t,fd,tau = SV_Channel_set(2*b,Nc,N,Nt,Nr,1,v_max_km)\n",
    "            H_batch = torch.zeros(2*b,T, Nc, N_r, N_t).cuda() + 0j\n",
    "            for i in range(T):\n",
    "                t = i*1/14000/8 #i就表示第i个OFDM符号，每个subframe时间是1ms，每个slot包含14个OFDM符号，当子载波间隔15kHz对应一个frame包含1个slot，30kHz对应2个，60kHz->4,120kHz->8,这里采用120kHz间隔所以除以8\n",
    "                H = SV_Channel_final(2*b,Nc,N,Nt,Nr,1,t,alpha,A_r,A_t,fd,tau)\n",
    "                H_batch[:,i] = H\n",
    "            H_batch_1 = H_batch[0:b]\n",
    "            H_batch_2 = H_batch[b:2*b]\n",
    "\n",
    "\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            logits,power_signal = model(H_batch_1,H_batch_2, SNR_dB, images)\n",
    "            # print(labels.min(), labels.max())\n",
    "\n",
    "            loss = F.cross_entropy(logits, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            acc = calculate_accuracy(logits, labels)\n",
    "            loss_avg += float(loss.item())\n",
    "            acc_avg  += float(acc)\n",
    "\n",
    "            # cur_t = time.time()\n",
    "            # if cur_t-t > 5:\n",
    "            #     print('|- epo %s/%s. train iter %s/%s. %.2f img/sec loss: %.4f, acc: %.4f' \\\n",
    "            #         % (epo, args.epoch_max, it+1, train_loader.n_iter, (it+1)*args.batch_size/(cur_t-start_t), float(loss), float(acc)))\n",
    "            #     t += 5\n",
    "\n",
    "        content = '| epo:%s/%s train_loss_avg:%.4f train_acc_avg:%.4f ' \\\n",
    "                % (epo, args.epoch_max, loss_avg/train_loader.n_iter, acc_avg/train_loader.n_iter)\n",
    "        print(content)\n",
    "        with open(log_file, 'a') as appender:\n",
    "            appender.write(content)\n",
    "\n",
    "\n",
    "    def validation(epo, model, val_loader):\n",
    "\n",
    "        loss_avg = 0.\n",
    "        acc_avg  = 0.\n",
    "        power_avg = 0.\n",
    "        start_t = time.time()\n",
    "        model.eval()\n",
    "\n",
    "        cf = np.zeros((n_class, n_class))\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for it, (images, labels, names) in enumerate(val_loader):\n",
    "                images = Variable(images)\n",
    "                labels = Variable(labels)\n",
    "                if args.gpu >= 0:\n",
    "                    images = images.cuda(args.gpu)\n",
    "                    labels = labels.cuda(args.gpu)\n",
    "                \n",
    "                b = images.shape[0]\n",
    "                alpha,A_r,A_t,fd,tau = SV_Channel_set(2*b,Nc,N,Nt,Nr,1,v_max_km)\n",
    "                H_batch = torch.zeros(2*b,T, Nc, N_r, N_t).cuda() + 0j\n",
    "                for i in range(T):\n",
    "                    t = i*1/14000/8 #i就表示第i个OFDM符号，每个subframe时间是1ms，每个slot包含14个OFDM符号，当子载波间隔15kHz对应一个frame包含1个slot，30kHz对应2个，60kHz->4,120kHz->8,这里采用120kHz间隔所以除以8\n",
    "                    H = SV_Channel_final(2*b,Nc,N,Nt,Nr,1,t,alpha,A_r,A_t,fd,tau)\n",
    "                    H_batch[:,i] = H\n",
    "                H_batch_1 = H_batch[0:b]\n",
    "                H_batch_2 = H_batch[b:2*b]\n",
    "\n",
    "                logits,power_signal = model(H_batch_1,H_batch_2, SNR_dB, images)\n",
    "                loss = F.cross_entropy(logits, labels)\n",
    "                acc = calculate_accuracy(logits, labels)\n",
    "                loss_avg += float(loss)\n",
    "                acc_avg  += float(acc)\n",
    "                power_avg += float(power_signal.item())\n",
    "\n",
    "                predictions = logits.argmax(1)\n",
    "                for gtcid in range(n_class): \n",
    "                    for pcid in range(n_class):\n",
    "                        gt_mask      = labels == gtcid \n",
    "                        pred_mask    = predictions == pcid\n",
    "                        intersection = gt_mask * pred_mask\n",
    "                        cf[gtcid, pcid] += int(intersection.sum())\n",
    "            overall_acc, acc, IoU = calculate_result(cf)\n",
    "\n",
    "                # cur_t = time.time()\n",
    "                # print('|- epo %s/%s. val iter %s/%s. %.2f img/sec loss: %.4f, acc: %.4f' \\\n",
    "                #         % (epo, args.epoch_max, it+1, val_loader.n_iter, (it+1)*args.batch_size/(cur_t-start_t), float(loss), float(acc)))\n",
    "\n",
    "        content = '| val_loss_avg:%.4f val_acc_avg:%.4f  val_power_avg:%.2f' \\\n",
    "                % (loss_avg/val_loader.n_iter, acc_avg/val_loader.n_iter, power_avg/val_loader.n_iter)\n",
    "        print(content)\n",
    "\n",
    "        content = '| class accuracy avg:%.4f class IoU avg:%.4f' \\\n",
    "                % (acc.mean(), IoU.mean())\n",
    "        print(content)\n",
    "        # with open(log_file, 'a') as appender:\n",
    "        #     appender.write(content)\n",
    "        return IoU.mean()\n",
    "    \n",
    "    def save_ckpt(folder_name):\n",
    "        folder_path=save_path+folder_name+\"/\";\n",
    "        if not os.path.exists(folder_path):\n",
    "            os.makedirs(folder_path);\n",
    "\n",
    "        torch.save({'state_dict': dec.state_dict()}, folder_path+model_name+\"_model.pth.tar\");\n",
    "        # torch.save({'best_loss': best_loss, \n",
    "        #             'opt_dec_dict': opt_dec.state_dict(), \n",
    "        #             }, folder_path+model_name+\"_opt.pth.tar\");\n",
    "\n",
    "\n",
    "#################################################################################################\n",
    "    import sys\n",
    "    sys.argv = ['run.py']\n",
    "    parser = argparse.ArgumentParser(description='Train MFNet with pytorch')\n",
    "    parser.add_argument('--model_name',  '-M',  type=str, default='Sem_E2E')\n",
    "    parser.add_argument('--batch_size',  '-B',  type=int, default=b)\n",
    "\n",
    "    parser.add_argument('--epoch_max' ,  '-E',  type=int, default=100)\n",
    "    # parser.add_argument('--epoch_max' ,  '-E',  type=int, default=2)\n",
    "\n",
    "    parser.add_argument('--epoch_from',  '-EF', type=int, default=1)\n",
    "    parser.add_argument('--gpu',         '-G',  type=int, default=0)\n",
    "    parser.add_argument('--num_workers', '-j',  type=int, default=0)\n",
    "    args = parser.parse_args()\n",
    "    model_dir = 'weights/'\n",
    "    model_dir = os.path.join(model_dir, args.model_name)\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    log_file              = os.path.join(model_dir, 'log_Sem_E2E.txt')\n",
    "\n",
    "    print('| training %s on GPU #%d with pytorch' % (args.model_name, args.gpu))\n",
    "    print('| from epoch %d / %s' % (args.epoch_from, args.epoch_max))\n",
    "    print('| model will be saved in: %s' % model_dir)\n",
    "\n",
    "\n",
    "\n",
    "    best_mIOU = -1\n",
    "\n",
    "    train_dataset = MF_dataset(data_dir, 'train', have_label=True, transform=augmentation_methods)\n",
    "    val_dataset  = MF_dataset(data_dir, 'val', have_label=True)\n",
    "\n",
    "    train_loader  = DataLoader(\n",
    "        dataset     = train_dataset,\n",
    "        batch_size  = args.batch_size,\n",
    "        shuffle     = True,\n",
    "        num_workers = args.num_workers,\n",
    "        pin_memory  = True,\n",
    "        drop_last   = True\n",
    "    )\n",
    "    val_loader  = DataLoader(\n",
    "        dataset     = val_dataset,\n",
    "        batch_size  = args.batch_size,\n",
    "        shuffle     = False,\n",
    "        num_workers = args.num_workers,\n",
    "        pin_memory  = True,\n",
    "        drop_last   = False\n",
    "    )\n",
    "    train_loader.n_iter = len(train_loader)\n",
    "    val_loader.n_iter   = len(val_loader)\n",
    "\n",
    "    for epo in (range(args.epoch_from, args.epoch_max+1)):\n",
    "        print('\\n| epo #%s begin...' % epo)\n",
    "\n",
    "        train(epo, dec, train_loader, opt_dec)\n",
    "        mIOU = validation(epo, dec, val_loader)\n",
    "\n",
    "        if mIOU>best_mIOU:\n",
    "            best_mIOU=mIOU;\n",
    "            save_ckpt(\"Sem_E2E\");\n",
    "            print(\"| save best\")\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t = 0\n",
    "# Nc = 100\n",
    "# N = 2\n",
    "# Nt = [1,8]\n",
    "# Nr = [1,64]\n",
    "# N_r_RF = 2\n",
    "# N_t_RF = 2\n",
    "\n",
    "# L = 8\n",
    "\n",
    "# feedback_bits_pre = None\n",
    "# SNR_dB_pre = None\n",
    "# v_max_km_pre = None\n",
    "# Q_pre = None\n",
    "\n",
    "# NOMA_pre=True\n",
    "# Phy_pre=True\n",
    "\n",
    "# feedback_bits = 1024\n",
    "# SNR_dB = -25\n",
    "# v_max_km = 120\n",
    "# Q = 4\n",
    "# for L in [16]:\n",
    "#     train_Sem_E2E(N,Nc,Nr,N_r_RF,Nt,N_t_RF,L,feedback_bits,SNR_dB,v_max_km,Q,NOMA_pre, Phy_pre,feedback_bits_pre,SNR_dB_pre,v_max_km_pre,Q_pre,ITERS=600_000,b=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 0\n",
    "Nc = 100\n",
    "N = 2\n",
    "Nt = [1,8]\n",
    "Nr = [1,64]\n",
    "N_r_RF = 2\n",
    "N_t_RF = 2\n",
    "\n",
    "L = 8\n",
    "\n",
    "feedback_bits_pre = None\n",
    "SNR_dB_pre = None\n",
    "v_max_km_pre = None\n",
    "Q_pre = None\n",
    "\n",
    "NOMA_pre=True\n",
    "Phy_pre=True\n",
    "\n",
    "feedback_bits = 1024\n",
    "SNR_dB = -25\n",
    "v_max_km = 120\n",
    "Q = 1\n",
    "for L in [2]:\n",
    "    train_Sem_E2E(N,Nc,Nr,N_r_RF,Nt,N_t_RF,L,feedback_bits,SNR_dB,v_max_km,Q,NOMA_pre, Phy_pre,feedback_bits_pre,SNR_dB_pre,v_max_km_pre,Q_pre,ITERS=600_000,b=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t = 0\n",
    "# Nc = 100\n",
    "# N = 2\n",
    "# Nt = [1,8]\n",
    "# Nr = [1,64]\n",
    "# N_r_RF = 2\n",
    "# N_t_RF = 2\n",
    "\n",
    "# L = 8\n",
    "\n",
    "# feedback_bits_pre = None\n",
    "# SNR_dB_pre = None\n",
    "# v_max_km_pre = None\n",
    "# Q_pre = None\n",
    "\n",
    "# NOMA_pre=True\n",
    "# Phy_pre=True\n",
    "\n",
    "# feedback_bits = 1024\n",
    "# SNR_dB = -25\n",
    "# v_max_km = 120\n",
    "# Q = 4\n",
    "# for feedback_bits in [16,64,256]:\n",
    "#     train_Sem_E2E(N,Nc,Nr,N_r_RF,Nt,N_t_RF,L,feedback_bits,SNR_dB,v_max_km,Q,NOMA_pre, Phy_pre,feedback_bits_pre,SNR_dB_pre,v_max_km_pre,Q_pre,ITERS=600_000,b=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 0\n",
    "Nc = 100\n",
    "N = 2\n",
    "Nt = [1,8]\n",
    "Nr = [1,64]\n",
    "N_r_RF = 2\n",
    "N_t_RF = 2\n",
    "\n",
    "L = 8\n",
    "\n",
    "feedback_bits_pre = None\n",
    "SNR_dB_pre = None\n",
    "v_max_km_pre = None\n",
    "Q_pre = None\n",
    "\n",
    "NOMA_pre=True\n",
    "Phy_pre=True\n",
    "\n",
    "feedback_bits = 1024\n",
    "SNR_dB = -25\n",
    "v_max_km = 120\n",
    "Q = 1\n",
    "for feedback_bits in [4,16,64,256]:\n",
    "    train_Sem_E2E(N,Nc,Nr,N_r_RF,Nt,N_t_RF,L,feedback_bits,SNR_dB,v_max_km,Q,NOMA_pre, Phy_pre,feedback_bits_pre,SNR_dB_pre,v_max_km_pre,Q_pre,ITERS=600_000,b=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 0\n",
    "Nc = 100\n",
    "N = 2\n",
    "Nt = [1,8]\n",
    "Nr = [1,64]\n",
    "N_r_RF = 2\n",
    "N_t_RF = 2\n",
    "\n",
    "L = 8\n",
    "\n",
    "feedback_bits_pre = None\n",
    "SNR_dB_pre = None\n",
    "v_max_km_pre = None\n",
    "Q_pre = None\n",
    "\n",
    "NOMA_pre=True\n",
    "Phy_pre=True\n",
    "\n",
    "feedback_bits = 1024\n",
    "SNR_dB = -25\n",
    "v_max_km = 120\n",
    "Q = 4\n",
    "for Q in [2,3,5]:\n",
    "    train_Sem_E2E(N,Nc,Nr,N_r_RF,Nt,N_t_RF,L,feedback_bits,SNR_dB,v_max_km,Q,NOMA_pre, Phy_pre,feedback_bits_pre,SNR_dB_pre,v_max_km_pre,Q_pre,ITERS=600_000,b=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t = 0\n",
    "# Nc = 100\n",
    "# N = 2\n",
    "# Nt = [1,8]\n",
    "# Nr = [1,64]\n",
    "# N_r_RF = 2\n",
    "# N_t_RF = 2\n",
    "\n",
    "# L = 8\n",
    "\n",
    "# feedback_bits_pre = None\n",
    "# SNR_dB_pre = None\n",
    "# v_max_km_pre = None\n",
    "# Q_pre = None\n",
    "\n",
    "# NOMA_pre=True\n",
    "# Phy_pre=True\n",
    "\n",
    "# feedback_bits = 1024\n",
    "# SNR_dB = -25\n",
    "# v_max_km = 120\n",
    "# Q = 4\n",
    "# for SNR_dB in [-5,0]:\n",
    "#     train_Sem_E2E(N,Nc,Nr,N_r_RF,Nt,N_t_RF,L,feedback_bits,SNR_dB,v_max_km,Q,NOMA_pre, Phy_pre,feedback_bits_pre,SNR_dB_pre,v_max_km_pre,Q_pre,ITERS=600_000,b=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 测试"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.util import visualize\n",
    "import sys\n",
    "\n",
    "\n",
    "t = 0\n",
    "Nc = 100\n",
    "N = 2\n",
    "Nt = [1,8]\n",
    "Nr = [1,64]\n",
    "N_r_RF = 2\n",
    "N_t_RF = 2\n",
    "N_t = Nt[0]*Nt[1]\n",
    "N_r = Nr[0]*Nr[1]\n",
    "L = 8\n",
    "feedback_bits = 1024\n",
    "SNR_dB = -25\n",
    "v_max_km = 120\n",
    "\n",
    "Q = 4\n",
    "T = L+Q\n",
    "U = 2\n",
    "\n",
    "sys.argv = ['run.py']\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Run MFNet demo with pytorch')\n",
    "parser.add_argument('--model_name', '-M',  type=str, default='Sem_E2E')\n",
    "parser.add_argument('--gpu',        '-G',  type=int, default=0)\n",
    "args = parser.parse_args()\n",
    "model_dir = 'weights/'\n",
    "model_dir = os.path.join(model_dir, args.model_name)\n",
    "\n",
    "model_name = 'Sem_E2E'+str(SNR_dB) + '_' + str(feedback_bits)+'_L' + str(L)+'_v' + str(v_max_km)+'_Q' + str(Q)\n",
    "\n",
    "final_model_file      = os.path.join(model_dir, model_name+\"_model.pth.tar\")\n",
    "print('| running %s demo on GPU #%d with pytorch' % (args.model_name, args.gpu))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = eval(args.model_name)(Nc=Nc,N_r=N_r,N_r_RF=N_r_RF,N_t=N_t,N_t_RF=N_t_RF,L=L,feedback_bits=feedback_bits,n_class=n_class,Q=Q)\n",
    "if args.gpu >= 0: model.cuda(args.gpu)\n",
    "\n",
    "device = 0\n",
    "save_path=\"./weights/\";\n",
    "load_path=save_path+\"Sem_E2E\"+\"/\";\n",
    "dec_dict = model.state_dict()\n",
    "model_name_pre = 'Sem_E2E'+str(SNR_dB) + '_' + str(feedback_bits)+'_L' + str(L)+'_v' + str(v_max_km)+'_Q' + str(Q)\n",
    "dec_load_path=load_path+model_name_pre+\"_model.pth.tar\";\n",
    "ckpt=torch.load(dec_load_path, map_location=\"cuda:\"+str(device));\n",
    "pretrained_dict=ckpt['state_dict'];\n",
    "pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in dec_dict}\n",
    "dec_dict.update(pretrained_dict);\n",
    "model.load_state_dict(dec_dict);\n",
    "print('全部参数读取成功')\n",
    "\n",
    "files = os.listdir('image')\n",
    "images = []\n",
    "fpath  = []\n",
    "fpath_out = []\n",
    "fpath_original = []\n",
    "for file in files:\n",
    "    if file[-3:] != 'png': continue\n",
    "    fpath.append('image/'+file)\n",
    "    fpath_out.append('seg_E2E_NOMA/'+file)\n",
    "    fpath_original.append('image_original/'+file)\n",
    "    images.append( np.asarray(Image.open('image/'+file)) )\n",
    "images = np.asarray(images, dtype=np.float32).transpose((0,3,1,2))/255.\n",
    "images = Variable(torch.tensor(images))\n",
    "if args.gpu >= 0: images = images.cuda(args.gpu)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    b = images.shape[0]\n",
    "    alpha,A_r,A_t,fd,tau = SV_Channel_set(2*b,Nc,N,Nt,Nr,1,v_max_km)\n",
    "    H_batch = torch.zeros(2*b,T, Nc, N_r, N_t).cuda() + 0j\n",
    "    for i in range(T):\n",
    "        t = i*1/14000/8 #i就表示第i个OFDM符号，每个subframe时间是1ms，每个slot包含14个OFDM符号，当子载波间隔15kHz对应一个frame包含1个slot，30kHz对应2个，60kHz->4,120kHz->8,这里采用120kHz间隔所以除以8\n",
    "        H = SV_Channel_final(2*b,Nc,N,Nt,Nr,1,t,alpha,A_r,A_t,fd,tau)\n",
    "        H_batch[:,i] = H\n",
    "    H_batch_1 = H_batch[0:b]\n",
    "    H_batch_2 = H_batch[b:2*b]\n",
    "    logits,power_signal = model(H_batch_1,H_batch_2, SNR_dB, images)\n",
    "    predictions = logits.argmax(1)\n",
    "    save_images(images, fpath_original)  #保存原始图像\n",
    "    visualize(fpath_out, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 性能指标 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.util import calculate_accuracy, calculate_result\n",
    "import sys\n",
    "\n",
    "def test_Sem_E2E(N,Nc,Nr,N_r_RF,Nt,N_t_RF,L,feedback_bits,SNR_dB,v_max_km,Q):\n",
    "    N_t = Nt[0]*Nt[1]\n",
    "    N_r = Nr[0]*Nr[1]\n",
    "    \n",
    "    T = L+Q\n",
    "    U = 2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    from util.util import calculate_accuracy, calculate_result\n",
    "    import sys\n",
    "    sys.argv = ['run.py']\n",
    "\n",
    "\n",
    "\n",
    "    cf = np.zeros((n_class, n_class))\n",
    "\n",
    "\n",
    "    parser = argparse.ArgumentParser(description='Test MFNet with pytorch')\n",
    "    parser.add_argument('--model_name', '-M',  type=str, default='Sem_E2E')\n",
    "    parser.add_argument('--batch_size',  '-B',  type=int, default=16)\n",
    "    parser.add_argument('--gpu',        '-G',  type=int, default=0)\n",
    "    parser.add_argument('--num_workers', '-j',  type=int, default=0)\n",
    "    args = parser.parse_args()\n",
    "    model_dir = 'weights/'\n",
    "    model_dir = os.path.join(model_dir, args.model_name)\n",
    "\n",
    "    model_name = 'Sem_E2E'+str(SNR_dB) + '_' + str(feedback_bits)+'_L' + str(L)+'_v' + str(v_max_km)+'_Q' + str(Q)\n",
    "\n",
    "    final_model_file      = os.path.join(model_dir, model_name+\"_model.pth.tar\")\n",
    "    # print('| running %s demo on GPU #%d with pytorch' % (args.model_name, args.gpu))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    model = eval(args.model_name)(Nc=Nc,N_r=N_r,N_r_RF=N_r_RF,N_t=N_t,N_t_RF=N_t_RF,L=L,feedback_bits=feedback_bits,n_class=n_class,Q=Q)\n",
    "    if args.gpu >= 0: model.cuda(args.gpu)\n",
    "\n",
    "    device = 0\n",
    "    save_path=\"./weights/\";\n",
    "    load_path=save_path+\"Sem_E2E\"+\"/\";\n",
    "    dec_dict = model.state_dict()\n",
    "    model_name_pre = 'Sem_E2E'+str(SNR_dB) + '_' + str(feedback_bits)+'_L' + str(L)+'_v' + str(v_max_km)+'_Q' + str(Q)\n",
    "    dec_load_path=load_path+model_name_pre+\"_model.pth.tar\";\n",
    "    ckpt=torch.load(dec_load_path, map_location=\"cuda:\"+str(device));\n",
    "    pretrained_dict=ckpt['state_dict'];\n",
    "    pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in dec_dict}\n",
    "    dec_dict.update(pretrained_dict);\n",
    "    model.load_state_dict(dec_dict);\n",
    "    # print('全部参数读取成功')\n",
    "\n",
    "    test_dataset  = MF_dataset(data_dir, 'test', have_label=True)\n",
    "    test_loader  = DataLoader(\n",
    "        dataset     = test_dataset,\n",
    "        batch_size  = args.batch_size,\n",
    "        shuffle     = False,\n",
    "        num_workers = args.num_workers,\n",
    "        pin_memory  = True,\n",
    "        drop_last   = False\n",
    "    )\n",
    "    test_loader.n_iter = len(test_loader)\n",
    "\n",
    "    loss_avg = 0.\n",
    "    acc_avg  = 0.\n",
    "    model.eval()\n",
    "    results_IOU = 0\n",
    "    val_num = 5\n",
    "    with torch.no_grad():\n",
    "        for aa in range(val_num):\n",
    "            cf = np.zeros((n_class, n_class))\n",
    "            for it, (images, labels, names) in enumerate(test_loader):\n",
    "                images = Variable(images)\n",
    "                labels = Variable(labels)\n",
    "                if args.gpu >= 0:\n",
    "                    images = images.cuda(args.gpu)\n",
    "                    labels = labels.cuda(args.gpu)\n",
    "\n",
    "                b = images.shape[0]\n",
    "                alpha,A_r,A_t,fd,tau = SV_Channel_set(2*b,Nc,N,Nt,Nr,1,v_max_km)\n",
    "                H_batch = torch.zeros(2*b,T, Nc, N_r, N_t).cuda() + 0j\n",
    "                for i in range(T):\n",
    "                    t = i*1/14000/8 #i就表示第i个OFDM符号，每个subframe时间是1ms，每个slot包含14个OFDM符号，当子载波间隔15kHz对应一个frame包含1个slot，30kHz对应2个，60kHz->4,120kHz->8,这里采用120kHz间隔所以除以8\n",
    "                    H = SV_Channel_final(2*b,Nc,N,Nt,Nr,1,t,alpha,A_r,A_t,fd,tau)\n",
    "                    H_batch[:,i] = H\n",
    "                H_batch_1 = H_batch[0:b]\n",
    "                H_batch_2 = H_batch[b:2*b]\n",
    "                logits,power_signal = model(H_batch_1,H_batch_2, SNR_dB, images)\n",
    "                loss = F.cross_entropy(logits, labels)\n",
    "                acc = calculate_accuracy(logits, labels)\n",
    "                loss_avg += float(loss)\n",
    "                acc_avg  += float(acc)\n",
    "\n",
    "                # print('|- test iter %s/%s. loss: %.4f, acc: %.4f' \\\n",
    "                #         % (it+1, test_loader.n_iter, float(loss), float(acc)))\n",
    "\n",
    "                predictions = logits.argmax(1)\n",
    "                for gtcid in range(n_class): \n",
    "                    for pcid in range(n_class):\n",
    "                        gt_mask      = labels == gtcid \n",
    "                        pred_mask    = predictions == pcid\n",
    "                        intersection = gt_mask * pred_mask\n",
    "                        cf[gtcid, pcid] += int(intersection.sum())\n",
    "\n",
    "            overall_acc, acc, IoU = calculate_result(cf)\n",
    "            results_IOU += IoU.mean()/val_num\n",
    "\n",
    "    # print('| overall accuracy:', overall_acc)\n",
    "    # print('| accuracy of each class:', acc)\n",
    "    # print('| class accuracy avg:', acc.mean())\n",
    "    # print('| IoU:', IoU)\n",
    "    print('| class IoU avg:', results_IOU)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 0\n",
    "Nc = 100\n",
    "N = 2\n",
    "Nt = [1,8]\n",
    "Nr = [1,64]\n",
    "N_r_RF = 2\n",
    "N_t_RF = 2\n",
    "\n",
    "L = 8\n",
    "\n",
    "feedback_bits_pre = None\n",
    "SNR_dB_pre = None\n",
    "v_max_km_pre = None\n",
    "Q_pre = None\n",
    "\n",
    "NOMA_pre=True\n",
    "Phy_pre=True\n",
    "\n",
    "feedback_bits = 1024\n",
    "SNR_dB = -25\n",
    "v_max_km = 120\n",
    "Q = 4\n",
    "for L in [1,2,4,8]:   #L=1的时候MIOU为0，所以模型没有保存，这里直接放弃掉，根据Q=4推算大概在0.13左右\n",
    "    test_Sem_E2E(N,Nc,Nr,N_r_RF,Nt,N_t_RF,L,feedback_bits,SNR_dB,v_max_km,Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 0\n",
    "Nc = 100\n",
    "N = 2\n",
    "Nt = [1,8]\n",
    "Nr = [1,64]\n",
    "N_r_RF = 2\n",
    "N_t_RF = 2\n",
    "\n",
    "L = 8\n",
    "\n",
    "feedback_bits_pre = None\n",
    "SNR_dB_pre = None\n",
    "v_max_km_pre = None\n",
    "Q_pre = None\n",
    "\n",
    "NOMA_pre=True\n",
    "Phy_pre=True\n",
    "\n",
    "feedback_bits = 1024\n",
    "SNR_dB = -25\n",
    "v_max_km = 120\n",
    "Q = 1\n",
    "for L in [1,2,4,8]:   #L=1的时候MIOU为0，所以模型没有保存，这里直接放弃掉，根据Q=4推算大概在0.13左右\n",
    "    test_Sem_E2E(N,Nc,Nr,N_r_RF,Nt,N_t_RF,L,feedback_bits,SNR_dB,v_max_km,Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 0\n",
    "Nc = 100\n",
    "N = 2\n",
    "Nt = [1,8]\n",
    "Nr = [1,64]\n",
    "N_r_RF = 2\n",
    "N_t_RF = 2\n",
    "\n",
    "L = 8\n",
    "\n",
    "feedback_bits_pre = None\n",
    "SNR_dB_pre = None\n",
    "v_max_km_pre = None\n",
    "Q_pre = None\n",
    "\n",
    "NOMA_pre=True\n",
    "Phy_pre=True\n",
    "\n",
    "feedback_bits = 1024\n",
    "SNR_dB = -25\n",
    "v_max_km = 120\n",
    "Q = 4\n",
    "for feedback_bits in [4,16,64,256,1024]:\n",
    "    test_Sem_E2E(N,Nc,Nr,N_r_RF,Nt,N_t_RF,L,feedback_bits,SNR_dB,v_max_km,Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 0\n",
    "Nc = 100\n",
    "N = 2\n",
    "Nt = [1,8]\n",
    "Nr = [1,64]\n",
    "N_r_RF = 2\n",
    "N_t_RF = 2\n",
    "\n",
    "L = 8\n",
    "\n",
    "feedback_bits_pre = None\n",
    "SNR_dB_pre = None\n",
    "v_max_km_pre = None\n",
    "Q_pre = None\n",
    "\n",
    "NOMA_pre=True\n",
    "Phy_pre=True\n",
    "\n",
    "feedback_bits = 1024\n",
    "SNR_dB = -25\n",
    "v_max_km = 120\n",
    "Q = 1\n",
    "for feedback_bits in [4,16,64,256,1024]:\n",
    "    test_Sem_E2E(N,Nc,Nr,N_r_RF,Nt,N_t_RF,L,feedback_bits,SNR_dB,v_max_km,Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 0\n",
    "Nc = 100\n",
    "N = 2\n",
    "Nt = [1,8]\n",
    "Nr = [1,64]\n",
    "N_r_RF = 2\n",
    "N_t_RF = 2\n",
    "\n",
    "L = 8\n",
    "\n",
    "feedback_bits_pre = None\n",
    "SNR_dB_pre = None\n",
    "v_max_km_pre = None\n",
    "Q_pre = None\n",
    "\n",
    "NOMA_pre=True\n",
    "Phy_pre=True\n",
    "\n",
    "feedback_bits = 1024\n",
    "SNR_dB = -25\n",
    "v_max_km = 120\n",
    "Q = 1\n",
    "for Q in [1,2,3,4,5]:\n",
    "    test_Sem_E2E(N,Nc,Nr,N_r_RF,Nt,N_t_RF,L,feedback_bits,SNR_dB,v_max_km,Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 0\n",
    "Nc = 100\n",
    "N = 2\n",
    "Nt = [1,8]\n",
    "Nr = [1,64]\n",
    "N_r_RF = 2\n",
    "N_t_RF = 2\n",
    "\n",
    "L = 8\n",
    "\n",
    "feedback_bits_pre = None\n",
    "SNR_dB_pre = None\n",
    "v_max_km_pre = None\n",
    "Q_pre = None\n",
    "\n",
    "NOMA_pre=True\n",
    "Phy_pre=True\n",
    "\n",
    "feedback_bits = 1024\n",
    "SNR_dB = -25\n",
    "v_max_km = 120\n",
    "Q = 4\n",
    "for SNR_dB in [-40,-35,-30,-25,-20,-15,-10]:\n",
    "    test_Sem_E2E(N,Nc,Nr,N_r_RF,Nt,N_t_RF,L,feedback_bits,SNR_dB,v_max_km,Q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基线（E2E正交设计）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 预训练OMA的语义提取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBnLeakyRelu2d(nn.Module):\n",
    "    # convolution\n",
    "    # batch normalization\n",
    "    # leaky relu\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, padding=1, stride=1, dilation=1, groups=1):\n",
    "        super(ConvBnLeakyRelu2d, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, padding=padding, stride=stride, dilation=dilation, groups=groups)\n",
    "        self.bn   = nn.BatchNorm2d(out_channels)\n",
    "    def forward(self, x):\n",
    "        return F.leaky_relu(self.bn(self.conv(x)), negative_slope=0.2)\n",
    "\n",
    "\n",
    "class MiniInception(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(MiniInception, self).__init__()\n",
    "        self.conv1_left  = ConvBnLeakyRelu2d(in_channels,   out_channels//2)\n",
    "        self.conv1_right = ConvBnLeakyRelu2d(in_channels,   out_channels//2, padding=2, dilation=2)\n",
    "        self.conv2_left  = ConvBnLeakyRelu2d(out_channels,  out_channels//2)\n",
    "        self.conv2_right = ConvBnLeakyRelu2d(out_channels,  out_channels//2, padding=2, dilation=2)\n",
    "        self.conv3_left  = ConvBnLeakyRelu2d(out_channels,  out_channels//2)\n",
    "        self.conv3_right = ConvBnLeakyRelu2d(out_channels,  out_channels//2, padding=2, dilation=2)\n",
    "    def forward(self,x):\n",
    "        x = torch.cat((self.conv1_left(x), self.conv1_right(x)), dim=1)\n",
    "        x = torch.cat((self.conv2_left(x), self.conv2_right(x)), dim=1)\n",
    "        x = torch.cat((self.conv3_left(x), self.conv3_right(x)), dim=1)\n",
    "        return x\n",
    "\n",
    "\n",
    "class MFNet_Enc_rgb_OMA(nn.Module):\n",
    "\n",
    "    def __init__(self, ):\n",
    "        super(MFNet_Enc_rgb_OMA, self).__init__()\n",
    "        rgb_ch = [16,48,48,96,192]\n",
    "        # self.pho = 2\n",
    "        # inf_ch = [16,48,48,96,96]\n",
    "        compress_ch = [192,96,96,C_dim]\n",
    "        self.compress_ch = compress_ch\n",
    "        out_dim = 2400\n",
    "\n",
    "        self.conv1_rgb   = ConvBnLeakyRelu2d(3, rgb_ch[0])\n",
    "        self.conv2_1_rgb = ConvBnLeakyRelu2d(rgb_ch[0], rgb_ch[1])\n",
    "        self.conv2_2_rgb = ConvBnLeakyRelu2d(rgb_ch[1], rgb_ch[1])\n",
    "        self.conv3_1_rgb = ConvBnLeakyRelu2d(rgb_ch[1], rgb_ch[2])\n",
    "        self.conv3_2_rgb = ConvBnLeakyRelu2d(rgb_ch[2], rgb_ch[2])\n",
    "        self.conv4_rgb   = MiniInception(rgb_ch[2], rgb_ch[3])\n",
    "        self.conv5_rgb   = MiniInception(rgb_ch[3], rgb_ch[4])\n",
    "        self.compress_1_rgb = ConvBnLeakyRelu2d(compress_ch[0], compress_ch[1])\n",
    "        self.compress_2_rgb = ConvBnLeakyRelu2d(compress_ch[1], compress_ch[2])\n",
    "        self.compress_3_rgb = ConvBnLeakyRelu2d(compress_ch[2], compress_ch[3])\n",
    "    def forward(self, x):\n",
    "        # split data into RGB and INF\n",
    "        x_rgb = x[:,:3]\n",
    "\n",
    "        # encode\n",
    "        x_rgb    = self.conv1_rgb(x_rgb)\n",
    "        x_rgb    = F.max_pool2d(x_rgb, kernel_size=2, stride=2) # pool1\n",
    "        x_rgb    = self.conv2_1_rgb(x_rgb)\n",
    "        x_rgb_p2 = self.conv2_2_rgb(x_rgb)\n",
    "        x_rgb    = F.max_pool2d(x_rgb_p2, kernel_size=2, stride=2) # pool2\n",
    "        x_rgb    = self.conv3_1_rgb(x_rgb)\n",
    "        x_rgb_p3 = self.conv3_2_rgb(x_rgb)\n",
    "        x_rgb    = F.max_pool2d(x_rgb_p3, kernel_size=2, stride=2) # pool3\n",
    "        x_rgb_p4 = self.conv4_rgb(x_rgb)\n",
    "        x_rgb    = F.max_pool2d(x_rgb_p4, kernel_size=2, stride=2) # pool4 #[batch,2,30,40]\n",
    "        x_rgb    = self.conv5_rgb(x_rgb)  #[batch,96,30,40]\n",
    "        x_rgb    = F.max_pool2d(x_rgb, kernel_size=(6,4), stride=(6,4)) # pool5  \n",
    "\n",
    "        x_rgb    = self.compress_1_rgb(x_rgb)  \n",
    "        x_rgb    = self.compress_2_rgb(x_rgb)\n",
    "        x_rgb    = self.compress_3_rgb(x_rgb) #[batch,C_dim,5,10]\n",
    "        return x_rgb\n",
    "\n",
    "\n",
    "class MFNet_Enc_inf_OMA(nn.Module):\n",
    "\n",
    "    def __init__(self, ):\n",
    "        super(MFNet_Enc_inf_OMA, self).__init__()\n",
    "        rgb_ch = [16,48,48,96,192]\n",
    "        # self.pho = 2\n",
    "        # inf_ch = [16,48,48,96,96]\n",
    "        # 压缩后的每个样本维度为[2，30，40]我们正好可以设置为单流2个实虚部组成的2、30个子载波和40个OFDM符号\n",
    "        compress_ch = [192,96,96,C_dim]\n",
    "        self.compress_ch = compress_ch\n",
    "        out_dim = 2400\n",
    "\n",
    "        self.conv1_inf   = ConvBnLeakyRelu2d(1, rgb_ch[0])\n",
    "        self.conv2_1_inf = ConvBnLeakyRelu2d(rgb_ch[0], rgb_ch[1])\n",
    "        self.conv2_2_inf = ConvBnLeakyRelu2d(rgb_ch[1], rgb_ch[1])\n",
    "        self.conv3_1_inf = ConvBnLeakyRelu2d(rgb_ch[1], rgb_ch[2])\n",
    "        self.conv3_2_inf = ConvBnLeakyRelu2d(rgb_ch[2], rgb_ch[2])\n",
    "        self.conv4_inf   = MiniInception(rgb_ch[2], rgb_ch[3])\n",
    "        self.conv5_inf   = MiniInception(rgb_ch[3], rgb_ch[4])\n",
    "        self.compress_1_inf = ConvBnLeakyRelu2d(compress_ch[0], compress_ch[1])\n",
    "        self.compress_2_inf = ConvBnLeakyRelu2d(compress_ch[1], compress_ch[2])\n",
    "        self.compress_3_inf = ConvBnLeakyRelu2d(compress_ch[2], compress_ch[3])\n",
    "    def forward(self, x):\n",
    "        # split data into RGB and INF\n",
    "        x_inf = x[:,3:]\n",
    "\n",
    "        # encode\n",
    "        x_inf    = self.conv1_inf(x_inf)\n",
    "        x_inf    = F.max_pool2d(x_inf, kernel_size=2, stride=2) # pool1\n",
    "        x_inf    = self.conv2_1_inf(x_inf)\n",
    "        x_inf_p2 = self.conv2_2_inf(x_inf)\n",
    "        x_inf    = F.max_pool2d(x_inf_p2, kernel_size=2, stride=2) # pool2\n",
    "        x_inf    = self.conv3_1_inf(x_inf)\n",
    "        x_inf_p3 = self.conv3_2_inf(x_inf)\n",
    "        x_inf    = F.max_pool2d(x_inf_p3, kernel_size=2, stride=2) # pool3\n",
    "        x_inf_p4 = self.conv4_inf(x_inf)\n",
    "        x_inf    = F.max_pool2d(x_inf_p4, kernel_size=2, stride=2) # pool4 #[batch,96,30,40]\n",
    "        x_inf    = self.conv5_inf(x_inf)\n",
    "        x_inf    = F.max_pool2d(x_inf, kernel_size=(6,4), stride=(6,4)) # pool5  \n",
    "\n",
    "        x_inf    = self.compress_1_inf(x_inf)  \n",
    "        x_inf    = self.compress_2_inf(x_inf)  \n",
    "        x_inf    = self.compress_3_inf(x_inf)    #[batch,C_dim,5,10]\n",
    "        return x_inf\n",
    "\n",
    "class MFNet_Dec_OMA(nn.Module):\n",
    "\n",
    "    def __init__(self, n_class):\n",
    "        super(MFNet_Dec_OMA, self).__init__()\n",
    "        rgb_ch = [16,48,48,96,192]\n",
    "        # self.pho = 2\n",
    "        # inf_ch = [16,48,48,96,96]\n",
    "        # 压缩后的每个样本维度为 #[C_dim,10,10]我们keyi\n",
    "        compress_ch = [192,96,96,C_dim]\n",
    "        self.compress_ch = compress_ch\n",
    "        out_dim = 2400\n",
    "\n",
    "        self.decompress_3 = ConvBnLeakyRelu2d(compress_ch[3], compress_ch[2])\n",
    "        self.decompress_2 = ConvBnLeakyRelu2d(compress_ch[2], compress_ch[1])\n",
    "        self.decompress_1 = ConvBnLeakyRelu2d(compress_ch[1], compress_ch[0])\n",
    "\n",
    "\n",
    "        self.decode5     = ConvBnLeakyRelu2d(rgb_ch[4], rgb_ch[3])\n",
    "        self.decode4     = ConvBnLeakyRelu2d(rgb_ch[3], rgb_ch[2])\n",
    "        self.decode3     = ConvBnLeakyRelu2d(rgb_ch[2], rgb_ch[1])\n",
    "        self.decode2     = ConvBnLeakyRelu2d(rgb_ch[1], rgb_ch[0])\n",
    "        self.decode1     = ConvBnLeakyRelu2d(rgb_ch[0], n_class)\n",
    "    def forward(self, x):\n",
    "        #[batch,8,30,40]\n",
    "        # x = self.decompress_4(x)\n",
    "        # x = x.reshape(-1,8,self.pho,15,20).permute(0,2,1,3,4)\n",
    "        # x = x.reshape(-1,self.pho*8,15,20)\n",
    "        # x = self.decompress_4(x.permute(0,1,3,2)).permute(0,1,3,2)\n",
    "        x = self.decompress_3(x)\n",
    "        x = self.decompress_2(x)\n",
    "        x = self.decompress_1(x) #[batch,96,5,10]\n",
    "\n",
    "        # decode\n",
    "        x = F.interpolate(x, scale_factor=(6,4), mode='nearest')# unpool5\n",
    "        x = self.decode5(x)\n",
    "        x = F.upsample(x, scale_factor=2, mode='nearest') # unpool4\n",
    "        x = self.decode4(x)\n",
    "        x = F.upsample(x, scale_factor=2, mode='nearest') # unpool3\n",
    "        x = self.decode3(x)\n",
    "        x = F.upsample(x, scale_factor=2, mode='nearest') # unpool2\n",
    "        x = self.decode2(x)\n",
    "        x = F.upsample(x, scale_factor=2, mode='nearest') # unpool1\n",
    "        x = self.decode1(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "class MFNet_OMA(nn.Module):\n",
    "\n",
    "    def __init__(self, n_class):\n",
    "        super(MFNet_OMA, self).__init__()\n",
    "        self.enc_rgb = MFNet_Enc_rgb_OMA()\n",
    "        self.enc_inf = MFNet_Enc_inf_OMA()\n",
    "        self.dec = MFNet_Dec_OMA(n_class)\n",
    "        \n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x_rgb = self.enc_rgb(x)\n",
    "        x_inf = self.enc_inf(x)\n",
    "        x = x_rgb + x_inf \n",
    "        x = self.dec(x)\n",
    "        return x\n",
    "        # x_rgb = self.enc_rgb(x) \n",
    "        # x_rgb = x_rgb[:,0] + 1j*x_rgb[:,1]\n",
    "        # x_rgb = x_rgb * (torch.randn(x.shape[0],1,40) + 1j*torch.randn(x.shape[0],1,40)).cuda()\n",
    "        # x_inf = self.enc_inf(x)\n",
    "        # x_inf = x_inf[:,0] + 1j*x_inf[:,1]\n",
    "        # x_inf = x_inf * (torch.randn(x.shape[0],1,40) + 1j*torch.randn(x.shape[0],1,40)).cuda()\n",
    "        # x = x_rgb + x_inf \n",
    "        # x = x.reshape(-1,1,30,40)\n",
    "        # x = torch.cat([x.real,x.imag],dim=1)\n",
    "        # x = self.dec(x)\n",
    "        # return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.argv = ['run.py']\n",
    "parser = argparse.ArgumentParser(description='Train MFNet with pytorch')\n",
    "parser.add_argument('--model_name',  '-M',  type=str, default='MFNet_OMA')\n",
    "parser.add_argument('--batch_size',  '-B',  type=int, default=8)\n",
    "\n",
    "parser.add_argument('--epoch_max' ,  '-E',  type=int, default=100)\n",
    "# parser.add_argument('--epoch_max' ,  '-E',  type=int, default=2)\n",
    "\n",
    "parser.add_argument('--epoch_from',  '-EF', type=int, default=1)\n",
    "parser.add_argument('--gpu',         '-G',  type=int, default=0)\n",
    "parser.add_argument('--num_workers', '-j',  type=int, default=0)\n",
    "args = parser.parse_args()\n",
    "model_dir = 'weights/'\n",
    "model_dir = os.path.join(model_dir, args.model_name)\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "checkpoint_model_file = os.path.join(model_dir, 'tmp_pretrain1.pth')\n",
    "checkpoint_optim_file = os.path.join(model_dir, 'tmp_pretrain1.optim')\n",
    "final_model_file      = os.path.join(model_dir, 'final_pretrain1_C4.pth')\n",
    "log_file              = os.path.join(model_dir, 'log_pretrain1.txt')\n",
    "\n",
    "print('| training %s on GPU #%d with pytorch' % (args.model_name, args.gpu))\n",
    "print('| from epoch %d / %s' % (args.epoch_from, args.epoch_max))\n",
    "print('| model will be saved in: %s' % model_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = eval(args.model_name)(n_class=n_class)\n",
    "if args.gpu >= 0: model.cuda(args.gpu)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr_start, momentum=0.9, weight_decay=0.0005) \n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=lr_start)\n",
    "\n",
    "if args.epoch_from > 1:\n",
    "    print('| loading checkpoint file %s... ' % checkpoint_model_file, end='')\n",
    "    model.load_state_dict(torch.load(checkpoint_model_file, map_location='cuda:0'))\n",
    "    optimizer.load_state_dict(torch.load(checkpoint_optim_file))\n",
    "    print('done!')\n",
    "\n",
    "train_dataset = MF_dataset(data_dir, 'train', have_label=True, transform=augmentation_methods)\n",
    "val_dataset  = MF_dataset(data_dir, 'val', have_label=True)\n",
    "\n",
    "train_loader  = DataLoader(\n",
    "    dataset     = train_dataset,\n",
    "    batch_size  = args.batch_size,\n",
    "    shuffle     = True,\n",
    "    num_workers = args.num_workers,\n",
    "    pin_memory  = True,\n",
    "    drop_last   = True\n",
    ")\n",
    "val_loader  = DataLoader(\n",
    "    dataset     = val_dataset,\n",
    "    batch_size  = args.batch_size,\n",
    "    shuffle     = False,\n",
    "    num_workers = args.num_workers,\n",
    "    pin_memory  = True,\n",
    "    drop_last   = False\n",
    ")\n",
    "train_loader.n_iter = len(train_loader)\n",
    "val_loader.n_iter   = len(val_loader)\n",
    "\n",
    "for epo in (range(args.epoch_from, args.epoch_max+1)):\n",
    "    print('\\n| epo #%s begin...' % epo)\n",
    "\n",
    "    train(epo, model, train_loader, optimizer)\n",
    "    validation(epo, model, val_loader)\n",
    "\n",
    "    # save check point model\n",
    "    # print('| saving check point model file... ', end='')\n",
    "    torch.save(model.state_dict(), checkpoint_model_file)\n",
    "    torch.save(optimizer.state_dict(), checkpoint_optim_file)\n",
    "    # print('done!')\n",
    "if os.path.exists(final_model_file):\n",
    "    os.remove(final_model_file) # 删除已存在的文件\n",
    "os.rename(checkpoint_model_file, final_model_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 测试"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.util import visualize\n",
    "import sys\n",
    "\n",
    "sys.argv = ['run.py']\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Run MFNet demo with pytorch')\n",
    "parser.add_argument('--model_name', '-M',  type=str, default='MFNet_OMA')\n",
    "parser.add_argument('--gpu',        '-G',  type=int, default=0)\n",
    "args = parser.parse_args()\n",
    "model_dir = 'weights/'\n",
    "model_dir = os.path.join(model_dir, args.model_name)\n",
    "\n",
    "checkpoint_model_file = os.path.join(model_dir, 'tmp_pretrain1.pth')\n",
    "final_model_file      = os.path.join(model_dir, 'final_pretrain1_C4.pth')\n",
    "print('| running %s demo on GPU #%d with pytorch' % (args.model_name, args.gpu))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = eval(args.model_name)(n_class=n_class)\n",
    "if args.gpu >= 0: model.cuda(args.gpu)\n",
    "if os.path.exists(final_model_file):\n",
    "    model.load_state_dict(torch.load(final_model_file, map_location='cuda:0'))\n",
    "elif os.path.exists(checkpoint_model_file):\n",
    "    model.load_state_dict(torch.load(checkpoint_model_file, map_location='cuda:0'))\n",
    "else:\n",
    "    raise Exception('| model file do not exists in %s' % model_dir)\n",
    "print('| model loaded!')\n",
    "\n",
    "files = os.listdir('image')\n",
    "images = []\n",
    "fpath  = []\n",
    "fpath_out = []\n",
    "fpath_original = []\n",
    "for file in files:\n",
    "    if file[-3:] != 'png': continue\n",
    "    fpath.append('image/'+file)\n",
    "    fpath_out.append('seg_MFNet_OMA/'+file)\n",
    "    fpath_original.append('image_original/'+file)\n",
    "    images.append( np.asarray(Image.open('image/'+file)) )\n",
    "images = np.asarray(images, dtype=np.float32).transpose((0,3,1,2))/255.\n",
    "images = Variable(torch.tensor(images))\n",
    "if args.gpu >= 0: images = images.cuda(args.gpu)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    logits = model(images)\n",
    "    predictions = logits.argmax(1)\n",
    "    save_images(images, fpath_original)  #保存原始图像\n",
    "    visualize(fpath_out, predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 性能指标"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.util import calculate_accuracy, calculate_result\n",
    "import sys\n",
    "\n",
    "sys.argv = ['run.py']\n",
    "\n",
    "\n",
    "cf = np.zeros((n_class, n_class))\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Test MFNet with pytorch')\n",
    "parser.add_argument('--model_name', '-M',  type=str, default='MFNet_OMA')\n",
    "parser.add_argument('--batch_size',  '-B',  type=int, default=16)\n",
    "parser.add_argument('--gpu',        '-G',  type=int, default=0)\n",
    "parser.add_argument('--num_workers', '-j',  type=int, default=0)\n",
    "\n",
    "\n",
    "\n",
    "args = parser.parse_args()\n",
    "model_dir = 'weights/'\n",
    "model_dir = os.path.join(model_dir, args.model_name)\n",
    "\n",
    "checkpoint_model_file = os.path.join(model_dir, 'tmp_pretrain1.pth')\n",
    "final_model_file      = os.path.join(model_dir, 'final_pretrain1_C4.pth')\n",
    "print('| testing %s on GPU #%d with pytorch' % (args.model_name, args.gpu))\n",
    "\n",
    "model = eval(args.model_name)(n_class=n_class)\n",
    "if args.gpu >= 0: model.cuda(args.gpu)\n",
    "if os.path.exists(final_model_file):\n",
    "    model.load_state_dict(torch.load(final_model_file, map_location='cuda:0'))\n",
    "elif os.path.exists(checkpoint_model_file):\n",
    "    model.load_state_dict(torch.load(checkpoint_model_file, map_location='cuda:0'))\n",
    "else:\n",
    "    raise Exception('| model file do not exists in %s' % model_dir)\n",
    "print('| model loaded!')\n",
    "\n",
    "\n",
    "test_dataset  = MF_dataset(data_dir, 'test', have_label=True)\n",
    "test_loader  = DataLoader(\n",
    "    dataset     = test_dataset,\n",
    "    batch_size  = args.batch_size,\n",
    "    shuffle     = False,\n",
    "    num_workers = args.num_workers,\n",
    "    pin_memory  = True,\n",
    "    drop_last   = False\n",
    ")\n",
    "test_loader.n_iter = len(test_loader)\n",
    "\n",
    "loss_avg = 0.\n",
    "acc_avg  = 0.\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for it, (images, labels, names) in enumerate(test_loader):\n",
    "        images = Variable(images)\n",
    "        labels = Variable(labels)\n",
    "        if args.gpu >= 0:\n",
    "            images = images.cuda(args.gpu)\n",
    "            labels = labels.cuda(args.gpu)\n",
    "\n",
    "        logits = model(images)\n",
    "        loss = F.cross_entropy(logits, labels)\n",
    "        acc = calculate_accuracy(logits, labels)\n",
    "        loss_avg += float(loss)\n",
    "        acc_avg  += float(acc)\n",
    "\n",
    "        print('|- test iter %s/%s. loss: %.4f, acc: %.4f' \\\n",
    "                % (it+1, test_loader.n_iter, float(loss), float(acc)))\n",
    "\n",
    "        predictions = logits.argmax(1)\n",
    "        for gtcid in range(n_class): \n",
    "            for pcid in range(n_class):\n",
    "                gt_mask      = labels == gtcid \n",
    "                pred_mask    = predictions == pcid\n",
    "                intersection = gt_mask * pred_mask\n",
    "                cf[gtcid, pcid] += int(intersection.sum())\n",
    "\n",
    "overall_acc, acc, IoU = calculate_result(cf)\n",
    "\n",
    "print('| overall accuracy:', overall_acc)\n",
    "print('| accuracy of each class:', acc)\n",
    "print('| class accuracy avg:', acc.mean())\n",
    "print('| IoU:', IoU)\n",
    "print('| class IoU avg:', IoU.mean())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 信源信道语义融合联合训练（E2E正交）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 网络和训练函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sem_fusion_OMA(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            C_out,     #输出通道数\n",
    "        ):\n",
    "        super(Sem_fusion_OMA, self).__init__()\n",
    "    \n",
    "        self.B = 4  #量化精度\n",
    "        self.C_out = C_out\n",
    "        self.CSI_dim = 16\n",
    "        self.d_model = 128\n",
    "\n",
    "\n",
    "\n",
    "        # self.trans  = TRANS_BLOCK(tx*2,tx*2,512,4)\n",
    "\n",
    "        self.embed_CSI=nn.Sequential(  \n",
    "            ReshapeLayer([-1, Nc*d_sem]),  \n",
    "            nn.Linear(Nc*d_sem, self.CSI_dim),  \n",
    "        );\n",
    "\n",
    "\n",
    "        \n",
    "    \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(in_features=C_dim+self.CSI_dim, out_features=C_dim),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(in_features=C_dim, out_features=C_dim),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "        self.head=nn.Sequential(  \n",
    "            nn.Linear(C_dim, C_out),\n",
    "\n",
    "        );\n",
    "    \n",
    "    \n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "    def forward(\n",
    "            self, \n",
    "            x_sem,   # b， C_dim, 5, 10  #语义编码结果\n",
    "            CSI_sem,  # b, Nc, d_sem   #反馈比特\n",
    "        ):\n",
    "        x_CSI = self.embed_CSI(CSI_sem) # b, 16\n",
    "        x_ini = torch.mean(x_sem, dim=(2, 3)) # b, C_dim\n",
    "        context_input = torch.cat([x_CSI,x_ini],dim=1) # b, C_dim + 16\n",
    "\n",
    "        mask = self.layers(context_input).view(-1, C_dim, 1, 1)\n",
    "\n",
    "        x = mask * x_sem  # b， C_dim, 5, 10  #语义编码结果\n",
    "\n",
    "        x = x.permute(0,2,3,1) # b, 5, 10, C_dim\n",
    "        x = self.head(x)     # b, 5, 10, C_out\n",
    "        \n",
    "\n",
    "        return x # b, 5, 10, C_out  #语义融合结果\n",
    "\n",
    "# Q的数量为C_out/2/N_rf*40，根据要的Q以及N_rf反推出所需的C_out\n",
    "\n",
    "class Sem_E2E_OMA(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            Nc,     #子载波数\n",
    "            N_r,    #基站接收天线数\n",
    "            N_r_RF, #基站射频数\n",
    "            N_t,    #用户发送天线数\n",
    "            N_t_RF, #用户发送射频数\n",
    "            L,      #导频OFDM符号数\n",
    "            feedback_bits,  #反馈比特数\n",
    "            n_class,#类别数\n",
    "            Q,      #传输数据符号数\n",
    "        ):\n",
    "        super(Sem_E2E_OMA, self).__init__()\n",
    "        self.N_r_RF = N_r_RF\n",
    "        self.N_t_RF = N_t_RF\n",
    "        self.Nc = Nc\n",
    "\n",
    "        self.Q = Q\n",
    "        self.C_out = Q*2*N_t_RF\n",
    "        self.MFNet = MFNet_OMA(n_class)\n",
    "        self.physical = physical_E2E(Nc,N_r, N_r_RF,N_t,N_t_RF,L,feedback_bits)\n",
    "        self.fusion_1 = Sem_fusion_OMA(self.C_out)\n",
    "        self.fusion_2 = Sem_fusion_OMA(self.C_out)\n",
    "\n",
    "        # self.embed_1 = nn.Linear(C_dim, self.C_out)\n",
    "        # self.embed_2 = nn.Linear(C_dim, self.C_out)\n",
    "\n",
    "        self.Dembed=nn.Linear(Q*2*N_r_RF, C_dim)\n",
    "        self.fusion_3 = Sem_fusion_OMA(C_dim)\n",
    "        \n",
    "\n",
    "    def forward(\n",
    "            self, \n",
    "            H_batch_1,  # b,T, Nc, N_r, N_t  T就是L+Q\n",
    "            H_batch_2,  # b,T, Nc, N_r, N_t\n",
    "            SNR_dB_Sem, \n",
    "            x, # \n",
    "        ):\n",
    "        Q = self.Q\n",
    "        Nc = self.Nc\n",
    "        C_out = self.C_out\n",
    "        N_t_RF = self.N_t_RF\n",
    "        # split data into RGB and INF\n",
    "        x_rgb = self.MFNet.enc_rgb(x) # [batch,C_dim,5,10]\n",
    "        x_inf = self.MFNet.enc_inf(x) # [batch,C_dim,5,10]\n",
    "\n",
    "        \n",
    "\n",
    "        W,F_1,F_2,CSI_sem_UE_1,CSI_sem_UE_2,CSI_sem_BS = self.physical(H_batch_1,H_batch_2)\n",
    "\n",
    "\n",
    "        # Calculate effective channel\n",
    "        b,_,N_r_RF,N_r = W.shape\n",
    "        N_t = F_1.shape[2]\n",
    "        H_eff_1 = W.reshape(b,1,1,N_r_RF,N_r) @ H_batch_1[:,L:(L+Q)] @ F_1.reshape(b,1,1,N_t,N_t_RF) #H [batch,Q,Nc,N_r_RF,N_t_RF]\n",
    "        H_eff_2 = W.reshape(b,1,1,N_r_RF,N_r) @ H_batch_2[:,L:(L+Q)] @ F_2.reshape(b,1,1,N_t,N_t_RF) #H [batch,Q,Nc,N_r_RF,N_t_RF]\n",
    "\n",
    "        #把bits和x融合\n",
    "        x_1 = self.fusion_1(x_rgb,CSI_sem_BS)  # [batch,5,10,C_out]\n",
    "        x_2 = self.fusion_2(x_inf,CSI_sem_BS)  # [batch,5,10,C_out]\n",
    "\n",
    "        # x_1 = self.embed_1(x_rgb.permute(0,2,3,1))  # [batch,5,10,C_out]\n",
    "        # x_2 = self.embed_2(x_inf.permute(0,2,3,1))  # [batch,5,10,C_out]\n",
    "\n",
    "        sigma = 10**(-SNR_dB_Sem/10)\n",
    "\n",
    "        x1 = x_1.reshape(b,Nc//2,Q,N_t_RF,1,2) #b,Nc//2,Q,N_t_RF,1,2\n",
    "        x1 = x1.permute(0,2,1,3,4,5)  #b,Q,Nc//2,N_t_RF,1,2\n",
    "        x1 = x1[:,:,:,:,:,0] + 1j*x1[:,:,:,:,:,0] #b,Q,Nc//2,N_t_RF,1\n",
    "        norm_factor = torch.sqrt(torch.sum(torch.abs(x1)**2, dim=(-4,-3,-2, -1), keepdim=True))\n",
    "        x1 = x1 / norm_factor * torch.sqrt(torch.tensor(Q*Nc//2*N_t_RF, dtype=H_batch_1.dtype, device=H_batch_1.device))\n",
    "        x1 = H_eff_1[:,:,0::2] @ x1           #b,Q,Nc//2,N_r_RF,1\n",
    "        n = (torch.randn(b,Q,Nc//2,N_r_RF,1).cuda() + 1j*torch.randn(b,Q,Nc//2,N_r_RF,1).cuda())/sqrt(2)*sqrt(sigma)\n",
    "        x1 = x1 + n # b,Q,Nc//2,N_r_RF,1\n",
    "\n",
    "        x2 = x_2.reshape(b,Nc//2,Q,N_t_RF,1,2) #b,Nc//2,Q,N_t_RF,1,2\n",
    "        x2 = x2.permute(0,2,1,3,4,5)  #b,Q,Nc//2,N_t_RF,1,2\n",
    "        x2 = x2[:,:,:,:,:,0] + 1j*x2[:,:,:,:,:,0] #b,Q,Nc//2,N_t_RF,1\n",
    "        norm_factor = torch.sqrt(torch.sum(torch.abs(x2)**2, dim=(-4,-3,-2, -1), keepdim=True))\n",
    "        x2 = x2 / norm_factor * torch.sqrt(torch.tensor(Q*Nc//2*N_t_RF, dtype=H_batch_1.dtype, device=H_batch_1.device))\n",
    "        x2 = H_eff_2[:,:,1::2] @ x2           #b,Q,Nc//2,N_r_RF,1\n",
    "        n = (torch.randn(b,Q,Nc//2,N_r_RF,1).cuda() + 1j*torch.randn(b,Q,Nc//2,N_r_RF,1).cuda())/sqrt(2)*sqrt(sigma)\n",
    "        x2 = x2 + n # b,Q,Nc//2,N_r_RF,1\n",
    "\n",
    "        x = x1 + x2 # b,Q,Nc//2,N_r_RF,1\n",
    "\n",
    "        \n",
    "        norm_factor = torch.sqrt(torch.sum(torch.abs(x)**2, dim=(-4,-3,-2, -1), keepdim=True))\n",
    "        x = x / norm_factor * torch.sqrt(torch.tensor(Q*Nc*N_r_RF//2, dtype=H_batch_1.dtype, device=H_batch_1.device)) # b,Q,Nc,1,1\n",
    "\n",
    "        \n",
    "        x = torch.cat([x.real,x.imag],dim=-1) # b,Q,Nc//2,N_r_RF,2\n",
    "        x = x.permute(0,2,1,3,4) # b,Nc//2,Q,N_r_RF,2\n",
    "        x = x.reshape(b,5,10,Q*2*N_r_RF)\n",
    "        x = self.Dembed(x) #b, 5,10,C_dim\n",
    "        x = x.permute(0,3,1,2) #b,C_dim,5,10\n",
    "        ####接收端融合####\n",
    "        x = self.fusion_3(x,CSI_sem_BS)  #b,5,10,C_dim\n",
    "        x = x.permute(0,3,1,2) #b,C_dim,5,10\n",
    "        #################\n",
    "        x = self.MFNet.dec(x)\n",
    "\n",
    "        power_signal = torch.sqrt(torch.sum(torch.abs(x1 + x2)**2))/b\n",
    "\n",
    "        return x,power_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_Sem_E2E_OMA(N,Nc,Nr,N_r_RF,Nt,N_t_RF,L,feedback_bits,SNR_dB,v_max_km,Q,NOMA_pre = True,Phy_pre = True,feedback_bits_pre = None,SNR_dB_pre = None,v_max_km_pre=None,Q_pre=None,ITERS=20_000,b=8):\n",
    "    # N代表路径数\n",
    "    \n",
    "    N_t = Nt[0]*Nt[1]\n",
    "    N_r = Nr[0]*Nr[1]\n",
    "    device=0;\n",
    "    lr=1e-4;\n",
    "    log_interval=100; # 每100个输出保存一下许训练记录\n",
    "    save_interval=10*log_interval; # 每1000个测试一下保存记录\n",
    "    iter_begin=0;   #从第0个开始训练 如果不是0就读取之前训练过的check points\n",
    "    save_path=\"./weights/\";\n",
    "    best_loss=0;\n",
    "\n",
    "    model_name_physical = 'physical_E2E'+ str(feedback_bits)+'_L' + str(L)+'_v' + str(v_max_km)\n",
    "    model_name = 'Sem_E2E_OMA'+str(SNR_dB) + '_' + str(feedback_bits)+'_L' + str(L)+'_v' + str(v_max_km)+'_Q' + str(Q)\n",
    "\n",
    "\n",
    "    dec=Sem_E2E_OMA(Nc=Nc,N_r=N_r,N_r_RF=N_r_RF,N_t=N_t,N_t_RF=N_t_RF,L=L,feedback_bits=feedback_bits,n_class=n_class,Q=Q).cuda()\n",
    "    \n",
    "    opt_dec=torch.optim.AdamW(\n",
    "        dec.parameters(), \n",
    "        lr=lr, \n",
    "    )\n",
    "    T = L+Q\n",
    "    load_path=save_path+\"Sem_E2E_OMA\"+\"/\";\n",
    "    load_path_physical = save_path+\"physical_E2E\"+\"/\";\n",
    "    if feedback_bits_pre == None:\n",
    "        if Phy_pre == True:\n",
    "            dec_load_path=load_path_physical+model_name_physical+\"_model.pth.tar\";\n",
    "            ckpt=torch.load(dec_load_path, map_location=\"cuda:\"+str(device));\n",
    "            pretrained_dict=ckpt['state_dict'];\n",
    "            model_dict=dec.physical.state_dict();\n",
    "            pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict.keys()};\n",
    "            model_dict.update(pretrained_dict);\n",
    "            dec.physical.load_state_dict(model_dict);\n",
    "            print('物理层预训练网络读取成功')\n",
    "        if NOMA_pre == True:\n",
    "            model_dir_pre = 'weights/'\n",
    "            model_dir_pre = os.path.join(model_dir_pre, 'MFNet_OMA')\n",
    "            # os.makedirs(model_dir_pre, exist_ok=True)\n",
    "            final_model_file_pre      = os.path.join(model_dir_pre, 'final_pretrain1_C4.pth')\n",
    "            dec.MFNet.load_state_dict(torch.load(final_model_file_pre, map_location='cuda:0'))\n",
    "            print('语义编码预训练网络读取成功')\n",
    "    else:\n",
    "        dec_dict = dec.state_dict()\n",
    "        model_name_pre = 'Sem_E2E_OMA'+str(SNR_dB_pre) + '_' + str(feedback_bits_pre)+'_L' + str(L)+'_v' + str(v_max_km_pre)+'_Q' + str(Q_pre)\n",
    "        dec_load_path=load_path+model_name_pre+\"_model.pth.tar\";\n",
    "        ckpt=torch.load(dec_load_path, map_location=\"cuda:\"+str(device));\n",
    "        pretrained_dict=ckpt['state_dict'];\n",
    "        pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in dec_dict and \".quan\" not in k and \".Dequan\" not in k and \".fusion_1.head\" not in k and \".fusion_2.head\" not in k  and \".Dembed\" not in k}\n",
    "        dec_dict.update(pretrained_dict);\n",
    "        dec.load_state_dict(dec_dict);\n",
    "        print('全部预训练参数读取成功')\n",
    "\n",
    "###################################################################\n",
    "    def train(epo, model, train_loader, optimizer):\n",
    "\n",
    "\n",
    "        loss_avg = 0.\n",
    "        acc_avg  = 0.\n",
    "        start_t = t = time.time()\n",
    "        model.train()\n",
    "\n",
    "        for it, (images, labels, names) in enumerate(tqdm(train_loader, desc=\"Training\", leave=True)):\n",
    "            images = Variable(images).cuda(args.gpu) \n",
    "            labels = Variable(labels).cuda(args.gpu)\n",
    "\n",
    "            b = images.shape[0]\n",
    "            alpha,A_r,A_t,fd,tau = SV_Channel_set(2*b,Nc,N,Nt,Nr,1,v_max_km)\n",
    "            H_batch = torch.zeros(2*b,T, Nc, N_r, N_t).cuda() + 0j\n",
    "            for i in range(T):\n",
    "                t = i*1/14000/8 #i就表示第i个OFDM符号，每个subframe时间是1ms，每个slot包含14个OFDM符号，当子载波间隔15kHz对应一个frame包含1个slot，30kHz对应2个，60kHz->4,120kHz->8,这里采用120kHz间隔所以除以8\n",
    "                H = SV_Channel_final(2*b,Nc,N,Nt,Nr,1,t,alpha,A_r,A_t,fd,tau)\n",
    "                H_batch[:,i] = H\n",
    "            H_batch_1 = H_batch[0:b]\n",
    "            H_batch_2 = H_batch[b:2*b]\n",
    "\n",
    "\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            logits,power_signal = model(H_batch_1,H_batch_2, SNR_dB, images)\n",
    "            # print(labels.min(), labels.max())\n",
    "\n",
    "            loss = F.cross_entropy(logits, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            acc = calculate_accuracy(logits, labels)\n",
    "            loss_avg += float(loss.item())\n",
    "            acc_avg  += float(acc)\n",
    "\n",
    "            # cur_t = time.time()\n",
    "            # if cur_t-t > 5:\n",
    "            #     print('|- epo %s/%s. train iter %s/%s. %.2f img/sec loss: %.4f, acc: %.4f' \\\n",
    "            #         % (epo, args.epoch_max, it+1, train_loader.n_iter, (it+1)*args.batch_size/(cur_t-start_t), float(loss), float(acc)))\n",
    "            #     t += 5\n",
    "\n",
    "        content = '| epo:%s/%s train_loss_avg:%.4f train_acc_avg:%.4f ' \\\n",
    "                % (epo, args.epoch_max, loss_avg/train_loader.n_iter, acc_avg/train_loader.n_iter)\n",
    "        print(content)\n",
    "        with open(log_file, 'a') as appender:\n",
    "            appender.write(content)\n",
    "\n",
    "\n",
    "    def validation(epo, model, val_loader):\n",
    "\n",
    "        loss_avg = 0.\n",
    "        acc_avg  = 0.\n",
    "        power_avg = 0.\n",
    "        start_t = time.time()\n",
    "        model.eval()\n",
    "\n",
    "        cf = np.zeros((n_class, n_class))\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for it, (images, labels, names) in enumerate(val_loader):\n",
    "                images = Variable(images)\n",
    "                labels = Variable(labels)\n",
    "                if args.gpu >= 0:\n",
    "                    images = images.cuda(args.gpu)\n",
    "                    labels = labels.cuda(args.gpu)\n",
    "                \n",
    "                b = images.shape[0]\n",
    "                alpha,A_r,A_t,fd,tau = SV_Channel_set(2*b,Nc,N,Nt,Nr,1,v_max_km)\n",
    "                H_batch = torch.zeros(2*b,T, Nc, N_r, N_t).cuda() + 0j\n",
    "                for i in range(T):\n",
    "                    t = i*1/14000/8 #i就表示第i个OFDM符号，每个subframe时间是1ms，每个slot包含14个OFDM符号，当子载波间隔15kHz对应一个frame包含1个slot，30kHz对应2个，60kHz->4,120kHz->8,这里采用120kHz间隔所以除以8\n",
    "                    H = SV_Channel_final(2*b,Nc,N,Nt,Nr,1,t,alpha,A_r,A_t,fd,tau)\n",
    "                    H_batch[:,i] = H\n",
    "                H_batch_1 = H_batch[0:b]\n",
    "                H_batch_2 = H_batch[b:2*b]\n",
    "\n",
    "                logits,power_signal = model(H_batch_1,H_batch_2, SNR_dB, images)\n",
    "                loss = F.cross_entropy(logits, labels)\n",
    "                acc = calculate_accuracy(logits, labels)\n",
    "                loss_avg += float(loss)\n",
    "                acc_avg  += float(acc)\n",
    "                power_avg += float(power_signal.item())\n",
    "\n",
    "                predictions = logits.argmax(1)\n",
    "                for gtcid in range(n_class): \n",
    "                    for pcid in range(n_class):\n",
    "                        gt_mask      = labels == gtcid \n",
    "                        pred_mask    = predictions == pcid\n",
    "                        intersection = gt_mask * pred_mask\n",
    "                        cf[gtcid, pcid] += int(intersection.sum())\n",
    "            overall_acc, acc, IoU = calculate_result(cf)\n",
    "\n",
    "                # cur_t = time.time()\n",
    "                # print('|- epo %s/%s. val iter %s/%s. %.2f img/sec loss: %.4f, acc: %.4f' \\\n",
    "                #         % (epo, args.epoch_max, it+1, val_loader.n_iter, (it+1)*args.batch_size/(cur_t-start_t), float(loss), float(acc)))\n",
    "\n",
    "        content = '| val_loss_avg:%.4f val_acc_avg:%.4f  val_power_avg:%.2f' \\\n",
    "                % (loss_avg/val_loader.n_iter, acc_avg/val_loader.n_iter, power_avg/val_loader.n_iter)\n",
    "        print(content)\n",
    "\n",
    "        content = '| class accuracy avg:%.4f class IoU avg:%.4f' \\\n",
    "                % (acc.mean(), IoU.mean())\n",
    "        print(content)\n",
    "        # with open(log_file, 'a') as appender:\n",
    "        #     appender.write(content)\n",
    "        return IoU.mean()\n",
    "    \n",
    "    def save_ckpt(folder_name):\n",
    "        folder_path=save_path+folder_name+\"/\";\n",
    "        if not os.path.exists(folder_path):\n",
    "            os.makedirs(folder_path);\n",
    "\n",
    "        torch.save({'state_dict': dec.state_dict()}, folder_path+model_name+\"_model.pth.tar\");\n",
    "        # torch.save({'best_loss': best_loss, \n",
    "        #             'opt_dec_dict': opt_dec.state_dict(), \n",
    "        #             }, folder_path+model_name+\"_opt.pth.tar\");\n",
    "\n",
    "\n",
    "#################################################################################################\n",
    "    import sys\n",
    "    sys.argv = ['run.py']\n",
    "    parser = argparse.ArgumentParser(description='Train MFNet with pytorch')\n",
    "    parser.add_argument('--model_name',  '-M',  type=str, default='Sem_E2E_OMA')\n",
    "    parser.add_argument('--batch_size',  '-B',  type=int, default=b)\n",
    "\n",
    "    parser.add_argument('--epoch_max' ,  '-E',  type=int, default=100)\n",
    "    # parser.add_argument('--epoch_max' ,  '-E',  type=int, default=2)\n",
    "\n",
    "    parser.add_argument('--epoch_from',  '-EF', type=int, default=1)\n",
    "    parser.add_argument('--gpu',         '-G',  type=int, default=0)\n",
    "    parser.add_argument('--num_workers', '-j',  type=int, default=0)\n",
    "    args = parser.parse_args()\n",
    "    model_dir = 'weights/'\n",
    "    model_dir = os.path.join(model_dir, args.model_name)\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    log_file              = os.path.join(model_dir, 'log_Sem_E2E.txt')\n",
    "\n",
    "    print('| training %s on GPU #%d with pytorch' % (args.model_name, args.gpu))\n",
    "    print('| from epoch %d / %s' % (args.epoch_from, args.epoch_max))\n",
    "    print('| model will be saved in: %s' % model_dir)\n",
    "\n",
    "\n",
    "\n",
    "    best_mIOU = -1\n",
    "\n",
    "    train_dataset = MF_dataset(data_dir, 'train', have_label=True, transform=augmentation_methods)\n",
    "    val_dataset  = MF_dataset(data_dir, 'val', have_label=True)\n",
    "\n",
    "    train_loader  = DataLoader(\n",
    "        dataset     = train_dataset,\n",
    "        batch_size  = args.batch_size,\n",
    "        shuffle     = True,\n",
    "        num_workers = args.num_workers,\n",
    "        pin_memory  = True,\n",
    "        drop_last   = True\n",
    "    )\n",
    "    val_loader  = DataLoader(\n",
    "        dataset     = val_dataset,\n",
    "        batch_size  = args.batch_size,\n",
    "        shuffle     = False,\n",
    "        num_workers = args.num_workers,\n",
    "        pin_memory  = True,\n",
    "        drop_last   = False\n",
    "    )\n",
    "    train_loader.n_iter = len(train_loader)\n",
    "    val_loader.n_iter   = len(val_loader)\n",
    "\n",
    "    for epo in (range(args.epoch_from, args.epoch_max+1)):\n",
    "        print('\\n| epo #%s begin...' % epo)\n",
    "\n",
    "        train(epo, dec, train_loader, opt_dec)\n",
    "        mIOU = validation(epo, dec, val_loader)\n",
    "\n",
    "        if mIOU>best_mIOU:\n",
    "            best_mIOU=mIOU;\n",
    "            save_ckpt(\"Sem_E2E_OMA\");\n",
    "            print(\"| save best\")\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t = 0\n",
    "# Nc = 100\n",
    "# N = 2\n",
    "# Nt = [1,8]\n",
    "# Nr = [1,64]\n",
    "# N_r_RF = 2\n",
    "# N_t_RF = 2\n",
    "\n",
    "# L = 8\n",
    "\n",
    "# feedback_bits_pre = None\n",
    "# SNR_dB_pre = None\n",
    "# v_max_km_pre = None\n",
    "# Q_pre = None\n",
    "\n",
    "# NOMA_pre=True\n",
    "# Phy_pre=True\n",
    "\n",
    "# feedback_bits = 1024\n",
    "# SNR_dB = -25\n",
    "# v_max_km = 120\n",
    "# Q = 4\n",
    "# for L in [2,4,8]:\n",
    "#     train_Sem_E2E_OMA(N,Nc,Nr,N_r_RF,Nt,N_t_RF,L,feedback_bits,SNR_dB,v_max_km,Q,NOMA_pre, Phy_pre,feedback_bits_pre,SNR_dB_pre,v_max_km_pre,Q_pre,ITERS=600_000,b=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 0\n",
    "Nc = 100\n",
    "N = 2\n",
    "Nt = [1,8]\n",
    "Nr = [1,64]\n",
    "N_r_RF = 2\n",
    "N_t_RF = 2\n",
    "\n",
    "L = 8\n",
    "\n",
    "feedback_bits_pre = None\n",
    "SNR_dB_pre = None\n",
    "v_max_km_pre = None\n",
    "Q_pre = None\n",
    "\n",
    "NOMA_pre=True\n",
    "Phy_pre=True\n",
    "\n",
    "feedback_bits = 1024\n",
    "SNR_dB = -25\n",
    "v_max_km = 120\n",
    "Q = 1\n",
    "for L in [2]:\n",
    "    train_Sem_E2E_OMA(N,Nc,Nr,N_r_RF,Nt,N_t_RF,L,feedback_bits,SNR_dB,v_max_km,Q,NOMA_pre, Phy_pre,feedback_bits_pre,SNR_dB_pre,v_max_km_pre,Q_pre,ITERS=600_000,b=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t = 0\n",
    "# Nc = 100\n",
    "# N = 2\n",
    "# Nt = [1,8]\n",
    "# Nr = [1,64]\n",
    "# N_r_RF = 2\n",
    "# N_t_RF = 2\n",
    "\n",
    "# L = 8\n",
    "\n",
    "# feedback_bits_pre = None\n",
    "# SNR_dB_pre = None\n",
    "# v_max_km_pre = None\n",
    "# Q_pre = None\n",
    "\n",
    "# NOMA_pre=True\n",
    "# Phy_pre=True\n",
    "\n",
    "# feedback_bits = 1024\n",
    "# SNR_dB = -25\n",
    "# v_max_km = 120\n",
    "# Q = 4\n",
    "# for feedback_bits in [4,16,64,256]:\n",
    "#     train_Sem_E2E_OMA(N,Nc,Nr,N_r_RF,Nt,N_t_RF,L,feedback_bits,SNR_dB,v_max_km,Q,NOMA_pre, Phy_pre,feedback_bits_pre,SNR_dB_pre,v_max_km_pre,Q_pre,ITERS=600_000,b=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t = 0\n",
    "# Nc = 100\n",
    "# N = 2\n",
    "# Nt = [1,8]\n",
    "# Nr = [1,64]\n",
    "# N_r_RF = 2\n",
    "# N_t_RF = 2\n",
    "\n",
    "# L = 8\n",
    "\n",
    "# feedback_bits_pre = None\n",
    "# SNR_dB_pre = None\n",
    "# v_max_km_pre = None\n",
    "# Q_pre = None\n",
    "\n",
    "# NOMA_pre=True\n",
    "# Phy_pre=True\n",
    "\n",
    "# feedback_bits = 1024\n",
    "# SNR_dB = -25\n",
    "# v_max_km = 120\n",
    "# Q = 1\n",
    "# for feedback_bits in [64,256]:\n",
    "#     train_Sem_E2E_OMA(N,Nc,Nr,N_r_RF,Nt,N_t_RF,L,feedback_bits,SNR_dB,v_max_km,Q,NOMA_pre, Phy_pre,feedback_bits_pre,SNR_dB_pre,v_max_km_pre,Q_pre,ITERS=600_000,b=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t = 0\n",
    "# Nc = 100\n",
    "# N = 2\n",
    "# Nt = [1,8]\n",
    "# Nr = [1,64]\n",
    "# N_r_RF = 2\n",
    "# N_t_RF = 2\n",
    "\n",
    "# L = 8\n",
    "\n",
    "# feedback_bits_pre = None\n",
    "# SNR_dB_pre = None\n",
    "# v_max_km_pre = None\n",
    "# Q_pre = None\n",
    "\n",
    "# NOMA_pre=True\n",
    "# Phy_pre=True\n",
    "\n",
    "# feedback_bits = 1024\n",
    "# SNR_dB = -25\n",
    "# v_max_km = 120\n",
    "# Q = 4\n",
    "# for Q in [2,3,5]:\n",
    "#     train_Sem_E2E_OMA(N,Nc,Nr,N_r_RF,Nt,N_t_RF,L,feedback_bits,SNR_dB,v_max_km,Q,NOMA_pre, Phy_pre,feedback_bits_pre,SNR_dB_pre,v_max_km_pre,Q_pre,ITERS=600_000,b=8) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 0\n",
    "Nc = 100\n",
    "N = 2\n",
    "Nt = [1,8]\n",
    "Nr = [1,64]\n",
    "N_r_RF = 2\n",
    "N_t_RF = 2\n",
    "\n",
    "L = 8\n",
    "\n",
    "feedback_bits_pre = None\n",
    "SNR_dB_pre = None\n",
    "v_max_km_pre = None\n",
    "Q_pre = None\n",
    "\n",
    "NOMA_pre=True\n",
    "Phy_pre=True\n",
    "\n",
    "feedback_bits = 1024\n",
    "SNR_dB = -25\n",
    "v_max_km = 120\n",
    "Q = 4\n",
    "for SNR_dB in [-15,-10,-5,0]:\n",
    "    train_Sem_E2E_OMA(N,Nc,Nr,N_r_RF,Nt,N_t_RF,L,feedback_bits,SNR_dB,v_max_km,Q,NOMA_pre, Phy_pre,feedback_bits_pre,SNR_dB_pre,v_max_km_pre,Q_pre,ITERS=600_000,b=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 测试"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.util import visualize\n",
    "import sys\n",
    "\n",
    "\n",
    "t = 0\n",
    "Nc = 100\n",
    "N = 2\n",
    "Nt = [1,8]\n",
    "Nr = [1,64]\n",
    "N_r_RF = 2\n",
    "N_t_RF = 2\n",
    "N_t = Nt[0]*Nt[1]\n",
    "N_r = Nr[0]*Nr[1]\n",
    "L = 8\n",
    "feedback_bits = 1024\n",
    "SNR_dB = -25\n",
    "v_max_km = 120\n",
    "\n",
    "Q = 4\n",
    "T = L+Q\n",
    "U = 2\n",
    "\n",
    "sys.argv = ['run.py']\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Run MFNet demo with pytorch')\n",
    "parser.add_argument('--model_name', '-M',  type=str, default='Sem_E2E_OMA')\n",
    "parser.add_argument('--gpu',        '-G',  type=int, default=0)\n",
    "args = parser.parse_args()\n",
    "model_dir = 'weights/'\n",
    "model_dir = os.path.join(model_dir, args.model_name)\n",
    "\n",
    "model_name = 'Sem_E2E_OMA'+str(SNR_dB) + '_' + str(feedback_bits)+'_L' + str(L)+'_v' + str(v_max_km)+'_Q' + str(Q)\n",
    "\n",
    "final_model_file      = os.path.join(model_dir, model_name+\"_model.pth.tar\")\n",
    "print('| running %s demo on GPU #%d with pytorch' % (args.model_name, args.gpu))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = eval(args.model_name)(Nc=Nc,N_r=N_r,N_r_RF=N_r_RF,N_t=N_t,N_t_RF=N_t_RF,L=L,feedback_bits=feedback_bits,n_class=n_class,Q=Q)\n",
    "if args.gpu >= 0: model.cuda(args.gpu)\n",
    "\n",
    "device = 0\n",
    "save_path=\"./weights/\";\n",
    "load_path=save_path+\"Sem_E2E_OMA\"+\"/\";\n",
    "dec_dict = model.state_dict()\n",
    "model_name_pre = 'Sem_E2E_OMA'+str(SNR_dB) + '_' + str(feedback_bits)+'_L' + str(L)+'_v' + str(v_max_km)+'_Q' + str(Q)\n",
    "dec_load_path=load_path+model_name_pre+\"_model.pth.tar\";\n",
    "ckpt=torch.load(dec_load_path, map_location=\"cuda:\"+str(device));\n",
    "pretrained_dict=ckpt['state_dict'];\n",
    "pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in dec_dict}\n",
    "dec_dict.update(pretrained_dict);\n",
    "model.load_state_dict(dec_dict);\n",
    "print('全部参数读取成功')\n",
    "\n",
    "files = os.listdir('image')\n",
    "images = []\n",
    "fpath  = []\n",
    "fpath_out = []\n",
    "fpath_original = []\n",
    "for file in files:\n",
    "    if file[-3:] != 'png': continue\n",
    "    fpath.append('image/'+file)\n",
    "    fpath_out.append('seg_E2E_OMA/'+file)\n",
    "    fpath_original.append('image_original/'+file)\n",
    "    images.append( np.asarray(Image.open('image/'+file)) )\n",
    "images = np.asarray(images, dtype=np.float32).transpose((0,3,1,2))/255.\n",
    "images = Variable(torch.tensor(images))\n",
    "if args.gpu >= 0: images = images.cuda(args.gpu)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    b = images.shape[0]\n",
    "    alpha,A_r,A_t,fd,tau = SV_Channel_set(2*b,Nc,N,Nt,Nr,1,v_max_km)\n",
    "    H_batch = torch.zeros(2*b,T, Nc, N_r, N_t).cuda() + 0j\n",
    "    for i in range(T):\n",
    "        t = i*1/14000/8 #i就表示第i个OFDM符号，每个subframe时间是1ms，每个slot包含14个OFDM符号，当子载波间隔15kHz对应一个frame包含1个slot，30kHz对应2个，60kHz->4,120kHz->8,这里采用120kHz间隔所以除以8\n",
    "        H = SV_Channel_final(2*b,Nc,N,Nt,Nr,1,t,alpha,A_r,A_t,fd,tau)\n",
    "        H_batch[:,i] = H\n",
    "    H_batch_1 = H_batch[0:b]\n",
    "    H_batch_2 = H_batch[b:2*b]\n",
    "    logits,power_signal = model(H_batch_1,H_batch_2, SNR_dB, images)\n",
    "    predictions = logits.argmax(1)\n",
    "    save_images(images, fpath_original)  #保存原始图像\n",
    "    visualize(fpath_out, predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 性能指标"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.util import calculate_accuracy, calculate_result\n",
    "import sys\n",
    "def test_Sem_E2E_OMA(N,Nc,Nr,N_r_RF,Nt,N_t_RF,L,feedback_bits,SNR_dB,v_max_km,Q):\n",
    "\n",
    "    N_t = Nt[0]*Nt[1]\n",
    "    N_r = Nr[0]*Nr[1]\n",
    "\n",
    "    T = L+Q\n",
    "    U = 2\n",
    "    from util.util import calculate_accuracy, calculate_result\n",
    "    import sys\n",
    "    sys.argv = ['run.py']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    cf = np.zeros((n_class, n_class))\n",
    "\n",
    "\n",
    "    parser = argparse.ArgumentParser(description='Test MFNet with pytorch')\n",
    "    parser.add_argument('--model_name', '-M',  type=str, default='Sem_E2E_OMA')\n",
    "    parser.add_argument('--batch_size',  '-B',  type=int, default=16)\n",
    "    parser.add_argument('--gpu',        '-G',  type=int, default=0)\n",
    "    parser.add_argument('--num_workers', '-j',  type=int, default=0)\n",
    "    args = parser.parse_args()\n",
    "    model_dir = 'weights/'\n",
    "    model_dir = os.path.join(model_dir, args.model_name)\n",
    "\n",
    "    model_name = 'Sem_E2E_OMA'+str(SNR_dB) + '_' + str(feedback_bits)+'_L' + str(L)+'_v' + str(v_max_km)+'_Q' + str(Q)\n",
    "\n",
    "    final_model_file      = os.path.join(model_dir, model_name+\"_model.pth.tar\")\n",
    "    # print('| running %s demo on GPU #%d with pytorch' % (args.model_name, args.gpu))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    model = Sem_E2E_OMA(Nc=Nc,N_r=N_r,N_r_RF=N_r_RF,N_t=N_t,N_t_RF=N_t_RF,L=L,feedback_bits=feedback_bits,n_class=n_class,Q=Q).cuda()\n",
    "    if args.gpu >= 0: model.cuda(args.gpu)\n",
    "\n",
    "    device = 0\n",
    "    save_path=\"./weights/\";\n",
    "    load_path=save_path+\"Sem_E2E_OMA\"+\"/\";\n",
    "    dec_dict = model.state_dict()\n",
    "    model_name_pre = 'Sem_E2E_OMA'+str(SNR_dB) + '_' + str(feedback_bits)+'_L' + str(L)+'_v' + str(v_max_km)+'_Q' + str(Q)\n",
    "    dec_load_path=load_path+model_name_pre+\"_model.pth.tar\";\n",
    "    ckpt=torch.load(dec_load_path, map_location=\"cuda:\"+str(device));\n",
    "    pretrained_dict=ckpt['state_dict'];\n",
    "    pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in dec_dict}\n",
    "    dec_dict.update(pretrained_dict);\n",
    "    model.load_state_dict(dec_dict);\n",
    "    # print('全部参数读取成功')\n",
    "\n",
    "    test_dataset  = MF_dataset(data_dir, 'test', have_label=True)\n",
    "    test_loader  = DataLoader(\n",
    "        dataset     = test_dataset,\n",
    "        batch_size  = args.batch_size,\n",
    "        shuffle     = False,\n",
    "        num_workers = args.num_workers,\n",
    "        pin_memory  = True,\n",
    "        drop_last   = False\n",
    "    )\n",
    "    test_loader.n_iter = len(test_loader)\n",
    "\n",
    "    loss_avg = 0.\n",
    "    acc_avg  = 0.\n",
    "    model.eval()\n",
    "    results_IOU = 0\n",
    "    val_num = 5\n",
    "    with torch.no_grad():\n",
    "        for aa in range(val_num):\n",
    "            cf = np.zeros((n_class, n_class))\n",
    "            for it, (images, labels, names) in enumerate(test_loader):\n",
    "                images = Variable(images)\n",
    "                labels = Variable(labels)\n",
    "                if args.gpu >= 0:\n",
    "                    images = images.cuda(args.gpu)\n",
    "                    labels = labels.cuda(args.gpu)\n",
    "\n",
    "                b = images.shape[0]\n",
    "                alpha,A_r,A_t,fd,tau = SV_Channel_set(2*b,Nc,N,Nt,Nr,1,v_max_km)\n",
    "                H_batch = torch.zeros(2*b,T, Nc, N_r, N_t).cuda() + 0j\n",
    "                for i in range(T):\n",
    "                    t = i*1/14000/8 #i就表示第i个OFDM符号，每个subframe时间是1ms，每个slot包含14个OFDM符号，当子载波间隔15kHz对应一个frame包含1个slot，30kHz对应2个，60kHz->4,120kHz->8,这里采用120kHz间隔所以除以8\n",
    "                    H = SV_Channel_final(2*b,Nc,N,Nt,Nr,1,t,alpha,A_r,A_t,fd,tau)\n",
    "                    H_batch[:,i] = H\n",
    "                H_batch_1 = H_batch[0:b]\n",
    "                H_batch_2 = H_batch[b:2*b]\n",
    "                logits,power_signal = model(H_batch_1,H_batch_2, SNR_dB, images)\n",
    "                loss = F.cross_entropy(logits, labels)\n",
    "                acc = calculate_accuracy(logits, labels)\n",
    "                loss_avg += float(loss)\n",
    "                acc_avg  += float(acc)\n",
    "\n",
    "                # print('|- test iter %s/%s. loss: %.4f, acc: %.4f' \\\n",
    "                #         % (it+1, test_loader.n_iter, float(loss), float(acc)))\n",
    "\n",
    "                predictions = logits.argmax(1)\n",
    "                for gtcid in range(n_class): \n",
    "                    for pcid in range(n_class):\n",
    "                        gt_mask      = labels == gtcid \n",
    "                        pred_mask    = predictions == pcid\n",
    "                        intersection = gt_mask * pred_mask\n",
    "                        cf[gtcid, pcid] += int(intersection.sum())\n",
    "\n",
    "            overall_acc, acc, IoU = calculate_result(cf)\n",
    "            results_IOU += IoU.mean()/val_num\n",
    "\n",
    "    # print('| overall accuracy:', overall_acc)\n",
    "    # print('| accuracy of each class:', acc)\n",
    "    # print('| class accuracy avg:', acc.mean())\n",
    "    # print('| IoU:', IoU)\n",
    "    print('| class IoU avg:', results_IOU)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 0\n",
    "Nc = 100\n",
    "N = 2\n",
    "Nt = [1,8]\n",
    "Nr = [1,64]\n",
    "N_r_RF = 2\n",
    "N_t_RF = 2\n",
    "\n",
    "L = 8\n",
    "\n",
    "feedback_bits_pre = None\n",
    "SNR_dB_pre = None\n",
    "v_max_km_pre = None\n",
    "Q_pre = None\n",
    "\n",
    "NOMA_pre=True\n",
    "Phy_pre=True\n",
    "\n",
    "feedback_bits = 1024\n",
    "SNR_dB = -25\n",
    "v_max_km = 120\n",
    "Q = 4\n",
    "for L in [1,2,4,8]:\n",
    "    test_Sem_E2E_OMA(N,Nc,Nr,N_r_RF,Nt,N_t_RF,L,feedback_bits,SNR_dB,v_max_km,Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 0\n",
    "Nc = 100\n",
    "N = 2\n",
    "Nt = [1,8]\n",
    "Nr = [1,64]\n",
    "N_r_RF = 2\n",
    "N_t_RF = 2\n",
    "\n",
    "L = 8\n",
    "\n",
    "feedback_bits_pre = None\n",
    "SNR_dB_pre = None\n",
    "v_max_km_pre = None\n",
    "Q_pre = None\n",
    "\n",
    "NOMA_pre=True\n",
    "Phy_pre=True\n",
    "\n",
    "feedback_bits = 1024\n",
    "SNR_dB = -25\n",
    "v_max_km = 120\n",
    "Q = 1\n",
    "\n",
    "for L in [1,2,4,8]:\n",
    "    test_Sem_E2E_OMA(N,Nc,Nr,N_r_RF,Nt,N_t_RF,L,feedback_bits,SNR_dB,v_max_km,Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 0\n",
    "Nc = 100\n",
    "N = 2\n",
    "Nt = [1,8]\n",
    "Nr = [1,64]\n",
    "N_r_RF = 2\n",
    "N_t_RF = 2\n",
    "\n",
    "L = 8\n",
    "\n",
    "feedback_bits_pre = None\n",
    "SNR_dB_pre = None\n",
    "v_max_km_pre = None\n",
    "Q_pre = None\n",
    "\n",
    "NOMA_pre=True\n",
    "Phy_pre=True\n",
    "\n",
    "feedback_bits = 1024\n",
    "SNR_dB = -25\n",
    "v_max_km = 120\n",
    "Q = 4\n",
    "for feedback_bits in [4,16,64,256,1024]:\n",
    "    test_Sem_E2E_OMA(N,Nc,Nr,N_r_RF,Nt,N_t_RF,L,feedback_bits,SNR_dB,v_max_km,Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 0\n",
    "Nc = 100\n",
    "N = 2\n",
    "Nt = [1,8]\n",
    "Nr = [1,64]\n",
    "N_r_RF = 2\n",
    "N_t_RF = 2\n",
    "\n",
    "L = 8\n",
    "\n",
    "feedback_bits_pre = None\n",
    "SNR_dB_pre = None\n",
    "v_max_km_pre = None\n",
    "Q_pre = None\n",
    "\n",
    "NOMA_pre=True\n",
    "Phy_pre=True\n",
    "\n",
    "feedback_bits = 1024\n",
    "SNR_dB = -25\n",
    "v_max_km = 120\n",
    "Q = 1\n",
    "for feedback_bits in [4,16,64,256,1024]:\n",
    "    test_Sem_E2E_OMA(N,Nc,Nr,N_r_RF,Nt,N_t_RF,L,feedback_bits,SNR_dB,v_max_km,Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 0\n",
    "Nc = 100\n",
    "N = 2\n",
    "Nt = [1,8]\n",
    "Nr = [1,64]\n",
    "N_r_RF = 2\n",
    "N_t_RF = 2\n",
    "\n",
    "L = 8\n",
    "\n",
    "feedback_bits_pre = None\n",
    "SNR_dB_pre = None\n",
    "v_max_km_pre = None\n",
    "Q_pre = None\n",
    "\n",
    "NOMA_pre=True\n",
    "Phy_pre=True\n",
    "\n",
    "feedback_bits = 1024\n",
    "SNR_dB = -25\n",
    "v_max_km = 120\n",
    "Q = 4\n",
    "for Q in [1,2,3,4,5]:\n",
    "    test_Sem_E2E_OMA(N,Nc,Nr,N_r_RF,Nt,N_t_RF,L,feedback_bits,SNR_dB,v_max_km,Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 0\n",
    "Nc = 100\n",
    "N = 2\n",
    "Nt = [1,8]\n",
    "Nr = [1,64]\n",
    "N_r_RF = 2\n",
    "N_t_RF = 2\n",
    "\n",
    "L = 8\n",
    "\n",
    "feedback_bits_pre = None\n",
    "SNR_dB_pre = None\n",
    "v_max_km_pre = None\n",
    "Q_pre = None\n",
    "\n",
    "NOMA_pre=True\n",
    "Phy_pre=True\n",
    "\n",
    "feedback_bits = 1024\n",
    "SNR_dB = -25\n",
    "v_max_km = 120\n",
    "Q = 4\n",
    "for SNR_dB in [-40,-35,-30,-25,-20,-10]:\n",
    "    test_Sem_E2E_OMA(N,Nc,Nr,N_r_RF,Nt,N_t_RF,L,feedback_bits,SNR_dB,v_max_km,Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基线（分离设计）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 插值(仅验证)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 时域和频域插值外推\n",
    "def interpolate_upsample(x, scale_factors, mode='bilinear', align_corners=False):\n",
    "    \"\"\"\n",
    "    使用双线性插值对张量 x 在时间和频域维度上进行上采样。\n",
    "    \n",
    "    参数:\n",
    "        x (torch.Tensor): 输入张量，形状为 [b, T, Nc, N_r, N_t]。\n",
    "        scale_factors (tuple): 时间和频域的上采样因子 (scale_time, scale_freq)。\n",
    "        mode (str): 插值模式，默认为 'bilinear'。\n",
    "        align_corners (bool): 插值参数，默认为 False。\n",
    "    \n",
    "    返回:\n",
    "        x_up (torch.Tensor): 上采样后的张量，形状为 [b, T*scale_time, Nc*scale_freq, N_r, N_t]。\n",
    "    \"\"\"\n",
    "    scale_time, scale_freq = scale_factors\n",
    "    \n",
    "    # Reshape to [b * N_r * N_t, 1, T, Nc] for 2D interpolation\n",
    "    b, T, Nc, N_r, N_t = x.shape\n",
    "    x_reshaped = x.permute(0, 3, 4, 1, 2).contiguous().view(b * N_r * N_t, 1, T, Nc)\n",
    "    \n",
    "    # Perform 2D interpolation on time and frequency dimensions\n",
    "    x_up = F.interpolate(x_reshaped, scale_factor=(scale_time, scale_freq), mode=mode, align_corners=align_corners)\n",
    "    \n",
    "    # Reshape back to [b, T*scale_time, Nc*scale_freq, N_r, N_t]\n",
    "    b_new, _, T_up, Nc_up = x_up.shape\n",
    "    x_up = x_up.view(b, N_r, N_t, T_up, Nc_up).permute(0, 3, 4, 1, 2).contiguous()\n",
    "    \n",
    "    return x_up\n",
    "def Subcar_Interp(H1, H2, rate1, rate2):\n",
    "    \"\"\"\n",
    "    对下采样后的信道 H1 和 H2 进行时间域和频域的插值上采样，恢复到完整的维度。\n",
    "    \n",
    "    参数:\n",
    "        H1 (torch.Tensor): 下采样后的信道矩阵，形状为 [b, T_down, Nc_down, N_r, N_t]，复数类型。\n",
    "        H2 (torch.Tensor): 下采样后的信道矩阵，形状为 [b, T_down, Nc_down, N_r, N_t]，复数类型。\n",
    "        rate1 (int): 时间域上采样因子（多普勒域）。\n",
    "        rate2 (int): 频域上采样因子（延时域）。\n",
    "    \n",
    "    返回:\n",
    "        H1_up (torch.Tensor): 上采样后的 H1，形状为 [b, T*rate1, Nc*rate2, N_r, N_t]。\n",
    "        H2_up_freq_shifted (torch.Tensor): 上采样并频率偏移后的 H2，形状为 [b, T*rate1, Nc*rate2, N_r, N_t]。\n",
    "    \"\"\"\n",
    "    # 分离实部和虚部进行插值\n",
    "    H1_real = H1.real\n",
    "    H1_imag = H1.imag\n",
    "    H2_real = H2.real\n",
    "    H2_imag = H2.imag\n",
    "    \n",
    "    # Perform interpolation on real and imaginary parts\n",
    "    H1_up_real = interpolate_upsample(H1_real, scale_factors=(rate1, rate2), mode='bilinear', align_corners=False)\n",
    "    H1_up_imag = interpolate_upsample(H1_imag, scale_factors=(rate1, rate2), mode='bilinear', align_corners=False)\n",
    "    H2_up_real = interpolate_upsample(H2_real, scale_factors=(rate1, rate2), mode='bilinear', align_corners=False)\n",
    "    H2_up_imag = interpolate_upsample(H2_imag, scale_factors=(rate1, rate2), mode='bilinear', align_corners=False)\n",
    "    \n",
    "    # Reconstruct complex tensors\n",
    "    H1_up = torch.complex(H1_up_real, H1_up_imag)\n",
    "    H2_up = torch.complex(H2_up_real, H2_up_imag)\n",
    "    \n",
    "    # Frequency shift for H2_up\n",
    "    H1_up = torch.roll(H1_up, shifts=-rate2//2, dims=2)  # Shift along frequency dimension\n",
    "    \n",
    "    return H1_up, H2_up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 0\n",
    "Nc = 100\n",
    "N = 2\n",
    "Nt = [1,8]\n",
    "Nr = [1,64]\n",
    "N_r_RF = 2\n",
    "N_t_RF = 2\n",
    "SNR_dB = -25\n",
    "v_max_km = 120\n",
    "T = 12\n",
    "b=16\n",
    "N_t = Nt[0]*Nt[1]\n",
    "N_r = Nr[0]*Nr[1]\n",
    "alpha,A_r,A_t,fd,tau = SV_Channel_set(2*b,Nc,N,Nt,Nr,1,v_max_km)\n",
    "H_batch = torch.zeros(2*b,T, Nc, N_r, N_t).cuda() + 0j\n",
    "\n",
    "for i in range(T):\n",
    "    t = i*1/14000/8 #i就表示第i个OFDM符号，每个subframe时间是1ms，每个slot包含14个OFDM符号，当子载波间隔15kHz对应一个frame包含1个slot，30kHz对应2个，60kHz->4,120kHz->8,这里采用120kHz间隔所以除以8\n",
    "    H = SV_Channel_final(2*b,Nc,N,Nt,Nr,1,t,alpha,A_r,A_t,fd,tau)\n",
    "    H_batch[:,i] = H\n",
    "H_batch_1 = H_batch[0:b]\n",
    "H_batch_2 = H_batch[b:2*b]\n",
    "\n",
    "\n",
    "rate1 = 4\n",
    "rate2 = 2\n",
    "H_1 = H_batch_1[:, ::rate1, ::rate2, :, :]\n",
    "H_2 = H_batch_2[:, ::rate1, rate2//2::rate2, :, :]\n",
    "H1_up, H2_up = Subcar_Interp(H_1, H_2, rate1, rate2)\n",
    "print(NMSE(H1_up,H_batch_1))\n",
    "print(NMSE(H2_up,H_batch_2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 预编码和合并(仅验证)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def Pre_PCA(H1, H2):\n",
    "    \"\"\"\n",
    "    MIMO预编码函数 Pre_PCA\n",
    "\n",
    "    参数:\n",
    "        H1: 张量，形状为 [b, T, Nc, N_r, N_t]，用户1到基站的信道矩阵\n",
    "        H2: 张量，形状为 [b, T, Nc, N_r, N_t]，用户2到基站的信道矩阵\n",
    "\n",
    "    返回:\n",
    "        {\n",
    "            'P_analog1': 用户1模拟预编码器，形状 [b, T, 1, N_t, 2],\n",
    "            'P_analog2': 用户2模拟预编码器，形状 [b, T, 1, N_t, 2],\n",
    "            'C_analog': 基站端模拟合并器，形状 [b, T, 1, 2, N_r],\n",
    "            'P_digital1': 用户1数字预编码器，形状 [b, T, Nc, 2, 1],\n",
    "            'P_digital2': 用户2数字预编码器, 形状 [b, T, Nc, 2, 1],\n",
    "            'C_digital': 基站端数字合并器，形状 [b, T, Nc, 2, 2]\n",
    "        }\n",
    "    \"\"\"\n",
    "    # 获取输入信道矩阵的尺寸信息\n",
    "    b, T, Nc, N_r, N_t = H1.shape\n",
    "    N_RF = 2  # 射频链路数\n",
    "\n",
    "    def compute_user_analog_precoder(H):\n",
    "        \"\"\"\n",
    "        计算用户端的模拟预编码器\n",
    "\n",
    "        输入:\n",
    "            H: 张量，形状为 [b, T, Nc, N_r, N_t]\n",
    "\n",
    "        输出:\n",
    "            P_analog: 张量，形状为 [b, T, 1, N_t, 2]\n",
    "        \"\"\"\n",
    "        # 将子载波和接收天线维度展平\n",
    "        H_reshaped = H.view(b, T, Nc * N_r, N_t)  # [b, T, Nc*N_r, N_t]\n",
    "\n",
    "        # 对展平后的信道矩阵进行奇异值分解（SVD）\n",
    "        U, S, Vh = torch.linalg.svd(H_reshaped, full_matrices=False)  # Vh: [b, T, Nc*N_r, N_t]\n",
    "\n",
    "        # 取右奇异矩阵的共轭转置，得到 V 矩阵\n",
    "        V = Vh.conj().transpose(-2, -1)  # [b, T, N_t, Nc*N_r]\n",
    "\n",
    "        # 取前两个右奇异向量作为模拟预编码器\n",
    "        P_analog = V[:, :, :, :N_RF]  # [b, T, N_t, 2]\n",
    "\n",
    "        # 恒模约束：仅保留相位信息\n",
    "        P_analog = P_analog / (P_analog.abs() + 1e-8)  # 避免除零\n",
    "\n",
    "        # 调整维度以匹配输出形状 [b, T, 1, N_t, 2]\n",
    "        P_analog = P_analog.unsqueeze(2)  # [b, T, 1, N_t, 2]\n",
    "\n",
    "        return P_analog\n",
    "\n",
    "    # 计算两个用户的模拟预编码器\n",
    "    P_analog1 = compute_user_analog_precoder(H1)  # 用户1的模拟预编码器 [b, T, 1, N_t, 2]\n",
    "    P_analog2 = compute_user_analog_precoder(H2)  # 用户2的模拟预编码器 [b, T, 1, N_t, 2]\n",
    "\n",
    "    def compute_base_analog_combiner(H):\n",
    "        \"\"\"\n",
    "        计算基站端的模拟合并器\n",
    "\n",
    "        输入:\n",
    "            H: 张量，形状为 [b, T, Nc, N_r, N_t]\n",
    "\n",
    "        输出:\n",
    "            C_analog_i: 张量，形状为 [b, T, 1, 1, N_r]\n",
    "        \"\"\"\n",
    "        # 置换维度，确保子载波和发送天线维度相邻\n",
    "        H_permuted = H.permute(0, 1, 2, 4, 3).contiguous()  # [b, T, Nc, N_t, N_r]\n",
    "\n",
    "        # 将子载波和发送天线维度展平\n",
    "        H_reshaped = H_permuted.view(b, T, Nc * N_t, N_r)  # [b, T, Nc*N_t, N_r]\n",
    "\n",
    "        # 对展平后的信道矩阵进行奇异值分解（SVD）\n",
    "        U, S, Vh = torch.linalg.svd(H_reshaped, full_matrices=False)  # Vh: [b, T, Nc*N_t, N_r]\n",
    "\n",
    "        # 取右奇异矩阵的共轭转置，得到 V 矩阵\n",
    "        V = Vh.conj().transpose(-2, -1)  # [b, T, N_r, Nc*N_t]\n",
    "\n",
    "        # 取前一个右奇异向量作为模拟合并器\n",
    "        C_analog_i = V[:, :, :, :1]  # [b, T, N_r, 1]\n",
    "\n",
    "        # 恒模约束：仅保留相位信息\n",
    "        C_analog_i = C_analog_i / (C_analog_i.abs() + 1e-8)  # 避免除零\n",
    "\n",
    "        # 调整维度以匹配输出形状 [b, T, 1, 1, N_r]\n",
    "        C_analog_i = C_analog_i.unsqueeze(2).permute(0, 1, 2, 4, 3)  # [b, T, 1, 1, N_r]\n",
    "\n",
    "        return C_analog_i\n",
    "\n",
    "    # 计算两个用户的模拟合并器\n",
    "    C_analog1 = compute_base_analog_combiner(H1)  # 用户1的模拟合并器 [b, T, 1, 1, N_r]\n",
    "    C_analog2 = compute_base_analog_combiner(H2)  # 用户2的模拟合并器 [b, T, 1, 1, N_r]\n",
    "\n",
    "    # 将两个用户的模拟合并器拼接到基站端的2个射频链路\n",
    "    C_analog = torch.cat([C_analog1, C_analog2], dim=3)  # [b, T, 1, 2, N_r]\n",
    "\n",
    "    def compute_digital_precoder(H, P_analog):\n",
    "        \"\"\"\n",
    "        计算用户端的数字预编码器\n",
    "\n",
    "        输入:\n",
    "            H: 张量，形状为 [b, T, Nc, N_r, N_t]\n",
    "            P_analog: 张量，形状为 [b, T, 1, N_t, 2]\n",
    "\n",
    "        输出:\n",
    "            P_digital: 张量，形状为 [b, T, Nc, 2, 1]\n",
    "        \"\"\"\n",
    "        # 计算 H * P_analog -> [b, T, Nc, N_r, 2]\n",
    "        H_P = torch.matmul(H, P_analog)  # [b, T, Nc, N_r, 2]\n",
    "\n",
    "        # 将 H_P 重塑为 [b*T*Nc, N_r, 2] 以进行批量 SVD\n",
    "        H_P_reshaped = H_P.view(-1, H_P.shape[-2], H_P.shape[-1])  # [b*T*Nc, N_r, 2]\n",
    "\n",
    "        # 对每个子载波的等效信道进行奇异值分解（SVD）\n",
    "        U, S, Vh = torch.linalg.svd(H_P_reshaped, full_matrices=False)  # Vh: [b*T*Nc, 2, 2]\n",
    "\n",
    "        # 取前一个右奇异向量作为数字预编码器\n",
    "        P_digital = Vh[:, :1, :].conj().transpose(-2, -1)  # [b*T*Nc, 2, 1]\n",
    "\n",
    "        # 恢复到原始形状 [b, T, Nc, 2, 1]\n",
    "        P_digital = P_digital.view(b, T, Nc, 2, 1)  # [b, T, Nc, 2, 1]\n",
    "\n",
    "        return P_digital  # [b, T, Nc, 2, 1]\n",
    "\n",
    "    # 计算两个用户的数字预编码器\n",
    "    P_digital1 = compute_digital_precoder(H1, P_analog1)  # 用户1数字预编码器 [b, T, Nc, 2, 1]\n",
    "    P_digital2 = compute_digital_precoder(H2, P_analog2)  # 用户2数字预编码器 [b, T, Nc, 2, 1]\n",
    "\n",
    "    def compute_digital_combiner(C_analog, H, P_analog, P_digital):\n",
    "        \"\"\"\n",
    "        计算数字合并器的等效信道\n",
    "\n",
    "        输入:\n",
    "            C_analog: 张量，形状为 [b, T, 1, 2, N_r]\n",
    "            H: 张量，形状为 [b, T, Nc, N_r, N_t]\n",
    "            P_analog: 张量，形状为 [b, T, 1, N_t, 2]\n",
    "            P_digital: 张量，形状为 [b, T, Nc, 2, 1]\n",
    "\n",
    "        输出:\n",
    "            H_eff: 张量，形状为 [b, T, Nc, 2, 1]\n",
    "        \"\"\"\n",
    "        # 计算 H * P_analog -> [b, T, Nc, N_r, 2]\n",
    "        H_eff = C_analog @ H @ P_analog @ P_digital  # [b, T, Nc, 2, 1]\n",
    "\n",
    "\n",
    "        return H_eff  # [b, T, Nc, 2, 1]\n",
    "\n",
    "    # 计算两个用户的等效信道\n",
    "    H_eff1 = compute_digital_combiner(C_analog, H1, P_analog1, P_digital1)  # 用户1等效信道 [b, T, Nc, 2, 1]\n",
    "    H_eff2 = compute_digital_combiner(C_analog, H2, P_analog2, P_digital2)  # 用户2等效信道 [b, T, Nc, 2, 1]\n",
    "\n",
    "    # 拼接两个用户的等效信道，形成 [b, T, Nc, 2, 2]\n",
    "    H_eff_stack = torch.cat([H_eff1, H_eff2], dim=-1)  # [b, T, Nc, 2, 2]\n",
    "\n",
    "    def compute_zf_digital_combiner(H_eff_stack):\n",
    "        \"\"\"\n",
    "        计算基站端的数字合并器，使用零迫（ZF）方法\n",
    "\n",
    "        输入:\n",
    "            H_eff_stack: 张量，形状为 [b, T, Nc, 2, 2]\n",
    "\n",
    "        输出:\n",
    "            C_digital: 张量，形状为 [b, T, Nc, 2, 2]\n",
    "        \"\"\"\n",
    "        # 计算数字合并器 W = (H_eff^H * H_eff)^{-1} * H_eff^H\n",
    "        # 首先计算 H_eff^H\n",
    "        H_eff_H = H_eff_stack.conj().transpose(-2, -1)  # [b, T, Nc, 2, 2]\n",
    "\n",
    "        # 计算 H_eff^H * H_eff\n",
    "        H_eff_H_H_eff = torch.matmul(H_eff_H, H_eff_stack)  # [b, T, Nc, 2, 2]\n",
    "\n",
    "        # 计算 (H_eff^H * H_eff)^{-1}\n",
    "        H_eff_H_H_eff_inv = torch.linalg.inv(H_eff_H_H_eff)  # [b, T, Nc, 2, 2]\n",
    "\n",
    "        # 计算 W = (H_eff^H * H_eff)^{-1} * H_eff^H\n",
    "        C_digital = torch.matmul(H_eff_H_H_eff_inv, H_eff_H)  # [b, T, Nc, 2, 2]\n",
    "\n",
    "        return C_digital  # [b, T, Nc, 2, 2]\n",
    "\n",
    "    # 计算基站端数字合并器\n",
    "    C_digital = compute_zf_digital_combiner(H_eff_stack)  # [b, T, Nc, 2, 2]\n",
    "\n",
    "    # 最终输出\n",
    "    return P_analog1,P_analog2,C_analog,P_digital1,P_digital2,C_digital\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 0\n",
    "Nc = 100\n",
    "N = 2\n",
    "Nt = [1,8]\n",
    "Nr = [1,64]\n",
    "N_r_RF = 2\n",
    "N_t_RF = 2\n",
    "SNR_dB = -25\n",
    "v_max_km = 120\n",
    "T = 1\n",
    "b=16\n",
    "N_t = Nt[0]*Nt[1]\n",
    "N_r = Nr[0]*Nr[1]\n",
    "alpha,A_r,A_t,fd,tau = SV_Channel_set(2*b,Nc,N,Nt,Nr,1,v_max_km)\n",
    "H_batch = torch.zeros(2*b,T, Nc, N_r, N_t).cuda() + 0j\n",
    "\n",
    "for i in range(T):\n",
    "    t = i*1/14000/8 #i就表示第i个OFDM符号，每个subframe时间是1ms，每个slot包含14个OFDM符号，当子载波间隔15kHz对应一个frame包含1个slot，30kHz对应2个，60kHz->4,120kHz->8,这里采用120kHz间隔所以除以8\n",
    "    H = SV_Channel_final(2*b,Nc,N,Nt,Nr,1,t,alpha,A_r,A_t,fd,tau)\n",
    "    H_batch[:,i] = H\n",
    "H_batch_1 = H_batch[0:b]\n",
    "H_batch_2 = H_batch[b:2*b]\n",
    "\n",
    "P_analog1,P_analog2,C_analog,P_digital1,P_digital2,C_digital = Pre_PCA(H_batch_1, H_batch_2)\n",
    "\n",
    "# 打印输出形状以验证\n",
    "print(\"用户1端模拟预编码器 P_analog1 的形状:\", P_analog1.shape)    # [b, T, 1, N_t, 2]\n",
    "print(\"用户2端模拟预编码器 P_analog2 的形状:\", P_analog2.shape)    # [b, T, 1, N_t, 2]\n",
    "print(\"基站端模拟合并器 C_analog 的形状:\", C_analog.shape)           # [b, T, 1, 2, N_r]\n",
    "print(\"用户1端数字预编码器 P_digital1 的形状:\", P_digital1.shape)  # [b, T, Nc, 2, 1]\n",
    "print(\"用户2端数字预编码器 P_digital2 的形状:\", P_digital2.shape)  # [b, T, Nc, 2, 1]\n",
    "print(\"基站端数字合并器 C_digital 的形状:\", C_digital.shape)         # [b, T, Nc, 2, 2]\n",
    "\n",
    "SNR_dB = 10\n",
    "L = 0\n",
    "F_1 = P_analog1 @ P_digital1\n",
    "F_2 = P_analog2 @ P_digital2\n",
    "W = C_digital @ C_analog\n",
    "# W = torch.randn(b, T, Nc, 2, N_r).cuda() + 1j*torch.randn(b, T, Nc, 2, N_r).cuda()\n",
    "R1 = calculate_average_channel_capacity(H_batch_1[:,L], F_1[:,L], W[:,L], SNR_dB)\n",
    "R2 = calculate_average_channel_capacity(H_batch_2[:,L], F_2[:,L], W[:,L], SNR_dB)\n",
    "print(\"R1:\", R1.mean(),\";  R2:\", R2.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 物理层预编码合并插值外推函数完整版"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "### 时域和频域插值外推\n",
    "def interpolate_upsample(x, scale_factors, mode='bilinear', align_corners=False):\n",
    "    \"\"\"\n",
    "    使用双线性插值对张量 x 在时间和频域维度上进行上采样。\n",
    "    \n",
    "    参数:\n",
    "        x (torch.Tensor): 输入张量，形状为 [b, T, Nc, N_r, N_t]。\n",
    "        scale_factors (tuple): 时间和频域的上采样因子 (scale_time, scale_freq)。\n",
    "        mode (str): 插值模式，默认为 'bilinear'。\n",
    "        align_corners (bool): 插值参数，默认为 False。\n",
    "    \n",
    "    返回:\n",
    "        x_up (torch.Tensor): 上采样后的张量，形状为 [b, T*scale_time, Nc*scale_freq, N_r, N_t]。\n",
    "    \"\"\"\n",
    "    scale_time, scale_freq = scale_factors\n",
    "    \n",
    "    # Reshape to [b * N_r * N_t, 1, T, Nc] for 2D interpolation\n",
    "    b, T, Nc, N_r, N_t = x.shape\n",
    "    x_reshaped = x.permute(0, 3, 4, 1, 2).contiguous().view(b * N_r * N_t, 1, T, Nc)\n",
    "    \n",
    "    # Perform 2D interpolation on time and frequency dimensions\n",
    "    x_up = F.interpolate(x_reshaped, scale_factor=(scale_time, scale_freq), mode=mode, align_corners=align_corners)\n",
    "    \n",
    "    # Reshape back to [b, T*scale_time, Nc*scale_freq, N_r, N_t]\n",
    "    b_new, _, T_up, Nc_up = x_up.shape\n",
    "    x_up = x_up.view(b, N_r, N_t, T_up, Nc_up).permute(0, 3, 4, 1, 2).contiguous()\n",
    "    \n",
    "    return x_up\n",
    "def Subcar_Interp(H1, H2, rate1, rate2):\n",
    "    \"\"\"\n",
    "    对下采样后的信道 H1 和 H2 进行时间域和频域的插值上采样，恢复到完整的维度。\n",
    "    \n",
    "    参数:\n",
    "        H1 (torch.Tensor): 下采样后的信道矩阵，形状为 [b, T_down, Nc_down, N_r, N_t]，复数类型。\n",
    "        H2 (torch.Tensor): 下采样后的信道矩阵，形状为 [b, T_down, Nc_down, N_r, N_t]，复数类型。\n",
    "        rate1 (int): 时间域上采样因子（多普勒域）。\n",
    "        rate2 (int): 频域上采样因子（延时域）。\n",
    "    \n",
    "    返回:\n",
    "        H1_up (torch.Tensor): 上采样后的 H1，形状为 [b, T*rate1, Nc*rate2, N_r, N_t]。\n",
    "        H2_up_freq_shifted (torch.Tensor): 上采样并频率偏移后的 H2，形状为 [b, T*rate1, Nc*rate2, N_r, N_t]。\n",
    "    \"\"\"\n",
    "    # 分离实部和虚部进行插值\n",
    "    H1_real = H1.real\n",
    "    H1_imag = H1.imag\n",
    "    H2_real = H2.real\n",
    "    H2_imag = H2.imag\n",
    "    \n",
    "    # Perform interpolation on real and imaginary parts\n",
    "    H1_up_real = interpolate_upsample(H1_real, scale_factors=(rate1, rate2), mode='bilinear', align_corners=False)\n",
    "    H1_up_imag = interpolate_upsample(H1_imag, scale_factors=(rate1, rate2), mode='bilinear', align_corners=False)\n",
    "    H2_up_real = interpolate_upsample(H2_real, scale_factors=(rate1, rate2), mode='bilinear', align_corners=False)\n",
    "    H2_up_imag = interpolate_upsample(H2_imag, scale_factors=(rate1, rate2), mode='bilinear', align_corners=False)\n",
    "    \n",
    "    # Reconstruct complex tensors\n",
    "    H1_up = torch.complex(H1_up_real, H1_up_imag)\n",
    "    H2_up = torch.complex(H2_up_real, H2_up_imag)\n",
    "    \n",
    "    # Frequency shift for H2_up\n",
    "    H1_up = torch.roll(H1_up, shifts=-rate2//2, dims=2)  # Shift along frequency dimension\n",
    "    \n",
    "    return H1_up, H2_up\n",
    "def Pre_PCA_total(H1, H2,  H1_UE, H2_UE, H1_base, H2_base, SNR_dB, rate1, rate2):\n",
    "    \"\"\"\n",
    "    MIMO预编码函数 Pre_PCA\n",
    "\n",
    "    参数:\n",
    "        H1: 张量，形状为 [b, Q, Nc, N_r, N_t]，用户1到基站的信道矩阵\n",
    "        H2: 张量，形状为 [b, Q, Nc, N_r, N_t]，用户2到基站的信道矩阵\n",
    "        H1_UE: 张量，形状为 [b, 1, Nc, N_r, N_t]，用户端信道估计的信道 用户1到基站的信道矩阵\n",
    "        H2_UE: 张量，形状为 [b, 1, Nc, N_r, N_t]，用户端信道估计的信道 用户2到基站的信道矩阵\n",
    "        H1_base: 张量，形状为 [b, 1, Nc, N_r, N_t]，基站端CSI反馈重建的信道 用户1到基站的信道矩阵\n",
    "        H2_base: 张量，形状为 [b, 1, Nc, N_r, N_t]，基站端CSI反馈重建的信道 用户2到基站的信道矩阵\n",
    "    返回:\n",
    "        {\n",
    "            'P_analog1': 用户1模拟预编码器，形状 [b, T, 1, N_t, 2],\n",
    "            'P_analog2': 用户2模拟预编码器，形状 [b, T, 1, N_t, 2],\n",
    "            'C_analog': 基站端模拟合并器，形状 [b, T, 1, 2, N_r],\n",
    "            'P_digital1': 用户1数字预编码器，形状 [b, T, Nc, 2, 1],\n",
    "            'P_digital2': 用户2数字预编码器, 形状 [b, T, Nc, 2, 1],\n",
    "            'C_digital': 基站端数字合并器，形状 [b, T, Nc, 2, 2]\n",
    "        }\n",
    "    \"\"\"\n",
    "    # 获取输入信道矩阵的尺寸信息\n",
    "    b, Q, Nc, N_r, N_t = H1.shape\n",
    "    N_RF = 2  # 射频链路数\n",
    "\n",
    "    def compute_user_analog_precoder(H):\n",
    "        T = 1\n",
    "        \"\"\"\n",
    "        计算用户端的模拟预编码器\n",
    "\n",
    "        输入:\n",
    "            H: 张量，形状为 [b, T, Nc, N_r, N_t]\n",
    "\n",
    "        输出:\n",
    "            P_analog: 张量，形状为 [b, T, 1, N_t, 2]\n",
    "        \"\"\"\n",
    "        # 将子载波和接收天线维度展平\n",
    "        H_reshaped = H.view(b, T, Nc * N_r, N_t)  # [b, T, Nc*N_r, N_t]\n",
    "\n",
    "        # 对展平后的信道矩阵进行奇异值分解（SVD）\n",
    "        U, S, Vh = torch.linalg.svd(H_reshaped, full_matrices=False)  # Vh: [b, T, Nc*N_r, N_t]\n",
    "\n",
    "        # 取右奇异矩阵的共轭转置，得到 V 矩阵\n",
    "        V = Vh.conj().transpose(-2, -1)  # [b, T, N_t, Nc*N_r]\n",
    "\n",
    "        # 取前两个右奇异向量作为模拟预编码器\n",
    "        P_analog = V[:, :, :, :N_RF]  # [b, T, N_t, 2]\n",
    "\n",
    "        # 恒模约束：仅保留相位信息\n",
    "        P_analog = P_analog / (P_analog.abs() + 1e-8)  # 避免除零\n",
    "\n",
    "        # 调整维度以匹配输出形状 [b, T, 1, N_t, 2]\n",
    "        P_analog = P_analog.unsqueeze(2)  # [b, T, 1, N_t, 2]\n",
    "\n",
    "        return P_analog\n",
    "\n",
    "    # 计算两个用户的模拟预编码器\n",
    "    P_analog1 = compute_user_analog_precoder(H1_UE)  # 用户1的模拟预编码器 [b, 1, 1, N_t, 2]\n",
    "    P_analog2 = compute_user_analog_precoder(H2_UE)  # 用户2的模拟预编码器 [b, 1, 1, N_t, 2]\n",
    "\n",
    "    def compute_base_analog_combiner(H):\n",
    "        T = 1\n",
    "        \"\"\"\n",
    "        计算基站端的模拟合并器\n",
    "\n",
    "        输入:\n",
    "            H: 张量，形状为 [b, T, Nc, N_r, N_t]\n",
    "\n",
    "        输出:\n",
    "            C_analog_i: 张量，形状为 [b, T, 1, 1, N_r]\n",
    "        \"\"\"\n",
    "        # 置换维度，确保子载波和发送天线维度相邻\n",
    "        H_permuted = H.permute(0, 1, 2, 4, 3).contiguous()  # [b, T, Nc, N_t, N_r]\n",
    "\n",
    "        # 将子载波和发送天线维度展平\n",
    "        H_reshaped = H_permuted.view(b, T, Nc * N_t, N_r)  # [b, T, Nc*N_t, N_r]\n",
    "\n",
    "        # 对展平后的信道矩阵进行奇异值分解（SVD）\n",
    "        U, S, Vh = torch.linalg.svd(H_reshaped, full_matrices=False)  # Vh: [b, T, Nc*N_t, N_r]\n",
    "\n",
    "        # 取右奇异矩阵的共轭转置，得到 V 矩阵\n",
    "        V = Vh.conj().transpose(-2, -1)  # [b, T, N_r, Nc*N_t]\n",
    "\n",
    "        # 取前一个右奇异向量作为模拟合并器\n",
    "        C_analog_i = V[:, :, :, :1]  # [b, T, N_r, 1]\n",
    "\n",
    "        # 恒模约束：仅保留相位信息\n",
    "        C_analog_i = C_analog_i / (C_analog_i.abs() + 1e-8)  # 避免除零\n",
    "\n",
    "        # 调整维度以匹配输出形状 [b, T, 1, 1, N_r]\n",
    "        C_analog_i = C_analog_i.unsqueeze(2).permute(0, 1, 2, 4, 3)  # [b, T, 1, 1, N_r]\n",
    "\n",
    "        return C_analog_i\n",
    "\n",
    "    # 计算两个用户的模拟合并器\n",
    "    C_analog1 = compute_base_analog_combiner(H1_base)  # 用户1的模拟合并器 [b, 1, 1, 1, N_r]\n",
    "    C_analog2 = compute_base_analog_combiner(H2_base)  # 用户2的模拟合并器 [b, 1, 1, 1, N_r]\n",
    "\n",
    "    # 将两个用户的模拟合并器拼接到基站端的2个射频链路\n",
    "    C_analog = torch.cat([C_analog1, C_analog2], dim=3)  # [b, 1, 1, 2, N_r]\n",
    "\n",
    "    def compute_digital_precoder(H, P_analog):\n",
    "        T = 1\n",
    "        \"\"\"\n",
    "        计算用户端的数字预编码器\n",
    "\n",
    "        输入:\n",
    "            H: 张量，形状为 [b, T, Nc, N_r, N_t]\n",
    "            P_analog: 张量，形状为 [b, T, 1, N_t, 2]\n",
    "\n",
    "        输出:\n",
    "            P_digital: 张量，形状为 [b, T, Nc, 2, 1]\n",
    "        \"\"\"\n",
    "        # 计算 H * P_analog -> [b, T, Nc, N_r, 2]\n",
    "        H_P = torch.matmul(H, P_analog)  # [b, T, Nc, N_r, 2]\n",
    "\n",
    "        # 将 H_P 重塑为 [b*T*Nc, N_r, 2] 以进行批量 SVD\n",
    "        H_P_reshaped = H_P.view(-1, H_P.shape[-2], H_P.shape[-1])  # [b*T*Nc, N_r, 2]\n",
    "\n",
    "        # 对每个子载波的等效信道进行奇异值分解（SVD）\n",
    "        U, S, Vh = torch.linalg.svd(H_P_reshaped, full_matrices=False)  # Vh: [b*T*Nc, 2, 2]\n",
    "\n",
    "        # 取前一个右奇异向量作为数字预编码器\n",
    "        P_digital = Vh[:, :1, :].conj().transpose(-2, -1)  # [b*T*Nc, 2, 1]\n",
    "\n",
    "        # 恢复到原始形状 [b, T, Nc, 2, 1]\n",
    "        P_digital = P_digital.view(b, T, Nc, 2, 1)  # [b, T, Nc, 2, 1]\n",
    "\n",
    "        return P_digital  # [b, T, Nc, 2, 1]\n",
    "\n",
    "    # 计算两个用户的数字预编码器\n",
    "    P_digital1 = compute_digital_precoder(H1_UE, P_analog1)  # 用户1数字预编码器 [b, 1, Nc, 2, 1]\n",
    "    P_digital2 = compute_digital_precoder(H2_UE, P_analog2)  # 用户2数字预编码器 [b, 1, Nc, 2, 1]\n",
    "\n",
    "    def compute_digital_combiner(C_analog, H, F):\n",
    "        \"\"\"\n",
    "        计算数字合并器的等效信道,实际在抽取之后就是接收DMRS导频（已加噪声）\n",
    "\n",
    "        输入:\n",
    "            C_analog: 张量，形状为 [b, 1, 1, 2, N_r]\n",
    "            H: 张量，形状为 [b, Q, Nc, N_r, N_t]\n",
    "            P_analog: 张量，形状为 [b, 1, 1, N_t, 2]\n",
    "            P_digital: 张量，形状为 [b, 1, Nc, 2, 1]\n",
    "\n",
    "        输出:\n",
    "            H_eff: 张量，形状为 [b, T, Nc, 2, 1]\n",
    "        \"\"\"\n",
    "       \n",
    "\n",
    "        \n",
    "        norm_factor = torch.sqrt(torch.sum(torch.abs(F)**2, dim=(-2, -1), keepdim=True))\n",
    "        F = F / norm_factor * torch.sqrt(torch.tensor(N_RF, dtype=H1.dtype, device=H1.device))  #[b, 1, 1, N_t, 1]\n",
    "\n",
    "        norm_factor = torch.sqrt(torch.sum(torch.abs(C_analog)**2, dim=(-2, -1), keepdim=True))\n",
    "        W = C_analog / norm_factor * torch.sqrt(torch.tensor(N_RF, dtype=H1.dtype, device=H1.device))\n",
    "\n",
    "        # Calculate effective channel\n",
    "        sigma = 10**(-SNR_dB/10)\n",
    "        n = (torch.randn(b,Q,Nc,N_RF,1).cuda() + 1j*torch.randn(b,Q,Nc,N_RF,1).cuda())/sqrt(2)*sqrt(sigma)\n",
    "        H_eff = W @ H @ F + n  # [b, Q, Nc, 2, 1]\n",
    "        # H_eff = W @ H @ F   # [b, Q, Nc, 2, 1]\n",
    "\n",
    "\n",
    "        return H_eff  # [b, Q, Nc, 2, 1]\n",
    "\n",
    "    # 计算两个用户的等效信道\n",
    "    F_1 = P_analog1 @ P_digital1\n",
    "    F_2 = P_analog2 @ P_digital2\n",
    "\n",
    "    norm_factor = torch.sqrt(torch.sum(torch.abs(F_1)**2, dim=(-2, -1), keepdim=True))\n",
    "    F_1 = F_1 / norm_factor * torch.sqrt(torch.tensor(N_RF, dtype=H1.dtype, device=H1.device))\n",
    "    norm_factor = torch.sqrt(torch.sum(torch.abs(F_2)**2, dim=(-2, -1), keepdim=True))\n",
    "    F_2 = F_2 / norm_factor * torch.sqrt(torch.tensor(N_RF, dtype=H1.dtype, device=H1.device))\n",
    "    norm_factor = torch.sqrt(torch.sum(torch.abs(C_analog)**2, dim=(-2, -1), keepdim=True))\n",
    "    C_analog = C_analog / norm_factor * torch.sqrt(torch.tensor(N_RF, dtype=H1.dtype, device=H1.device))\n",
    "\n",
    "    H_eff1 = compute_digital_combiner(C_analog, H1, F_1)  # 用户1等效信道 [b, Q, Nc, 2, 1]\n",
    "    H_eff2 = compute_digital_combiner(C_analog, H2, F_2)  # 用户2等效信道 [b, Q, Nc, 2, 1]\n",
    "\n",
    "    H_eff1_down = H_eff1[:, ::rate1, ::rate2, :, :]\n",
    "    H_eff2_down = H_eff2[:, ::rate1, rate2//2::rate2, :, :]\n",
    "    H_eff1_up, H_eff2_up = Subcar_Interp(H_eff1_down, H_eff2_down, rate1, rate2)\n",
    "\n",
    "    # print(NMSE(H_eff1_up,H_eff1))\n",
    "    # print(NMSE(H_eff2_up,H_eff2))\n",
    "\n",
    "    # 拼接两个用户的等效信道，形成 [b, T, Nc, 2, 2]\n",
    "    H_eff_stack = torch.cat([H_eff1_up, H_eff2_up], dim=-1)  # [b, Q, Nc, 2, 2]\n",
    "\n",
    "    def compute_zf_digital_combiner(H_eff_stack):\n",
    "        T = Q\n",
    "        \"\"\"\n",
    "        计算基站端的数字合并器，使用零迫（ZF）方法\n",
    "\n",
    "        输入:\n",
    "            H_eff_stack: 张量，形状为 [b, T, Nc, 2, 2]\n",
    "\n",
    "        输出:\n",
    "            C_digital: 张量，形状为 [b, T, Nc, 2, 2]\n",
    "        \"\"\"\n",
    "        # 计算数字合并器 W = (H_eff^H * H_eff)^{-1} * H_eff^H\n",
    "        # 首先计算 H_eff^H\n",
    "        H_eff_H = H_eff_stack.conj().transpose(-2, -1)  # [b, T, Nc, 2, 2]\n",
    "\n",
    "        # 计算 H_eff^H * H_eff\n",
    "        H_eff_H_H_eff = torch.matmul(H_eff_H, H_eff_stack)  # [b, T, Nc, 2, 2]\n",
    "\n",
    "        # 计算 (H_eff^H * H_eff)^{-1}\n",
    "        H_eff_H_H_eff_inv = torch.linalg.inv(H_eff_H_H_eff)  # [b, T, Nc, 2, 2]\n",
    "\n",
    "        # 计算 W = (H_eff^H * H_eff)^{-1} * H_eff^H\n",
    "        C_digital = torch.matmul(H_eff_H_H_eff_inv, H_eff_H)  # [b, T, Nc, 2, 2]\n",
    "\n",
    "        return C_digital  # [b, T, Nc, 2, 2]\n",
    "\n",
    "    # 计算基站端数字合并器\n",
    "    C_digital = compute_zf_digital_combiner(H_eff_stack)  # [b, Q, Nc, 2, 2]\n",
    "\n",
    "    W = C_digital @ C_analog\n",
    "\n",
    "\n",
    "\n",
    "    # 最终输出\n",
    "    return P_analog1,P_analog2,C_analog,P_digital1,P_digital2,C_digital, F_1, F_2, W\n",
    "\n",
    "def Pre_PCA_total_analog(H1, H2,  H1_UE, H2_UE, H1_base, H2_base, SNR_dB, rate1, rate2):\n",
    "    \"\"\"\n",
    "    MIMO预编码函数 Pre_PCA\n",
    "\n",
    "    参数:\n",
    "        H1: 张量，形状为 [b, Q, Nc, N_r, N_t]，用户1到基站的信道矩阵\n",
    "        H2: 张量，形状为 [b, Q, Nc, N_r, N_t]，用户2到基站的信道矩阵\n",
    "        H1_UE: 张量，形状为 [b, 1, Nc, N_r, N_t]，用户端信道估计的信道 用户1到基站的信道矩阵\n",
    "        H2_UE: 张量，形状为 [b, 1, Nc, N_r, N_t]，用户端信道估计的信道 用户2到基站的信道矩阵\n",
    "        H1_base: 张量，形状为 [b, 1, Nc, N_r, N_t]，基站端CSI反馈重建的信道 用户1到基站的信道矩阵\n",
    "        H2_base: 张量，形状为 [b, 1, Nc, N_r, N_t]，基站端CSI反馈重建的信道 用户2到基站的信道矩阵\n",
    "    返回:\n",
    "        {\n",
    "            'P_analog1': 用户1模拟预编码器，形状 [b, T, 1, N_t, 2],\n",
    "            'P_analog2': 用户2模拟预编码器，形状 [b, T, 1, N_t, 2],\n",
    "            'C_analog': 基站端模拟合并器，形状 [b, T, 1, 2, N_r],\n",
    "            'P_digital1': 用户1数字预编码器，形状 [b, T, Nc, 2, 1],\n",
    "            'P_digital2': 用户2数字预编码器, 形状 [b, T, Nc, 2, 1],\n",
    "            'C_digital': 基站端数字合并器，形状 [b, T, Nc, 2, 2]\n",
    "        }\n",
    "    \"\"\"\n",
    "    # 获取输入信道矩阵的尺寸信息\n",
    "    b, Q, Nc, N_r, N_t = H1.shape\n",
    "    N_RF = 2  # 射频链路数\n",
    "\n",
    "    def compute_user_analog_precoder(H):\n",
    "        T = 1\n",
    "        \"\"\"\n",
    "        计算用户端的模拟预编码器\n",
    "\n",
    "        输入:\n",
    "            H: 张量，形状为 [b, T, Nc, N_r, N_t]\n",
    "\n",
    "        输出:\n",
    "            P_analog: 张量，形状为 [b, T, 1, N_t, 2]\n",
    "        \"\"\"\n",
    "        # 将子载波和接收天线维度展平\n",
    "        H_reshaped = H.view(b, T, Nc * N_r, N_t)  # [b, T, Nc*N_r, N_t]\n",
    "\n",
    "        # 对展平后的信道矩阵进行奇异值分解（SVD）\n",
    "        U, S, Vh = torch.linalg.svd(H_reshaped, full_matrices=False)  # Vh: [b, T, Nc*N_r, N_t]\n",
    "\n",
    "        # 取右奇异矩阵的共轭转置，得到 V 矩阵\n",
    "        V = Vh.conj().transpose(-2, -1)  # [b, T, N_t, Nc*N_r]\n",
    "\n",
    "        # 取前1个右奇异向量作为模拟预编码器\n",
    "        P_analog = V[:, :, :, :1]  # [b, T, N_t, 1]\n",
    "\n",
    "        # 恒模约束：仅保留相位信息\n",
    "        P_analog = P_analog / (P_analog.abs() + 1e-8)  # 避免除零\n",
    "\n",
    "        # 调整维度以匹配输出形状 [b, T, 1, N_t, 1]\n",
    "        P_analog = P_analog.unsqueeze(2)  # [b, T, 1, N_t, 1]\n",
    "\n",
    "        return P_analog\n",
    "\n",
    "    # 计算两个用户的模拟预编码器\n",
    "    P_analog1 = compute_user_analog_precoder(H1_UE)  # 用户1的模拟预编码器 [b, 1, 1, N_t, 1]\n",
    "    P_analog2 = compute_user_analog_precoder(H2_UE)  # 用户2的模拟预编码器 [b, 1, 1, N_t, 1]\n",
    "\n",
    "    def compute_base_analog_combiner(H):\n",
    "        T = 1\n",
    "        \"\"\"\n",
    "        计算基站端的模拟合并器\n",
    "\n",
    "        输入:\n",
    "            H: 张量，形状为 [b, T, Nc, N_r, N_t]\n",
    "\n",
    "        输出:\n",
    "            C_analog_i: 张量，形状为 [b, T, 1, 1, N_r]\n",
    "        \"\"\"\n",
    "        # 置换维度，确保子载波和发送天线维度相邻\n",
    "        H_permuted = H.permute(0, 1, 2, 4, 3).contiguous()  # [b, T, Nc, N_t, N_r]\n",
    "\n",
    "        # 将子载波和发送天线维度展平\n",
    "        H_reshaped = H_permuted.view(b, T, Nc * N_t, N_r)  # [b, T, Nc*N_t, N_r]\n",
    "\n",
    "        # 对展平后的信道矩阵进行奇异值分解（SVD）\n",
    "        U, S, Vh = torch.linalg.svd(H_reshaped, full_matrices=False)  # Vh: [b, T, Nc*N_t, N_r]\n",
    "\n",
    "        # 取右奇异矩阵的共轭转置，得到 V 矩阵\n",
    "        V = Vh.conj().transpose(-2, -1)  # [b, T, N_r, Nc*N_t]\n",
    "\n",
    "        # 取前一个右奇异向量作为模拟合并器\n",
    "        C_analog_i = V[:, :, :, :1]  # [b, T, N_r, 1]\n",
    "\n",
    "        # 恒模约束：仅保留相位信息\n",
    "        C_analog_i = C_analog_i / (C_analog_i.abs() + 1e-8)  # 避免除零\n",
    "\n",
    "        # 调整维度以匹配输出形状 [b, T, 1, 1, N_r]\n",
    "        C_analog_i = C_analog_i.unsqueeze(2).permute(0, 1, 2, 4, 3)  # [b, T, 1, 1, N_r]\n",
    "\n",
    "        return C_analog_i\n",
    "\n",
    "    # 计算两个用户的模拟合并器\n",
    "    C_analog1 = compute_base_analog_combiner(H1_base)  # 用户1的模拟合并器 [b, 1, 1, 1, N_r]\n",
    "    C_analog2 = compute_base_analog_combiner(H2_base)  # 用户2的模拟合并器 [b, 1, 1, 1, N_r]\n",
    "\n",
    "    # 将两个用户的模拟合并器拼接到基站端的2个射频链路\n",
    "    C_analog = torch.cat([C_analog1, C_analog2], dim=3)  # [b, 1, 1, 2, N_r]\n",
    "\n",
    "    # def compute_digital_precoder(H, P_analog):\n",
    "    #     T = 1\n",
    "    #     \"\"\"\n",
    "    #     计算用户端的数字预编码器\n",
    "\n",
    "    #     输入:\n",
    "    #         H: 张量，形状为 [b, T, Nc, N_r, N_t]\n",
    "    #         P_analog: 张量，形状为 [b, T, 1, N_t, 2]\n",
    "\n",
    "    #     输出:\n",
    "    #         P_digital: 张量，形状为 [b, T, Nc, 2, 1]\n",
    "    #     \"\"\"\n",
    "    #     # 计算 H * P_analog -> [b, T, Nc, N_r, 2]\n",
    "    #     H_P = torch.matmul(H, P_analog)  # [b, T, Nc, N_r, 2]\n",
    "\n",
    "    #     # 将 H_P 重塑为 [b*T*Nc, N_r, 2] 以进行批量 SVD\n",
    "    #     H_P_reshaped = H_P.view(-1, H_P.shape[-2], H_P.shape[-1])  # [b*T*Nc, N_r, 2]\n",
    "\n",
    "    #     # 对每个子载波的等效信道进行奇异值分解（SVD）\n",
    "    #     U, S, Vh = torch.linalg.svd(H_P_reshaped, full_matrices=False)  # Vh: [b*T*Nc, 2, 2]\n",
    "\n",
    "    #     # 取前一个右奇异向量作为数字预编码器\n",
    "    #     P_digital = Vh[:, :1, :].conj().transpose(-2, -1)  # [b*T*Nc, 2, 1]\n",
    "\n",
    "    #     # 恢复到原始形状 [b, T, Nc, 2, 1]\n",
    "    #     P_digital = P_digital.view(b, T, Nc, 2, 1)  # [b, T, Nc, 2, 1]\n",
    "\n",
    "    #     return P_digital  # [b, T, Nc, 2, 1]\n",
    "\n",
    "    # # 计算两个用户的数字预编码器\n",
    "    # P_digital1 = compute_digital_precoder(H1_UE, P_analog1)  # 用户1数字预编码器 [b, 1, Nc, 2, 1]\n",
    "    # P_digital2 = compute_digital_precoder(H2_UE, P_analog2)  # 用户2数字预编码器 [b, 1, Nc, 2, 1]\n",
    "\n",
    "    def compute_digital_combiner(C_analog, H, F):\n",
    "        \"\"\"\n",
    "        计算数字合并器的等效信道,实际在抽取之后就是接收DMRS导频（已加噪声）\n",
    "\n",
    "        输入:\n",
    "            C_analog: 张量，形状为 [b, 1, 1, 2, N_r]\n",
    "            H: 张量，形状为 [b, Q, Nc, N_r, N_t]\n",
    "            P_analog: 张量，形状为 [b, 1, 1, N_t, 2]\n",
    "            P_digital: 张量，形状为 [b, 1, Nc, 2, 1]\n",
    "\n",
    "        输出:\n",
    "            H_eff: 张量，形状为 [b, T, Nc, 2, 1]\n",
    "        \"\"\"\n",
    "       \n",
    "\n",
    "        \n",
    "        norm_factor = torch.sqrt(torch.sum(torch.abs(F)**2, dim=(-2, -1), keepdim=True))\n",
    "        F = F / norm_factor * torch.sqrt(torch.tensor(N_RF, dtype=H1.dtype, device=H1.device))  #[b, 1, 1, N_t, 1]\n",
    "\n",
    "        norm_factor = torch.sqrt(torch.sum(torch.abs(C_analog)**2, dim=(-2, -1), keepdim=True))\n",
    "        W = C_analog / norm_factor * torch.sqrt(torch.tensor(N_RF, dtype=H1.dtype, device=H1.device))\n",
    "\n",
    "        # Calculate effective channel\n",
    "        sigma = 10**(-SNR_dB/10)\n",
    "        n = (torch.randn(b,Q,Nc,N_RF,1).cuda() + 1j*torch.randn(b,Q,Nc,N_RF,1).cuda())/sqrt(2)*sqrt(sigma)\n",
    "        H_eff = W @ H @ F + n  # [b, Q, Nc, 2, 1]\n",
    "        # H_eff = W @ H @ F   # [b, Q, Nc, 2, 1]\n",
    "\n",
    "\n",
    "        return H_eff  # [b, Q, Nc, 2, 1]\n",
    "\n",
    "    # 计算两个用户的等效信道\n",
    "    F_1 = P_analog1\n",
    "    F_2 = P_analog2\n",
    "\n",
    "    norm_factor = torch.sqrt(torch.sum(torch.abs(F_1)**2, dim=(-2, -1), keepdim=True))\n",
    "    F_1 = F_1 / norm_factor * torch.sqrt(torch.tensor(N_RF, dtype=H1.dtype, device=H1.device))\n",
    "    norm_factor = torch.sqrt(torch.sum(torch.abs(F_2)**2, dim=(-2, -1), keepdim=True))\n",
    "    F_2 = F_2 / norm_factor * torch.sqrt(torch.tensor(N_RF, dtype=H1.dtype, device=H1.device))\n",
    "    norm_factor = torch.sqrt(torch.sum(torch.abs(C_analog)**2, dim=(-2, -1), keepdim=True))\n",
    "    C_analog = C_analog / norm_factor * torch.sqrt(torch.tensor(N_RF, dtype=H1.dtype, device=H1.device))\n",
    "\n",
    "    H_eff1 = compute_digital_combiner(C_analog, H1, F_1)  # 用户1等效信道 [b, Q, Nc, 2, 1]\n",
    "    H_eff2 = compute_digital_combiner(C_analog, H2, F_2)  # 用户2等效信道 [b, Q, Nc, 2, 1]\n",
    "\n",
    "    H_eff1_down = H_eff1[:, ::rate1, ::rate2, :, :]\n",
    "    H_eff2_down = H_eff2[:, ::rate1, rate2//2::rate2, :, :]\n",
    "    H_eff1_up, H_eff2_up = Subcar_Interp(H_eff1_down, H_eff2_down, rate1, rate2)\n",
    "\n",
    "    # print(NMSE(H_eff1_up,H_eff1))\n",
    "    # print(NMSE(H_eff2_up,H_eff2))\n",
    "\n",
    "    # 拼接两个用户的等效信道，形成 [b, T, Nc, 2, 2]\n",
    "    H_eff_stack = torch.cat([H_eff1_up, H_eff2_up], dim=-1)  # [b, Q, Nc, 2, 2]\n",
    "\n",
    "    def compute_zf_digital_combiner(H_eff_stack):\n",
    "        T = Q\n",
    "        \"\"\"\n",
    "        计算基站端的数字合并器，使用零迫（ZF）方法\n",
    "\n",
    "        输入:\n",
    "            H_eff_stack: 张量，形状为 [b, T, Nc, 2, 2]\n",
    "\n",
    "        输出:\n",
    "            C_digital: 张量，形状为 [b, T, Nc, 2, 2]\n",
    "        \"\"\"\n",
    "        # 计算数字合并器 W = (H_eff^H * H_eff)^{-1} * H_eff^H\n",
    "        # 首先计算 H_eff^H\n",
    "        H_eff_H = H_eff_stack.conj().transpose(-2, -1)  # [b, T, Nc, 2, 2]\n",
    "\n",
    "        # 计算 H_eff^H * H_eff\n",
    "        H_eff_H_H_eff = torch.matmul(H_eff_H, H_eff_stack)  # [b, T, Nc, 2, 2]\n",
    "\n",
    "        # 计算 (H_eff^H * H_eff)^{-1}\n",
    "        H_eff_H_H_eff_inv = torch.linalg.inv(H_eff_H_H_eff)  # [b, T, Nc, 2, 2]\n",
    "\n",
    "        # 计算 W = (H_eff^H * H_eff)^{-1} * H_eff^H\n",
    "        C_digital = torch.matmul(H_eff_H_H_eff_inv, H_eff_H)  # [b, T, Nc, 2, 2]\n",
    "\n",
    "        return C_digital  # [b, T, Nc, 2, 2]\n",
    "\n",
    "    # 计算基站端数字合并器\n",
    "    C_digital = compute_zf_digital_combiner(H_eff_stack)  # [b, Q, Nc, 2, 2]\n",
    "\n",
    "    W = C_digital @ C_analog\n",
    "\n",
    "\n",
    "\n",
    "    # 最终输出\n",
    "    return P_analog1,P_analog2,C_analog,C_digital, F_1, F_2, W[:,0:Q]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 0\n",
    "Nc = 100\n",
    "N = 2\n",
    "Nt = [1,8]\n",
    "Nr = [1,64]\n",
    "N_r_RF = 2\n",
    "N_t_RF = 2\n",
    "v_max_km = 120\n",
    "L = 8\n",
    "Q = 12\n",
    "T = L+Q\n",
    "b=16\n",
    "N_t = Nt[0]*Nt[1]\n",
    "N_r = Nr[0]*Nr[1]\n",
    "alpha,A_r,A_t,fd,tau = SV_Channel_set(2*b,Nc,N,Nt,Nr,1,v_max_km)\n",
    "H_batch = torch.zeros(2*b,T, Nc, N_r, N_t).cuda() + 0j\n",
    "\n",
    "for i in range(T):\n",
    "    t = i*1/14000/8 #i就表示第i个OFDM符号，每个subframe时间是1ms，每个slot包含14个OFDM符号，当子载波间隔15kHz对应一个frame包含1个slot，30kHz对应2个，60kHz->4,120kHz->8,这里采用120kHz间隔所以除以8\n",
    "    H = SV_Channel_final(2*b,Nc,N,Nt,Nr,1,t,alpha,A_r,A_t,fd,tau)\n",
    "    H_batch[:,i] = H\n",
    "H_batch_1 = H_batch[0:b]\n",
    "H_batch_2 = H_batch[b:2*b]\n",
    "\n",
    "# rate1 (int): 时间域上DMRS采样因子。\n",
    "# rate2 (int): 频域上DMRS采样因子。\n",
    "rate1 = 4\n",
    "rate2 = 2\n",
    "SNR_dB = 10\n",
    "\n",
    "H1 = H_batch_1[:,L:L+Q] \n",
    "H2 = H_batch_2[:,L:L+Q] \n",
    "H1_UE = H_batch_1[:,L:L+1]\n",
    "H2_UE = H_batch_2[:,L:L+1]\n",
    "H1_base = H_batch_1[:,L:L+1]\n",
    "H2_base = H_batch_2[:,L:L+1]\n",
    "P_analog1,P_analog2,C_analog,C_digital,F_1, F_2, W = Pre_PCA_total_analog(H1, H2,  H1_UE, H2_UE, H1_base, H2_base, SNR_dB, rate1, rate2)\n",
    "\n",
    "# 打印输出形状以验证\n",
    "print(\"用户1端模拟预编码器 P_analog1 的形状:\", P_analog1.shape)    # [b, T, 1, N_t, 2]\n",
    "print(\"用户2端模拟预编码器 P_analog2 的形状:\", P_analog2.shape)    # [b, T, 1, N_t, 2]\n",
    "print(\"基站端模拟合并器 C_analog 的形状:\", C_analog.shape)           # [b, T, 1, 2, N_r]\n",
    "print(\"基站端数字合并器 C_digital 的形状:\", C_digital.shape)         # [b, T, Nc, 2, 2]\n",
    "\n",
    "\n",
    "# W = torch.randn(b, T, Nc, 2, N_r).cuda() + 1j*torch.randn(b, T, Nc, 2, N_r).cuda()\n",
    "R1 = calculate_average_channel_capacity_T(H1, F_1, W, SNR_dB)\n",
    "R2 = calculate_average_channel_capacity_T(H2, F_2, W, SNR_dB)\n",
    "print(\"R1:\", R1.mean().item(),\";  R2:\", R2.mean().item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 0\n",
    "Nc = 100\n",
    "N = 2\n",
    "Nt = [1,8]\n",
    "Nr = [1,64]\n",
    "N_r_RF = 2\n",
    "N_t_RF = 2\n",
    "v_max_km = 120\n",
    "L = 8\n",
    "Q = 12\n",
    "T = L+Q\n",
    "b=16\n",
    "N_t = Nt[0]*Nt[1]\n",
    "N_r = Nr[0]*Nr[1]\n",
    "alpha,A_r,A_t,fd,tau = SV_Channel_set(2*b,Nc,N,Nt,Nr,1,v_max_km)\n",
    "H_batch = torch.zeros(2*b,T, Nc, N_r, N_t).cuda() + 0j\n",
    "\n",
    "for i in range(T):\n",
    "    t = i*1/14000/8 #i就表示第i个OFDM符号，每个subframe时间是1ms，每个slot包含14个OFDM符号，当子载波间隔15kHz对应一个frame包含1个slot，30kHz对应2个，60kHz->4,120kHz->8,这里采用120kHz间隔所以除以8\n",
    "    H = SV_Channel_final(2*b,Nc,N,Nt,Nr,1,t,alpha,A_r,A_t,fd,tau)\n",
    "    H_batch[:,i] = H\n",
    "H_batch_1 = H_batch[0:b]\n",
    "H_batch_2 = H_batch[b:2*b]\n",
    "\n",
    "# rate1 (int): 时间域上DMRS采样因子。\n",
    "# rate2 (int): 频域上DMRS采样因子。\n",
    "rate1 = 4\n",
    "rate2 = 2\n",
    "SNR_dB = 10\n",
    "\n",
    "H1 = H_batch_1[:,L:L+Q] \n",
    "H2 = H_batch_2[:,L:L+Q] \n",
    "H1_UE = H_batch_1[:,L:L+1]\n",
    "H2_UE = H_batch_2[:,L:L+1]\n",
    "H1_base = H_batch_1[:,L:L+1]\n",
    "H2_base = H_batch_2[:,L:L+1]\n",
    "P_analog1,P_analog2,C_analog,P_digital1,P_digital2,C_digital,F_1, F_2, W = Pre_PCA_total(H1, H2,  H1_UE, H2_UE, H1_base, H2_base, SNR_dB, rate1, rate2)\n",
    "\n",
    "# 打印输出形状以验证\n",
    "print(\"用户1端模拟预编码器 P_analog1 的形状:\", P_analog1.shape)    # [b, T, 1, N_t, 2]\n",
    "print(\"用户2端模拟预编码器 P_analog2 的形状:\", P_analog2.shape)    # [b, T, 1, N_t, 2]\n",
    "print(\"基站端模拟合并器 C_analog 的形状:\", C_analog.shape)           # [b, T, 1, 2, N_r]\n",
    "print(\"用户1端数字预编码器 P_digital1 的形状:\", P_digital1.shape)  # [b, T, Nc, 2, 1]\n",
    "print(\"用户2端数字预编码器 P_digital2 的形状:\", P_digital2.shape)  # [b, T, Nc, 2, 1]\n",
    "print(\"基站端数字合并器 C_digital 的形状:\", C_digital.shape)         # [b, T, Nc, 2, 2]\n",
    "\n",
    "\n",
    "# W = torch.randn(b, T, Nc, 2, N_r).cuda() + 1j*torch.randn(b, T, Nc, 2, N_r).cuda()\n",
    "R1 = calculate_average_channel_capacity_T(H1, F_1, W, SNR_dB)\n",
    "R2 = calculate_average_channel_capacity_T(H2, F_2, W, SNR_dB)\n",
    "print(\"R1:\", R1.mean().item(),\";  R2:\", R2.mean().item())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WY信道估计"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 网络和训练函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from tqdm import trange\n",
    "from time import sleep\n",
    "from my_log import logger, rmLogger\n",
    "\n",
    "# 可训练的三个导频\n",
    "class Pilot_trans_WY(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            Nc,     #子载波数\n",
    "            N_r,    #基站接收天线数\n",
    "            N_r_RF, #基站射频数\n",
    "            N_t,    #用户发送天线数\n",
    "            N_t_RF, #用户发送射频数\n",
    "            L,      #导频OFDM符号数\n",
    "        ):\n",
    "        super().__init__();\n",
    "\n",
    "        self.N_r = N_r\n",
    "        self.L = L\n",
    "        self.N_t = N_t\n",
    "        self.N_t_RF = N_t_RF\n",
    "\n",
    "        # self.p_UE_1 = nn.Parameter(torch.randn(1, Nc, L, N_t, 1) + 1j*torch.randn(1, Nc, L, N_t, 1))\n",
    "        # self.p_UE_2 = nn.Parameter(torch.randn(1, Nc, L, N_t, 1) + 1j*torch.randn(1, Nc, L, N_t, 1))\n",
    "\n",
    "        # self.p_UE_1 = nn.Parameter(torch.randn(1, 1, L, N_t, 1) + 1j*torch.randn(1, 1, L, N_t, 1))\n",
    "        # self.p_UE_2 = nn.Parameter(torch.randn(1, 1, L, N_t, 1) + 1j*torch.randn(1, 1, L, N_t, 1))\n",
    "\n",
    "        self.p_BS_RF = nn.Parameter(torch.randn(1, 1, L, N_r, N_r_RF) + 1j*torch.randn(1, 1, L, N_r, N_r_RF))\n",
    "        self.p_BS_BB = nn.Parameter(torch.randn(1, Nc, L, N_r_RF, 1) + 1j*torch.randn(1, Nc, L, N_r_RF, 1))\n",
    "\n",
    "        self.p_UE = nn.Parameter(torch.randn(1, 1, L, N_t_RF, N_t) + 1j*torch.randn(1, 1, L, N_t_RF, N_t))\n",
    "\n",
    "    def forward(\n",
    "            self, \n",
    "            H_batch,  # b,T, Nc, N_r, N_t\n",
    "        ):\n",
    "\n",
    "\n",
    "        b,T, Nc, N_r, N_t = H_batch.shape\n",
    "        N_t_RF = self.N_t_RF\n",
    "        L = self.L\n",
    "        H_batch = H_batch[:,0:L].permute(0,2,1,4,3) # b, Nc, L, N_t, N_r\n",
    "\n",
    "\n",
    "        p_UE = self.p_UE/torch.abs(self.p_UE)/sqrt(self.N_t)\n",
    "        p_BS = self.p_BS_RF @ self.p_BS_BB\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        received_pilot = p_UE @ (H_batch @ p_BS) # b, Nc, L, N_t_RF, 1\n",
    "\n",
    "\n",
    "        norm_factor = torch.sqrt(torch.sum(torch.abs(received_pilot)**2, dim=(-4,-3,-2, -1), keepdim=True))\n",
    "        received_pilot = received_pilot / norm_factor * torch.sqrt(torch.tensor(Nc*L*N_t_RF, dtype=received_pilot.dtype, device=received_pilot.device))\n",
    "\n",
    "\n",
    "\n",
    "        return received_pilot   \n",
    "\n",
    "class pilot2H_WY(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            Nc,     #子载波数\n",
    "            N_r,    #基站接收天线数\n",
    "            N_r_RF, #基站射频数\n",
    "            N_t,    #用户发送天线数\n",
    "            N_t_RF, #用户发送射频数\n",
    "            L,      #导频OFDM符号数\n",
    "        ):\n",
    "        super().__init__();\n",
    "\n",
    "        self.d_model = 1024\n",
    "        self.N_t = N_t\n",
    "        self.N_t_RF = N_t_RF\n",
    "        self.N_r = N_r\n",
    "\n",
    "        # self.trans  = TRANS_BLOCK(tx*2,tx*2,512,4)\n",
    "\n",
    "        self.embed= nn.Linear(2*N_t_RF*L, self.d_model) \n",
    "        self.positional_embedding=nn.Parameter(torch.zeros(1, Nc, self.d_model));\n",
    "\n",
    "        self.backbone=nn.Sequential(  # b, K*T, d_model\n",
    "            *[nn.Sequential(\n",
    "                nn.TransformerEncoderLayer(\n",
    "                    d_model=self.d_model, \n",
    "                    nhead=8, \n",
    "                    dim_feedforward=4*self.d_model, \n",
    "                    dropout=0.0, \n",
    "                    activation=\"gelu\", \n",
    "                    batch_first=True,\n",
    "                    norm_first = True, \n",
    "                ), \n",
    "            ) for _ in range(6)], \n",
    "            nn.LayerNorm(self.d_model),\n",
    "        );  # b, K*T, d_model\n",
    "\n",
    "        self.head=nn.Sequential(  \n",
    "            nn.Linear(self.d_model, 2*N_r*N_t),  \n",
    "        );\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    def forward(\n",
    "            self, \n",
    "            received_pilot,  # b, Nc, L, N_t_RF, 1\n",
    "        ):\n",
    "        # b = H_DL_batch.shape[0]\n",
    "        # H_DL_batch_1 = H_DL_batch.reshape(b, 48, 4, 128,2,2)[:,:,:,:,0,:].conj() #这里加了conj是因为上下行信道之间有个共轭转置，所以共轭这部分需要conj回去消除掉\n",
    "        # H_DL_batch_2 = H_DL_batch.reshape(b, 48, 4, 128,2,2)[:,:,:,:,1,:].conj()\n",
    "\n",
    "        # H_DL_batch_beam_1 = (H_DL_batch_1*np.exp(1j*pi/2 * 0) + H_DL_batch_2*np.exp(1j*pi/2 * 0)).reshape(b,1,48,4,256)\n",
    "\n",
    "        b, Nc, L, N_t_RF, _ = received_pilot.shape\n",
    "        N_t = self.N_t\n",
    "        N_t_RF = self.N_t_RF\n",
    "        N_r = self.N_r\n",
    "\n",
    "        y_cat = received_pilot.reshape(b,Nc,L*N_t_RF) \n",
    "        y_cat=torch.cat([y_cat.real, y_cat.imag], dim=-1);  # b,Nc,2*L*N_t_RF\n",
    "\n",
    "        x = self.embed(y_cat) + self.positional_embedding  # b,Nc,d_model\n",
    "\n",
    "        x = self.backbone(x)   # b,Nc,d_model\n",
    "\n",
    "        H = self.head(x)  # b,Nc,2*N_r*N_t\n",
    "        H = H.reshape(b,Nc,N_r,N_t,2)\n",
    "        H_hat = H[:,:,:,:,0] + 1j*H[:,:,:,:,1]\n",
    "\n",
    "\n",
    "        return H_hat     #[b,Nc,N_r,N_t]\n",
    "\n",
    "\n",
    "class CE_WY(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            Nc,     #子载波数\n",
    "            N_r,    #基站接收天线数\n",
    "            N_r_RF, #基站射频数\n",
    "            N_t,    #用户发送天线数\n",
    "            N_t_RF, #用户发送射频数\n",
    "            L,      #导频OFDM符号数\n",
    "        ):\n",
    "        super().__init__();\n",
    "\n",
    "        \n",
    "        self.Pilot_trans = Pilot_trans_WY(Nc,N_r,N_r_RF,N_t,N_t_RF,L)\n",
    "        self.pilot2H = pilot2H_WY(Nc,N_r,N_r_RF,N_t,N_t_RF,L)\n",
    "\n",
    "       \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    def forward(\n",
    "            self, \n",
    "            H_batch,  # b,T, Nc, N_r, N_t 用户1\n",
    "        ):\n",
    "        received_pilot = self.Pilot_trans(H_batch)\n",
    "        H_hat = self.pilot2H(received_pilot)\n",
    "        return H_hat\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SGCS_H(H1, H2):\n",
    "    tx=H1.shape[-1];\n",
    "    rx=H1.shape[-2]\n",
    "    v1=H1.to(torch.complex64);\n",
    "    v2=H2.to(torch.complex64);\n",
    "\n",
    "\n",
    "    v1=v1.reshape(-1, 1, rx*tx);\n",
    "    v2=v2.reshape(-1, 1, rx*tx);\n",
    "\n",
    "    tmp12=(v1@v2.mH).abs();\n",
    "    tmp11=(v1@v1.mH).abs();\n",
    "    tmp22=(v2@v2.mH).abs();\n",
    "\n",
    "    SGCS=tmp12.square()/tmp11/tmp22;\n",
    "\n",
    "    return -SGCS.mean();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_CE_WY(N,Nc,Nr,N_r_RF,Nt,N_t_RF,L,SNR_dB,v_max_km,v_max_km_pre=None,ITERS=20_000,b=32,acc_num=1):\n",
    "    # N代表路径数\n",
    "    \n",
    "    N_t = Nt[0]*Nt[1]\n",
    "    N_r = Nr[0]*Nr[1]\n",
    "    device=0;\n",
    "    lr=1e-4;\n",
    "    log_interval=100; # 每100个输出保存一下许训练记录\n",
    "    save_interval=10*log_interval; # 每1000个测试一下保存记录\n",
    "    iter_begin=0;   #从第0个开始训练 如果不是0就读取之前训练过的check points\n",
    "    save_path=\"./weights/\";\n",
    "    best_loss=10;\n",
    "\n",
    "    model_name = 'CE_WY'+'_L' + str(L)+'_v' + str(v_max_km)\n",
    "\n",
    "    dec=CE_WY(Nc=Nc,N_r=N_r,N_r_RF=N_r_RF,N_t=N_t,N_t_RF=N_t_RF,L=L).cuda()\n",
    "    \n",
    "    opt_dec=torch.optim.AdamW(\n",
    "        dec.parameters(), \n",
    "        lr=lr, \n",
    "    )\n",
    "    T = L+1\n",
    "    load_path=save_path+\"CE_WY\"+\"/\";\n",
    "    if v_max_km_pre == None:\n",
    "        print('从头训练')\n",
    "    else:\n",
    "        dec_dict = dec.state_dict()\n",
    "        model_name_pre = 'CE_WY' + '_L' + str(L)+'_v' + str(v_max_km_pre)\n",
    "        dec_load_path=load_path+model_name_pre+\"_model.pth.tar\";\n",
    "        ckpt=torch.load(dec_load_path, map_location=\"cuda:\"+str(device));\n",
    "        pretrained_dict=ckpt['state_dict'];\n",
    "        pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in dec_dict and \".quan\" not in k and \".Dequan\" not in k}\n",
    "        dec_dict.update(pretrained_dict);\n",
    "        dec.load_state_dict(dec_dict);\n",
    "        print('全部预训练参数读取成功')\n",
    "\n",
    "    def step(step_id):\n",
    "        dec.train();\n",
    "        opt_dec.zero_grad();\n",
    "        loss_acc=0;\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        for _ in range(acc_num):\n",
    "            alpha,A_r,A_t,fd,tau = SV_Channel_set(b,Nc,N,Nt,Nr,1,v_max_km)\n",
    "            H_batch = torch.zeros(b,T, Nc, N_r, N_t).cuda() + 0j\n",
    "\n",
    "            for i in range(T):\n",
    "                t = i*1/14000/8 #i就表示第i个OFDM符号，每个subframe时间是1ms，每个slot包含14个OFDM符号，当子载波间隔15kHz对应一个frame包含1个slot，30kHz对应2个，60kHz->4,120kHz->8,这里采用120kHz间隔所以除以8\n",
    "                H = SV_Channel_final(b,Nc,N,Nt,Nr,1,t,alpha,A_r,A_t,fd,tau)\n",
    "                H_batch[:,i] = H\n",
    "            # H_batch_1 = H_batch[0:b]\n",
    "            # H_batch_2 = H_batch[b:2*b]\n",
    "\n",
    "            \n",
    "\n",
    "            \n",
    "            H_hat=dec(\n",
    "                    H_batch = H_batch,  # b,T, Nc, N_r, N_t 用户1\n",
    "                );\n",
    "            # H_hat # b,Nc, N_r, N_t 用户1\n",
    "\n",
    "\n",
    "\n",
    "            # loss_SE = -calculate_average_channel_capacity(H_DL_batch_beam[:,0:1], F, Pt,N0)/acc_num\n",
    "\n",
    "            loss = SGCS_H(H_batch[:,L],H_hat)/acc_num\n",
    "            loss_acc += loss.item()\n",
    "\n",
    "            loss.backward();\n",
    "        \n",
    "\n",
    "        opt_dec.step();\n",
    "\n",
    "        return loss_acc\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def evaluate(step_id):\n",
    "        global loader_test;\n",
    "        dec.eval();\n",
    "        loss_acc=0;\n",
    "        val_num = 10\n",
    "        b = 64\n",
    "        with torch.no_grad():\n",
    "            for i in range(val_num):\n",
    "\n",
    "                alpha,A_r,A_t,fd,tau = SV_Channel_set(b,Nc,N,Nt,Nr,1,v_max_km)\n",
    "                H_batch = torch.zeros(b,T, Nc, N_r, N_t).cuda() + 0j\n",
    "\n",
    "                for i in range(T):\n",
    "                    t = i*1/14000/8\n",
    "                    H = SV_Channel_final(b,Nc,N,Nt,Nr,1,t,alpha,A_r,A_t,fd,tau)\n",
    "                    H_batch[:,i] = H\n",
    "                # H_batch_1 = H_batch[0:b]\n",
    "                # H_batch_2 = H_batch[b:2*b]\n",
    "\n",
    "\n",
    "                \n",
    "                H_hat=dec(\n",
    "                        H_batch = H_batch,  # b,T, Nc, N_r, N_t 用户1\n",
    "                    );\n",
    "                loss = SGCS_H(H_batch[:,L],H_hat)/val_num\n",
    "                loss_acc += loss.item()\n",
    "\n",
    "        return loss_acc\n",
    "\n",
    "    def save_ckpt(folder_name):\n",
    "        folder_path=save_path+folder_name+\"/\";\n",
    "        if not os.path.exists(folder_path):\n",
    "            os.makedirs(folder_path);\n",
    "\n",
    "        torch.save({'state_dict': dec.state_dict()}, folder_path+model_name+\"_model.pth.tar\");\n",
    "        torch.save({'best_loss': best_loss, \n",
    "                    'opt_dec_dict': opt_dec.state_dict(), \n",
    "                    }, folder_path+model_name+\"_opt.pth.tar\");\n",
    "\n",
    "    loss_SGCS_log=0;\n",
    "    t1=time.time();\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    with trange(iter_begin, iter_begin+ITERS) as t:\n",
    "        for i in t:            \n",
    "            loss_SGCS = step(i);\n",
    "            loss_SGCS_log+=loss_SGCS/log_interval;\n",
    "\n",
    "            if (i+1)%log_interval==0:\n",
    "                loss_SGCS = evaluate(i);\n",
    "                \n",
    "                logger(\"\");\n",
    "                if loss_SGCS<best_loss:\n",
    "                    best_loss=loss_SGCS;\n",
    "                    save_ckpt(\"CE_WY\");\n",
    "                    logger(\"\\nbest - SGCS = {}\".format(best_loss));\n",
    "                \n",
    "                logger(\"log - iter[{}] - train - SGCS = {}\".format(i, -loss_SGCS_log));\n",
    "                logger(\"log - iter[{}] - test - SGCS = {}\".format(i, -loss_SGCS));\n",
    "\n",
    "                \n",
    "\n",
    "                logger(\"time: {} s\".format(time.time()-t1));\n",
    "                t1=time.time();\n",
    "\n",
    "                if (i+1)%save_interval==0:\n",
    "                    logger(\"\");\n",
    "                    logger(\"save - iter[{}] - test - SGCS = {}\".format(i, -loss_SGCS));\n",
    "                    logger(\"save - iter[{}] - best - SGCS = {}\".format(i, -best_loss));\n",
    "\n",
    "                    \n",
    "\n",
    "                t.set_postfix(train_SGCS=loss_SGCS_log,test_SGCS=loss_SGCS,best_SGCS=-best_loss)\n",
    "\n",
    "                loss_SGCS_log=0;\n",
    "    rmLogger();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#这里测试频谱效率的时候假设完美CSI反馈\n",
    "def test_CE_WY(N,Nc,Nr,N_r_RF,Nt,N_t_RF,L,SNR_dB,v_max_km):\n",
    "    # N代表路径数\n",
    "    \n",
    "    N_t = Nt[0]*Nt[1]\n",
    "    N_r = Nr[0]*Nr[1]\n",
    "    device=0;\n",
    "    lr=1e-4;\n",
    "    log_interval=100; # 每100个输出保存一下许训练记录\n",
    "    save_interval=10*log_interval; # 每1000个测试一下保存记录\n",
    "    iter_begin=0;   #从第0个开始训练 如果不是0就读取之前训练过的check points\n",
    "    save_path=\"./weights/\";\n",
    "    best_loss=10;\n",
    "\n",
    "    model_name = 'CE_WY'+'_L' + str(L)+'_v' + str(v_max_km)\n",
    "\n",
    "    dec=CE_WY(Nc=Nc,N_r=N_r,N_r_RF=N_r_RF,N_t=N_t,N_t_RF=N_t_RF,L=L).cuda()\n",
    "    \n",
    "    \n",
    "    load_path=save_path+\"CE_WY\"+\"/\";\n",
    "\n",
    "    dec_dict = dec.state_dict()\n",
    "    dec_load_path=load_path+model_name+\"_model.pth.tar\";\n",
    "    ckpt=torch.load(dec_load_path, map_location=\"cuda:\"+str(device));\n",
    "    pretrained_dict=ckpt['state_dict'];\n",
    "    pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in dec_dict}\n",
    "    dec_dict.update(pretrained_dict);\n",
    "    dec.load_state_dict(dec_dict);\n",
    "\n",
    "    Q = 12\n",
    "    T = L+Q\n",
    "    rate1 = 4\n",
    "    rate2 = 2\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def evaluate(step_id):\n",
    "        global loader_test;\n",
    "        dec.eval();\n",
    "        loss_acc=0;\n",
    "        R_acc = 0\n",
    "        val_num = 10\n",
    "        b = 64\n",
    "        with torch.no_grad():\n",
    "            for i in range(val_num):\n",
    "\n",
    "                alpha,A_r,A_t,fd,tau = SV_Channel_set(2*b,Nc,N,Nt,Nr,1,v_max_km)\n",
    "                H_batch = torch.zeros(2*b,T, Nc, N_r, N_t).cuda() + 0j\n",
    "\n",
    "                for i in range(T):\n",
    "                    t = i*1/14000/8\n",
    "                    H = SV_Channel_final(2*b,Nc,N,Nt,Nr,1,t,alpha,A_r,A_t,fd,tau)\n",
    "                    H_batch[:,i] = H\n",
    "                H_batch_1 = H_batch[0:b]\n",
    "                H_batch_2 = H_batch[b:2*b]\n",
    "\n",
    "\n",
    "                \n",
    "                H_hat=dec(\n",
    "                        H_batch = H_batch,  # b,T, Nc, N_r, N_t 用户1\n",
    "                    );\n",
    "                loss = SGCS_H(H_batch[:,L],H_hat)/val_num\n",
    "                loss_acc += loss.item()\n",
    "\n",
    "                H_hat_1 = H_hat[0:b]\n",
    "                H_hat_2 = H_hat[b:2*b]\n",
    "\n",
    "                # H1 = H_batch_1[:,L:L+Q] \n",
    "                # H2 = H_batch_2[:,L:L+Q] \n",
    "                # H1_UE = H_batch_1[:,L:L+1]\n",
    "                # H2_UE = H_batch_2[:,L:L+1]\n",
    "                # H1_base = H_batch_1[:,L:L+1]\n",
    "                # H2_base = H_batch_2[:,L:L+1]\n",
    "\n",
    "                H1 = H_batch_1[:,L:L+Q] \n",
    "                H2 = H_batch_2[:,L:L+Q] \n",
    "                H1_UE = H_hat_1.reshape(b,1,Nc,N_r,N_t)\n",
    "                H2_UE = H_hat_2.reshape(b,1,Nc,N_r,N_t)\n",
    "                H1_base = H_hat_1.reshape(b,1,Nc,N_r,N_t)\n",
    "                H2_base = H_hat_2.reshape(b,1,Nc,N_r,N_t)\n",
    "                P_analog1,P_analog2,C_analog,P_digital1,P_digital2,C_digital,F_1, F_2, W = Pre_PCA_total(H1, H2,  H1_UE, H2_UE, H1_base, H2_base, SNR_dB, rate1, rate2)\n",
    "\n",
    "                # 打印输出形状以验证\n",
    "                # print(\"用户1端模拟预编码器 P_analog1 的形状:\", P_analog1.shape)    # [b, T, 1, N_t, 2]\n",
    "                # print(\"用户2端模拟预编码器 P_analog2 的形状:\", P_analog2.shape)    # [b, T, 1, N_t, 2]\n",
    "                # print(\"基站端模拟合并器 C_analog 的形状:\", C_analog.shape)           # [b, T, 1, 2, N_r]\n",
    "                # print(\"用户1端数字预编码器 P_digital1 的形状:\", P_digital1.shape)  # [b, T, Nc, 2, 1]\n",
    "                # print(\"用户2端数字预编码器 P_digital2 的形状:\", P_digital2.shape)  # [b, T, Nc, 2, 1]\n",
    "                # print(\"基站端数字合并器 C_digital 的形状:\", C_digital.shape)         # [b, T, Nc, 2, 2]\n",
    "\n",
    "\n",
    "                # W = torch.randn(b, T, Nc, 2, N_r).cuda() + 1j*torch.randn(b, T, Nc, 2, N_r).cuda()\n",
    "                R1 = calculate_average_channel_capacity_T(H1, F_1, W, SNR_dB)\n",
    "                R2 = calculate_average_channel_capacity_T(H2, F_2, W, SNR_dB)\n",
    "                R_acc = R_acc + (R1.mean().item() + R2.mean().item())/2/val_num\n",
    "\n",
    "        return loss_acc,R_acc\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    loss_SGCS,R_acc = evaluate(0);\n",
    "    print(\"SGCS: \",-loss_SGCS,\"    SE: \",R_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 0\n",
    "Nc = 100\n",
    "N = 2\n",
    "Nt = [1,8]\n",
    "Nr = [1,64]\n",
    "N_r_RF = 2\n",
    "N_t_RF = 2\n",
    "\n",
    "L = 1\n",
    "\n",
    "v_max_km_pre = None\n",
    "\n",
    "SNR_dB = 10\n",
    "v_max_km = 120\n",
    "train_CE_WY(N,Nc,Nr,N_r_RF,Nt,N_t_RF,L,SNR_dB,v_max_km,v_max_km_pre,ITERS=60_000,b=64,acc_num=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 0\n",
    "Nc = 100\n",
    "N = 2\n",
    "Nt = [1,8]\n",
    "Nr = [1,64]\n",
    "N_r_RF = 2\n",
    "N_t_RF = 2\n",
    "\n",
    "L = 8\n",
    "\n",
    "v_max_km_pre = None\n",
    "\n",
    "SNR_dB = 10\n",
    "v_max_km = 120\n",
    "for L in [16,1,2,4,8]:\n",
    "    train_CE_WY(N,Nc,Nr,N_r_RF,Nt,N_t_RF,L,SNR_dB,v_max_km,v_max_km_pre,ITERS=60_000,b=64,acc_num=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 开始测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 0\n",
    "Nc = 100\n",
    "N = 2\n",
    "Nt = [1,8]\n",
    "Nr = [1,64]\n",
    "N_r_RF = 2\n",
    "N_t_RF = 2\n",
    "\n",
    "L = 8\n",
    "\n",
    "v_max_km_pre = None\n",
    "\n",
    "SNR_dB = 10\n",
    "v_max_km = 120\n",
    "for L in [1,2,4,8,16]:\n",
    "    test_CE_WY(N,Nc,Nr,N_r_RF,Nt,N_t_RF,L,SNR_dB,v_max_km)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WY CSI反馈"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 网络和训练函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from tqdm import trange\n",
    "from time import sleep\n",
    "from my_log import logger, rmLogger\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class H2bits(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            Nc,     #子载波数\n",
    "            N_r,    #基站接收天线数\n",
    "            N_t,    #用户发送天线数\n",
    "            feedback_bits,  #反馈比特数\n",
    "        ):\n",
    "        super().__init__();\n",
    "\n",
    "        self.d_model = 1024\n",
    "        self.B = 4  #量化精度\n",
    "\n",
    "        # self.trans  = TRANS_BLOCK(tx*2,tx*2,512,4)\n",
    "\n",
    "        self.embed= nn.Linear(2*N_r*N_t, self.d_model) \n",
    "        self.positional_embedding=nn.Parameter(torch.zeros(1, Nc, self.d_model));\n",
    "\n",
    "        self.backbone=nn.Sequential(  # b, K*T, d_model\n",
    "            *[nn.Sequential(\n",
    "                nn.TransformerEncoderLayer(\n",
    "                    d_model=self.d_model, \n",
    "                    nhead=8, \n",
    "                    dim_feedforward=4*self.d_model, \n",
    "                    dropout=0.0, \n",
    "                    activation=\"gelu\", \n",
    "                    batch_first=True,\n",
    "                    norm_first = True, \n",
    "                ), \n",
    "            ) for _ in range(4)], \n",
    "            nn.LayerNorm(self.d_model),\n",
    "        );  # b, K*T, d_model\n",
    "\n",
    "        self.quan=nn.Sequential(  \n",
    "            ReshapeLayer([-1, Nc*self.d_model]),  \n",
    "            nn.Linear(Nc*self.d_model, feedback_bits//self.B),  # b, feedback_bits//self.B\n",
    "            nn.BatchNorm1d(feedback_bits//self.B), \n",
    "            nn.Sigmoid(), \n",
    "            QuantizationLayer(self.B),  # b, feedback_bits\n",
    "        );\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    def forward(\n",
    "            self, \n",
    "            H,  # b, Nc, N_r, N_t\n",
    "        ):\n",
    "        # b = H_DL_batch.shape[0]\n",
    "        # H_DL_batch_1 = H_DL_batch.reshape(b, 48, 4, 128,2,2)[:,:,:,:,0,:].conj() #这里加了conj是因为上下行信道之间有个共轭转置，所以共轭这部分需要conj回去消除掉\n",
    "        # H_DL_batch_2 = H_DL_batch.reshape(b, 48, 4, 128,2,2)[:,:,:,:,1,:].conj()\n",
    "\n",
    "        # H_DL_batch_beam_1 = (H_DL_batch_1*np.exp(1j*pi/2 * 0) + H_DL_batch_2*np.exp(1j*pi/2 * 0)).reshape(b,1,48,4,256)\n",
    "\n",
    "        b, Nc, N_r, N_t = H.shape\n",
    "\n",
    "\n",
    "        y_cat = H.reshape(b,Nc,N_r*N_t) \n",
    "        y_cat=torch.cat([y_cat.real, y_cat.imag], dim=-1);  # b,Nc,2*N_r*N_t\n",
    "\n",
    "        x = self.embed(y_cat) + self.positional_embedding  # b,Nc,d_model\n",
    "\n",
    "        x = self.backbone(x)   # b,Nc,d_model\n",
    "        out = self.quan(x)   #[batch, Bits]\n",
    "        return out     #[batch, Bits]\n",
    "\n",
    "\n",
    "\n",
    "class bits2H(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            Nc,     #子载波数\n",
    "            N_r,    #基站接收天线数\n",
    "            N_t,    #用户发送天线数\n",
    "            feedback_bits,  #反馈比特数\n",
    "        ):\n",
    "        super().__init__();\n",
    "\n",
    "        self.d_model = 1024\n",
    "        self.B = 4  #量化精度\n",
    "        self.feedback_bits = feedback_bits\n",
    "\n",
    "        self.Nc = Nc\n",
    "        self.N_r = N_r\n",
    "        self.N_r_RF = N_r_RF\n",
    "        self.N_t = N_t\n",
    "\n",
    "        # self.trans  = TRANS_BLOCK(tx*2,tx*2,512,4)\n",
    "        self.Dequan=nn.Sequential(  \n",
    "            DequantizationLayer(self.B),  \n",
    "        );\n",
    "\n",
    "        self.embed=nn.Sequential(  \n",
    "            nn.Linear(feedback_bits//self.B, Nc*self.d_model),  \n",
    "            ReshapeLayer([-1, Nc,self.d_model]),  \n",
    "            NormLayer(self.d_model), \n",
    "        );\n",
    "\n",
    "        self.backbone=nn.Sequential(  # b, K*T, d_model\n",
    "            *[nn.Sequential(\n",
    "                nn.TransformerEncoderLayer(\n",
    "                    d_model=self.d_model, \n",
    "                    nhead=8, \n",
    "                    dim_feedforward=4*self.d_model, \n",
    "                    dropout=0.0, \n",
    "                    activation=\"gelu\", \n",
    "                    batch_first=True,\n",
    "                    norm_first = True, \n",
    "                ), \n",
    "            ) for _ in range(4)], \n",
    "            nn.LayerNorm(self.d_model),\n",
    "        );  # b, K*T, d_model\n",
    "\n",
    "        # self.head=nn.Sequential(  \n",
    "        #     nn.Linear(self.d_model, N_t*2),  \n",
    "        # );\n",
    "        self.head=nn.Sequential(  \n",
    "            nn.Linear(self.d_model, 2*N_t*N_r),  \n",
    "        );\n",
    "\n",
    "    \n",
    "    \n",
    "    def forward(\n",
    "            self, \n",
    "            x,  # b, feedback_bits   #反馈比特\n",
    "        ):\n",
    "        N_r = self.N_r\n",
    "        N_t = self.N_t\n",
    "        Nc = self.Nc\n",
    "\n",
    "        b = x.shape[0]\n",
    "\n",
    "        x = self.Dequan(x) # b,feedback_bits//self.B\n",
    "\n",
    "        out = self.embed(x) # b,Nc,d_model\n",
    "        out = self.backbone(out)# b,Nc,d_model\n",
    "        out = self.head(out)   # b,Nc,2*N_r*N_t\n",
    "\n",
    "\n",
    "        H_hat = out.reshape(b,Nc,N_r,N_t,2)\n",
    "        H_hat = H_hat[:,:,:,:,0] + 1j*H_hat[:,:,:,:,1]\n",
    "\n",
    "\n",
    "        return H_hat     #[b,Nc,N_r,N_t]\n",
    "\n",
    "class CF_WY(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            Nc,     #子载波数\n",
    "            N_r,    #基站接收天线数\n",
    "            N_t,    #用户发送天线数\n",
    "            feedback_bits,  #反馈比特数\n",
    "        ):\n",
    "        super().__init__();\n",
    "\n",
    "        self.H2bits = H2bits(Nc,N_r,N_t,feedback_bits)\n",
    "        self.bits2H = bits2H(Nc,N_r,N_t,feedback_bits)\n",
    "    \n",
    "    def forward(\n",
    "            self, \n",
    "            H,  # b, Nc, N_r, N_t 用户\n",
    "        ):\n",
    "\n",
    "        bits = self.H2bits(H)\n",
    "        H_hat = self.bits2H(bits)\n",
    "        return H_hat\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_CF_WY(N,Nc,Nr,N_r_RF,Nt,N_t_RF,L,feedback_bits,SNR_dB,v_max_km,feedback_bits_pre = None,v_max_km_pre=None,ITERS=20_000,b=32,acc_num=1):\n",
    "    # N代表路径数\n",
    "    \n",
    "    N_t = Nt[0]*Nt[1]\n",
    "    N_r = Nr[0]*Nr[1]\n",
    "    device=0;\n",
    "    lr=1e-4;\n",
    "    log_interval=100; # 每100个输出保存一下许训练记录\n",
    "    save_interval=10*log_interval; # 每1000个测试一下保存记录\n",
    "    iter_begin=0;   #从第0个开始训练 如果不是0就读取之前训练过的check points\n",
    "    save_path=\"./weights/\";\n",
    "    best_loss=10;\n",
    "\n",
    "    model_name_CE = 'CE_WY'+'_L' + str(L)+'_v' + str(v_max_km)\n",
    "    model_name_CF = 'CF_WY'+'_bits' + str(feedback_bits)+'_L' + str(L)+'_v' + str(v_max_km)\n",
    "    model_name = model_name_CF\n",
    "\n",
    "    dec_CE=CE_WY(Nc=Nc,N_r=N_r,N_r_RF=N_r_RF,N_t=N_t,N_t_RF=N_t_RF,L=L).cuda()\n",
    "    dec_CF=CF_WY(Nc=Nc,N_r=N_r,N_t=N_t,feedback_bits=feedback_bits).cuda()\n",
    "    \n",
    "    opt_dec=torch.optim.AdamW(\n",
    "        dec_CF.parameters(), \n",
    "        lr=lr, \n",
    "    )\n",
    "    T = L+1\n",
    "    load_path_CE=save_path+\"CE_WY\"+\"/\";\n",
    "    load_path_CF=save_path+\"CF_WY\"+\"/\";\n",
    "\n",
    "    dec_dict = dec_CE.state_dict()\n",
    "    dec_load_path=load_path_CE+model_name_CE+\"_model.pth.tar\";\n",
    "    ckpt=torch.load(dec_load_path, map_location=\"cuda:\"+str(device));\n",
    "    pretrained_dict=ckpt['state_dict'];\n",
    "    pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in dec_dict}\n",
    "    dec_dict.update(pretrained_dict);\n",
    "    dec_CE.load_state_dict(dec_dict);\n",
    "    print('CE参数读取成功')\n",
    "\n",
    "    dec_CE.eval()\n",
    "\n",
    "\n",
    "    if v_max_km_pre == None:\n",
    "        print('从头训练')\n",
    "    else:\n",
    "        dec_dict = dec_CF.state_dict()\n",
    "        model_name_pre = 'CF_WY'+'_bits' + str(feedback_bits_pre)+'_L' + str(L)+'_v' + str(v_max_km_pre)\n",
    "        dec_load_path=load_path_CF+model_name_pre+\"_model.pth.tar\";\n",
    "        ckpt=torch.load(dec_load_path, map_location=\"cuda:\"+str(device));\n",
    "        pretrained_dict=ckpt['state_dict'];\n",
    "        pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in dec_dict and \".quan\" not in k and \".Dequan\" not in k}\n",
    "        dec_dict.update(pretrained_dict);\n",
    "        dec_CF.load_state_dict(dec_dict);\n",
    "        print('全部预训练参数读取成功')\n",
    "\n",
    "    def step(step_id):\n",
    "        dec_CF.train();\n",
    "        opt_dec.zero_grad();\n",
    "        loss_acc=0;\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        for _ in range(acc_num):\n",
    "            alpha,A_r,A_t,fd,tau = SV_Channel_set(b,Nc,N,Nt,Nr,1,v_max_km)\n",
    "            H_batch = torch.zeros(b,T, Nc, N_r, N_t).cuda() + 0j\n",
    "\n",
    "            for i in range(T):\n",
    "                t = i*1/14000/8 #i就表示第i个OFDM符号，每个subframe时间是1ms，每个slot包含14个OFDM符号，当子载波间隔15kHz对应一个frame包含1个slot，30kHz对应2个，60kHz->4,120kHz->8,这里采用120kHz间隔所以除以8\n",
    "                H = SV_Channel_final(b,Nc,N,Nt,Nr,1,t,alpha,A_r,A_t,fd,tau)\n",
    "                H_batch[:,i] = H\n",
    "            # H_batch_1 = H_batch[0:b]\n",
    "            # H_batch_2 = H_batch[b:2*b]\n",
    "\n",
    "            \n",
    "\n",
    "            with torch.no_grad():\n",
    "                H_CE=dec_CE(\n",
    "                    H_batch = H_batch,  # b,T, Nc, N_r, N_t 用户1\n",
    "                );\n",
    "            H_CF=dec_CF(\n",
    "                    H = H_CE,  # b,T, Nc, N_r, N_t 用户1\n",
    "                );\n",
    "            # H_hat # b,Nc, N_r, N_t 用户1\n",
    "\n",
    "\n",
    "\n",
    "            # loss_SE = -calculate_average_channel_capacity(H_DL_batch_beam[:,0:1], F, Pt,N0)/acc_num\n",
    "\n",
    "            loss = SGCS_H(H_batch[:,L],H_CF)/acc_num\n",
    "            loss_acc += loss.item()\n",
    "\n",
    "            loss.backward();\n",
    "        \n",
    "\n",
    "        opt_dec.step();\n",
    "\n",
    "        return loss_acc\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def evaluate(step_id):\n",
    "        global loader_test;\n",
    "        dec_CF.eval();\n",
    "        loss_acc_CE=0;\n",
    "        loss_acc_CF=0;\n",
    "        val_num = 10\n",
    "        b = 64\n",
    "        with torch.no_grad():\n",
    "            for i in range(val_num):\n",
    "\n",
    "                alpha,A_r,A_t,fd,tau = SV_Channel_set(b,Nc,N,Nt,Nr,1,v_max_km)\n",
    "                H_batch = torch.zeros(b,T, Nc, N_r, N_t).cuda() + 0j\n",
    "\n",
    "                for i in range(T):\n",
    "                    t = i*1/14000/8\n",
    "                    H = SV_Channel_final(b,Nc,N,Nt,Nr,1,t,alpha,A_r,A_t,fd,tau)\n",
    "                    H_batch[:,i] = H\n",
    "                # H_batch_1 = H_batch[0:b]\n",
    "                # H_batch_2 = H_batch[b:2*b]\n",
    "\n",
    "\n",
    "                \n",
    "                H_CE=dec_CE(\n",
    "                    H_batch = H_batch,  # b,T, Nc, N_r, N_t 用户1\n",
    "                );\n",
    "                H_CF=dec_CF(\n",
    "                    H = H_CE,  # b,T, Nc, N_r, N_t 用户1\n",
    "                );\n",
    "\n",
    "                loss_CE = SGCS_H(H_batch[:,L],H_CE)/val_num\n",
    "                loss_acc_CE += loss_CE.item()\n",
    "\n",
    "                loss_CF = SGCS_H(H_batch[:,L],H_CF)/val_num\n",
    "                loss_acc_CF += loss_CF.item()\n",
    "\n",
    "        return loss_acc_CE,loss_acc_CF\n",
    "\n",
    "    def save_ckpt(folder_name):\n",
    "        folder_path=save_path+folder_name+\"/\";\n",
    "        if not os.path.exists(folder_path):\n",
    "            os.makedirs(folder_path);\n",
    "\n",
    "        torch.save({'state_dict': dec_CF.state_dict()}, folder_path+model_name+\"_model.pth.tar\");\n",
    "        torch.save({'best_loss': best_loss, \n",
    "                    'opt_dec_dict': opt_dec.state_dict(), \n",
    "                    }, folder_path+model_name+\"_opt.pth.tar\");\n",
    "\n",
    "    loss_SGCS_log=0;\n",
    "    t1=time.time();\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    with trange(iter_begin, iter_begin+ITERS) as t:\n",
    "        for i in t:            \n",
    "            loss_SGCS = step(i);\n",
    "            loss_SGCS_log+=loss_SGCS/log_interval;\n",
    "\n",
    "            if (i+1)%log_interval==0:\n",
    "                loss_SGCS_CE,loss_SGCS_CF = evaluate(i);\n",
    "                \n",
    "                logger(\"\");\n",
    "                if loss_SGCS_CF<best_loss:\n",
    "                    best_loss=loss_SGCS_CF;\n",
    "                    save_ckpt(\"CF_WY\");\n",
    "                    logger(\"\\nbest - SGCS = {}\".format(best_loss));\n",
    "                \n",
    "                logger(\"log - iter[{}] - train - SGCS = {}\".format(i, -loss_SGCS_log));\n",
    "                logger(\"log - iter[{}] - test - SGCS = {}\".format(i, -loss_SGCS_CF));\n",
    "\n",
    "                \n",
    "\n",
    "                logger(\"time: {} s\".format(time.time()-t1));\n",
    "                t1=time.time();\n",
    "\n",
    "                if (i+1)%save_interval==0:\n",
    "                    logger(\"\");\n",
    "                    logger(\"save - iter[{}] - test - CE SGCS = {}\".format(i, -loss_SGCS_CE));\n",
    "                    logger(\"save - iter[{}] - test - SGCS = {}\".format(i, -loss_SGCS_CF));\n",
    "                    logger(\"save - iter[{}] - best - SGCS = {}\".format(i, -best_loss));\n",
    "\n",
    "                    \n",
    "\n",
    "                t.set_postfix(train_SGCS=-loss_SGCS_log,test_SGCS=-loss_SGCS_CF,best_SGCS=-best_loss)\n",
    "\n",
    "                loss_SGCS_log=0;\n",
    "    rmLogger();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_CF_WY(N,Nc,Nr,N_r_RF,Nt,N_t_RF,L,feedback_bits,SNR_dB,v_max_km):\n",
    "    # N代表路径数\n",
    "    \n",
    "    N_t = Nt[0]*Nt[1]\n",
    "    N_r = Nr[0]*Nr[1]\n",
    "    device=0;\n",
    "    lr=1e-4;\n",
    "    log_interval=100; # 每100个输出保存一下许训练记录\n",
    "    save_interval=10*log_interval; # 每1000个测试一下保存记录\n",
    "    iter_begin=0;   #从第0个开始训练 如果不是0就读取之前训练过的check points\n",
    "    save_path=\"./weights/\";\n",
    "    best_loss=10;\n",
    "\n",
    "    model_name_CE = 'CE_WY'+'_L' + str(L)+'_v' + str(v_max_km)\n",
    "    model_name_CF = 'CF_WY'+'_bits' + str(feedback_bits)+'_L' + str(L)+'_v' + str(v_max_km)\n",
    "    model_name = model_name_CF\n",
    "\n",
    "    dec_CE=CE_WY(Nc=Nc,N_r=N_r,N_r_RF=N_r_RF,N_t=N_t,N_t_RF=N_t_RF,L=L).cuda()\n",
    "    dec_CF=CF_WY(Nc=Nc,N_r=N_r,N_t=N_t,feedback_bits=feedback_bits).cuda()\n",
    "\n",
    "    rate1 = 4\n",
    "    rate2 = 2\n",
    "    \n",
    "    Q = 12\n",
    "    T = L+Q\n",
    "    load_path_CE=save_path+\"CE_WY\"+\"/\";\n",
    "    load_path_CF=save_path+\"CF_WY\"+\"/\";\n",
    "\n",
    "    dec_dict = dec_CE.state_dict()\n",
    "    dec_load_path=load_path_CE+model_name_CE+\"_model.pth.tar\";\n",
    "    ckpt=torch.load(dec_load_path, map_location=\"cuda:\"+str(device));\n",
    "    pretrained_dict=ckpt['state_dict'];\n",
    "    pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in dec_dict}\n",
    "    dec_dict.update(pretrained_dict);\n",
    "    dec_CE.load_state_dict(dec_dict);\n",
    "    dec_CE.eval()\n",
    "\n",
    "\n",
    "\n",
    "    dec_dict = dec_CF.state_dict()\n",
    "    dec_load_path=load_path_CF+model_name_CF+\"_model.pth.tar\";\n",
    "    ckpt=torch.load(dec_load_path, map_location=\"cuda:\"+str(device));\n",
    "    pretrained_dict=ckpt['state_dict'];\n",
    "    pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in dec_dict}\n",
    "    dec_dict.update(pretrained_dict);\n",
    "    dec_CF.load_state_dict(dec_dict);\n",
    "    dec_CF.eval()\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def evaluate(step_id):\n",
    "        global loader_test;\n",
    "        dec_CF.eval();\n",
    "        loss_acc_CE=0;\n",
    "        loss_acc_CF=0;\n",
    "        R_acc = 0\n",
    "        val_num = 10\n",
    "        b = 64\n",
    "        with torch.no_grad():\n",
    "            for i in range(val_num):\n",
    "\n",
    "                alpha,A_r,A_t,fd,tau = SV_Channel_set(2*b,Nc,N,Nt,Nr,1,v_max_km)\n",
    "                H_batch = torch.zeros(2*b,T, Nc, N_r, N_t).cuda() + 0j\n",
    "\n",
    "                for i in range(T):\n",
    "                    t = i*1/14000/8\n",
    "                    H = SV_Channel_final(2*b,Nc,N,Nt,Nr,1,t,alpha,A_r,A_t,fd,tau)\n",
    "                    H_batch[:,i] = H\n",
    "                H_batch_1 = H_batch[0:b]\n",
    "                H_batch_2 = H_batch[b:2*b]\n",
    "\n",
    "\n",
    "                \n",
    "                H_CE=dec_CE(\n",
    "                    H_batch = H_batch,  # b,T, Nc, N_r, N_t 用户1\n",
    "                );\n",
    "                H_CF=dec_CF(\n",
    "                    H = H_CE,  # b,T, Nc, N_r, N_t 用户1\n",
    "                );\n",
    "\n",
    "                loss_CE = SGCS_H(H_batch[:,L],H_CE)/val_num\n",
    "                loss_acc_CE += loss_CE.item()\n",
    "\n",
    "                loss_CF = SGCS_H(H_batch[:,L],H_CF)/val_num\n",
    "                loss_acc_CF += loss_CF.item()\n",
    "                \n",
    "\n",
    "                H_CE_1 = H_CE[0:b]\n",
    "                H_CE_2 = H_CE[b:2*b]\n",
    "                H_CF_1 = H_CF[0:b]\n",
    "                H_CF_2 = H_CF[b:2*b]\n",
    "\n",
    "                # H1 = H_batch_1[:,L:L+Q] \n",
    "                # H2 = H_batch_2[:,L:L+Q] \n",
    "                # H1_UE = H_batch_1[:,L:L+1]\n",
    "                # H2_UE = H_batch_2[:,L:L+1]\n",
    "                # H1_base = H_batch_1[:,L:L+1]\n",
    "                # H2_base = H_batch_2[:,L:L+1]\n",
    "\n",
    "                H1 = H_batch_1[:,L:L+Q] \n",
    "                H2 = H_batch_2[:,L:L+Q] \n",
    "                H1_UE = H_CE_1.reshape(b,1,Nc,N_r,N_t)\n",
    "                H2_UE = H_CE_2.reshape(b,1,Nc,N_r,N_t)\n",
    "                H1_base = H_CF_1.reshape(b,1,Nc,N_r,N_t)\n",
    "                H2_base = H_CF_2.reshape(b,1,Nc,N_r,N_t)\n",
    "                P_analog1,P_analog2,C_analog,P_digital1,P_digital2,C_digital,F_1, F_2, W = Pre_PCA_total(H1, H2,  H1_UE, H2_UE, H1_base, H2_base, SNR_dB, rate1, rate2)\n",
    "\n",
    "                # 打印输出形状以验证\n",
    "                # print(\"用户1端模拟预编码器 P_analog1 的形状:\", P_analog1.shape)    # [b, T, 1, N_t, 2]\n",
    "                # print(\"用户2端模拟预编码器 P_analog2 的形状:\", P_analog2.shape)    # [b, T, 1, N_t, 2]\n",
    "                # print(\"基站端模拟合并器 C_analog 的形状:\", C_analog.shape)           # [b, T, 1, 2, N_r]\n",
    "                # print(\"用户1端数字预编码器 P_digital1 的形状:\", P_digital1.shape)  # [b, T, Nc, 2, 1]\n",
    "                # print(\"用户2端数字预编码器 P_digital2 的形状:\", P_digital2.shape)  # [b, T, Nc, 2, 1]\n",
    "                # print(\"基站端数字合并器 C_digital 的形状:\", C_digital.shape)         # [b, T, Nc, 2, 2]\n",
    "\n",
    "\n",
    "                # W = torch.randn(b, T, Nc, 2, N_r).cuda() + 1j*torch.randn(b, T, Nc, 2, N_r).cuda()\n",
    "                R1 = calculate_average_channel_capacity_T(H1, F_1, W, SNR_dB)\n",
    "                R2 = calculate_average_channel_capacity_T(H2, F_2, W, SNR_dB)\n",
    "                R_acc = R_acc + (R1.mean().item() + R2.mean().item())/2/val_num\n",
    "\n",
    "        return loss_acc_CE,loss_acc_CF,R_acc\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    loss_SGCS_CE,loss_SGCS_CF,R_acc = evaluate(0);\n",
    "    print(\"SGCS_CE: \",-loss_SGCS_CE,\"    SGCS_CF: \",-loss_SGCS_CF,\"    SE: \",R_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 0\n",
    "Nc = 100\n",
    "N = 2\n",
    "Nt = [1,8]\n",
    "Nr = [1,64]\n",
    "N_r_RF = 2\n",
    "N_t_RF = 2\n",
    "\n",
    "L = 8\n",
    "\n",
    "feedback_bits_pre = None\n",
    "v_max_km_pre = None\n",
    "\n",
    "feedback_bits = 1024\n",
    "SNR_dB = 10\n",
    "v_max_km = 120\n",
    "for L in [8,1,2,4,16]:\n",
    "    train_CF_WY(N,Nc,Nr,N_r_RF,Nt,N_t_RF,L,feedback_bits,SNR_dB,v_max_km,feedback_bits_pre,v_max_km_pre,ITERS=60_000,b=64,acc_num=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 0\n",
    "Nc = 100\n",
    "N = 2\n",
    "Nt = [1,8]\n",
    "Nr = [1,64]\n",
    "N_r_RF = 2\n",
    "N_t_RF = 2\n",
    "\n",
    "L = 8\n",
    "\n",
    "feedback_bits_pre = None\n",
    "v_max_km_pre = None\n",
    "\n",
    "feedback_bits = 1024\n",
    "SNR_dB = 10\n",
    "v_max_km = 120\n",
    "for feedback_bits in [4,16,64,256,4096]:\n",
    "    train_CF_WY(N,Nc,Nr,N_r_RF,Nt,N_t_RF,L,feedback_bits,SNR_dB,v_max_km,feedback_bits_pre,v_max_km_pre,ITERS=60_000,b=64,acc_num=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 开始测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 0\n",
    "Nc = 100\n",
    "N = 2\n",
    "Nt = [1,8]\n",
    "Nr = [1,64]\n",
    "N_r_RF = 2\n",
    "N_t_RF = 2\n",
    "\n",
    "L = 8\n",
    "\n",
    "feedback_bits_pre = None\n",
    "v_max_km_pre = None\n",
    "\n",
    "feedback_bits = 1024\n",
    "SNR_dB = 10\n",
    "v_max_km = 120\n",
    "for L in [1,2,4,8,16]:\n",
    "    test_CF_WY(N,Nc,Nr,N_r_RF,Nt,N_t_RF,L,feedback_bits,SNR_dB,v_max_km)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 0\n",
    "Nc = 100\n",
    "N = 2\n",
    "Nt = [1,8]\n",
    "Nr = [1,64]\n",
    "N_r_RF = 2\n",
    "N_t_RF = 2\n",
    "\n",
    "L = 8\n",
    "\n",
    "feedback_bits_pre = None\n",
    "v_max_km_pre = None\n",
    "\n",
    "feedback_bits = 1024\n",
    "SNR_dB = 10\n",
    "v_max_km = 120\n",
    "for feedback_bits in [4,16,64,256,1024]:\n",
    "    test_CF_WY(N,Nc,Nr,N_r_RF,Nt,N_t_RF,L,feedback_bits,SNR_dB,v_max_km)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WY 预编码"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 网络和训练函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class H2precoding_WY(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            Nc,     #子载波数\n",
    "            N_r,    #基站接收天线数\n",
    "            N_r_RF, #基站射频数\n",
    "            N_t,    #用户发送天线数\n",
    "            N_t_RF, #用户发送射频数\n",
    "        ):\n",
    "        super().__init__();\n",
    "\n",
    "        self.d_model = 1024\n",
    "        self.N_t = N_t\n",
    "        self.N_t_RF = N_t_RF\n",
    "\n",
    "        # self.trans  = TRANS_BLOCK(tx*2,tx*2,512,4)\n",
    "\n",
    "        self.embed= nn.Linear(2*N_t*N_r, self.d_model) \n",
    "        self.positional_embedding=nn.Parameter(torch.zeros(1, Nc, self.d_model));\n",
    "\n",
    "        self.backbone=nn.Sequential(  # b, K*T, d_model\n",
    "            *[nn.Sequential(\n",
    "                nn.TransformerEncoderLayer(\n",
    "                    d_model=self.d_model, \n",
    "                    nhead=8, \n",
    "                    dim_feedforward=4*self.d_model, \n",
    "                    dropout=0.0, \n",
    "                    activation=\"gelu\", \n",
    "                    batch_first=True,\n",
    "                    norm_first = True, \n",
    "                ), \n",
    "            ) for _ in range(2)], \n",
    "            nn.LayerNorm(self.d_model),\n",
    "        );  # b, K*T, d_model\n",
    "\n",
    "        self.head_RF=nn.Sequential(  \n",
    "            ReshapeLayer([-1, Nc*self.d_model]),  \n",
    "            nn.Linear(Nc*self.d_model, 2*1*N_t),  \n",
    "        );\n",
    "        # self.head_BB=nn.Sequential(  \n",
    "        #     nn.Linear(self.d_model, 2*N_t_RF),  \n",
    "        # );\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    def forward(\n",
    "            self, \n",
    "            H_CE,  # b, Nc, N_r, N_t\n",
    "        ):\n",
    "        # b = H_DL_batch.shape[0]\n",
    "        # H_DL_batch_1 = H_DL_batch.reshape(b, 48, 4, 128,2,2)[:,:,:,:,0,:].conj() #这里加了conj是因为上下行信道之间有个共轭转置，所以共轭这部分需要conj回去消除掉\n",
    "        # H_DL_batch_2 = H_DL_batch.reshape(b, 48, 4, 128,2,2)[:,:,:,:,1,:].conj()\n",
    "\n",
    "        # H_DL_batch_beam_1 = (H_DL_batch_1*np.exp(1j*pi/2 * 0) + H_DL_batch_2*np.exp(1j*pi/2 * 0)).reshape(b,1,48,4,256)\n",
    "\n",
    "        b, Nc, N_r, N_t = H_CE.shape\n",
    "\n",
    "        y_cat = H_CE.reshape(b,Nc,N_t*N_r) \n",
    "        y_cat=torch.cat([y_cat.real, y_cat.imag], dim=-1);  # b,Nc,2*N_t*N_r\n",
    "\n",
    "        x = self.embed(y_cat) + self.positional_embedding  # b,Nc,d_model\n",
    "\n",
    "        x = self.backbone(x)   # b,Nc,d_model\n",
    "\n",
    "        F_RF = self.head_RF(x)\n",
    "        F_RF = F_RF.reshape(b,1,N_t,1,2) # b,1,N_t,N_t_RF,2\n",
    "        F_RF = F_RF[:,:,:,:,0] + 1j*F_RF[:,:,:,:,1]\n",
    "        F_RF = F_RF/torch.abs(F_RF)/sqrt(N_t) #[batch, 1,N_t,1]\n",
    "\n",
    "        # F_BB = self.head_BB(x)\n",
    "        # F_BB = F_BB.reshape(b,Nc,N_t_RF,1,2) # b,Nc,N_t_RF,1,2\n",
    "        # F_BB = F_BB[:,:,:,:,0] + 1j*F_BB[:,:,:,:,1] # b,Nc,N_t_RF,1\n",
    "        # F = F_RF @ F_BB\n",
    "\n",
    "        return F_RF     #[batch, 1,N_t,1]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class H2combiner_WY(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            Nc,     #子载波数\n",
    "            N_r,    #基站接收天线数\n",
    "            N_r_RF, #基站射频数\n",
    "            N_t,    #用户发送天线数\n",
    "            N_t_RF, #用户发送射频数\n",
    "\n",
    "        ):\n",
    "        super().__init__();\n",
    "\n",
    "        self.d_model = 1024\n",
    "\n",
    "\n",
    "        self.Nc = Nc\n",
    "        self.N_r = N_r\n",
    "        self.N_r_RF = N_r_RF\n",
    "\n",
    "        # self.trans  = TRANS_BLOCK(tx*2,tx*2,512,4)\n",
    "\n",
    "\n",
    "        self.embed_1 = nn.Linear(2*N_t*N_r, self.d_model) \n",
    "        self.embed_2 = nn.Linear(2*N_t*N_r, self.d_model) \n",
    "\n",
    "        self.positional_embedding_1=nn.Parameter(torch.zeros(1, Nc, self.d_model));\n",
    "        self.positional_embedding_2=nn.Parameter(torch.zeros(1, Nc, self.d_model));\n",
    "\n",
    "        self.backbone_1=nn.Sequential(  # b, K*T, d_model\n",
    "            *[nn.Sequential(\n",
    "                nn.TransformerEncoderLayer(\n",
    "                    d_model=self.d_model, \n",
    "                    nhead=8, \n",
    "                    dim_feedforward=4*self.d_model, \n",
    "                    dropout=0.0, \n",
    "                    activation=\"gelu\", \n",
    "                    batch_first=True,\n",
    "                    norm_first = True, \n",
    "                ), \n",
    "            ) for _ in range(1)], \n",
    "            nn.LayerNorm(self.d_model),\n",
    "            nn.Linear(self.d_model, 512),  \n",
    "        );  \n",
    "\n",
    "        self.backbone_2=nn.Sequential(  # b, K*T, d_model\n",
    "            *[nn.Sequential(\n",
    "                nn.TransformerEncoderLayer(\n",
    "                    d_model=self.d_model, \n",
    "                    nhead=8, \n",
    "                    dim_feedforward=4*self.d_model, \n",
    "                    dropout=0.0, \n",
    "                    activation=\"gelu\", \n",
    "                    batch_first=True,\n",
    "                    norm_first = True, \n",
    "                ), \n",
    "            ) for _ in range(1)], \n",
    "            nn.LayerNorm(self.d_model),\n",
    "            nn.Linear(self.d_model, 512),  \n",
    "        );  \n",
    "\n",
    "        self.embed_3 = nn.Linear(1024, self.d_model) \n",
    "\n",
    "        self.backbone_3=nn.Sequential(  # b, K*T, d_model\n",
    "            *[nn.Sequential(\n",
    "                nn.TransformerEncoderLayer(\n",
    "                    d_model=self.d_model, \n",
    "                    nhead=8, \n",
    "                    dim_feedforward=4*self.d_model, \n",
    "                    dropout=0.0, \n",
    "                    activation=\"gelu\", \n",
    "                    batch_first=True,\n",
    "                    norm_first = True, \n",
    "                ), \n",
    "            ) for _ in range(2)], \n",
    "            nn.LayerNorm(self.d_model),\n",
    "        );  \n",
    "\n",
    "        # self.head=nn.Sequential(  \n",
    "        #     nn.Linear(self.d_model, N_t*2),  \n",
    "        # );\n",
    "        self.head_RF=nn.Sequential(  \n",
    "            ReshapeLayer([-1, Nc*self.d_model]),  \n",
    "            nn.Linear(Nc*self.d_model, 2*N_r*N_r_RF),  \n",
    "        );\n",
    "        # self.head_BB=nn.Sequential(  \n",
    "        #     nn.Linear(self.d_model, 2*N_r_RF*N_r_RF),  \n",
    "        # );\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    def forward(\n",
    "            self, \n",
    "            H_CF_1,  # b, Nc, N_r, N_t   \n",
    "            H_CF_2,  # b, Nc, N_r, N_t   \n",
    "        ):\n",
    "        \n",
    "\n",
    "        b, Nc, N_r, N_t = H_CF_1.shape\n",
    "        N_r_RF = self.N_r_RF\n",
    "\n",
    "        y_cat = H_CF_1.reshape(b,Nc,N_t*N_r) \n",
    "        y_cat=torch.cat([y_cat.real, y_cat.imag], dim=-1);  # b,Nc,2*N_t*N_r\n",
    "        x_1 = self.embed_1(y_cat) + self.positional_embedding_1  # b,Nc,d_model\n",
    "        x_1 = self.backbone_1(x_1)   # b,Nc,512\n",
    "\n",
    "        y_cat = H_CF_2.reshape(b,Nc,N_t*N_r) \n",
    "        y_cat=torch.cat([y_cat.real, y_cat.imag], dim=-1);  # b,Nc,2*N_t*N_r\n",
    "        x_2 = self.embed_2(y_cat) + self.positional_embedding_2  # b,Nc,d_model\n",
    "        x_2 = self.backbone_2(x_2)   # b,Nc,512\n",
    "\n",
    "        x = torch.cat([x_1, x_2], dim=-1);  # b,Nc,1024\n",
    "\n",
    "\n",
    "        out = self.embed_3(x) # b,Nc,d_model\n",
    "        out = self.backbone_3(out)# b,Nc,d_model\n",
    "        \n",
    "        # F = out.reshape(b,1,self.N_t,N_t_RF,2) # b,1,N_t,N_t_RF,2\n",
    "        # F = F[:,:,:,:,0] + 1j*F[:,:,:,:,1]\n",
    "        # F = F/torch.abs(F)/sqrt(self.N_t) #[batch, 1,N_t,N_t_RF]\n",
    "\n",
    "        W_RF = self.head_RF(out)   # b,N_t*2\n",
    "        W_RF = W_RF.reshape(b,1,self.N_r_RF,self.N_r,2)\n",
    "        W_RF = W_RF[:,:,:,:,0] + 1j*W_RF[:,:,:,:,1]\n",
    "        W_RF = W_RF/torch.abs(W_RF)/sqrt(self.N_r)  #b,1,self.N_r_RF,self.N_r\n",
    "\n",
    "        # W_BB = self.head_BB(out)   # b,Nc,2*N_r_RF*N_r_RF\n",
    "        # W_BB = W_BB.reshape(b,Nc,self.N_r_RF,self.N_r_RF,2)\n",
    "        # W_BB = W_BB[:,:,:,:,0] + 1j*W_BB[:,:,:,:,1] # b,Nc,N_r_RF,N_r_RF\n",
    "\n",
    "        # W = W_BB @ W_RF\n",
    "\n",
    "\n",
    "        return W_RF     #[b,1,N_r_RF,N_r]\n",
    "\n",
    "class Precoding_WY(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            Nc,     #子载波数\n",
    "            N_r,    #基站接收天线数\n",
    "            N_r_RF, #基站射频数\n",
    "            N_t,    #用户发送天线数\n",
    "            N_t_RF, #用户发送射频数\n",
    "        ):\n",
    "        super().__init__();\n",
    "\n",
    "        self.H2precoding_WY_1 = H2precoding_WY(Nc,N_r,N_r_RF,N_t,N_t_RF)\n",
    "        self.H2precoding_WY_2 = H2precoding_WY(Nc,N_r,N_r_RF,N_t,N_t_RF)\n",
    "        self.H2combiner_WY = H2combiner_WY(Nc,N_r,N_r_RF,N_t,N_t_RF)\n",
    "\n",
    "    def forward(\n",
    "            self, \n",
    "            H_CE_1,  # b, Nc, N_r, N_t \n",
    "            H_CE_2,  # b, Nc, N_r, N_t \n",
    "            H_CF_1,  # b, Nc, N_r, N_t \n",
    "            H_CF_2,  # b, Nc, N_r, N_t \n",
    "        ):\n",
    "        F_1 = self.H2precoding_WY_1(H_CE_1)\n",
    "        F_2 = self.H2precoding_WY_2(H_CE_2)\n",
    "        W = self.H2combiner_WY(H_CF_1,H_CF_2)\n",
    "        return W,F_1,F_2\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "### 时域和频域插值外推\n",
    "def interpolate_upsample(x, scale_factors, mode='bilinear', align_corners=False):\n",
    "    \"\"\"\n",
    "    使用双线性插值对张量 x 在时间和频域维度上进行上采样。\n",
    "    \n",
    "    参数:\n",
    "        x (torch.Tensor): 输入张量，形状为 [b, T, Nc, N_r, N_t]。\n",
    "        scale_factors (tuple): 时间和频域的上采样因子 (scale_time, scale_freq)。\n",
    "        mode (str): 插值模式，默认为 'bilinear'。\n",
    "        align_corners (bool): 插值参数，默认为 False。\n",
    "    \n",
    "    返回:\n",
    "        x_up (torch.Tensor): 上采样后的张量，形状为 [b, T*scale_time, Nc*scale_freq, N_r, N_t]。\n",
    "    \"\"\"\n",
    "    scale_time, scale_freq = scale_factors\n",
    "    \n",
    "    # Reshape to [b * N_r * N_t, 1, T, Nc] for 2D interpolation\n",
    "    b, T, Nc, N_r, N_t = x.shape\n",
    "    x_reshaped = x.permute(0, 3, 4, 1, 2).contiguous().view(b * N_r * N_t, 1, T, Nc)\n",
    "    \n",
    "    # Perform 2D interpolation on time and frequency dimensions\n",
    "    x_up = F.interpolate(x_reshaped, scale_factor=(scale_time, scale_freq), mode=mode, align_corners=align_corners)\n",
    "    \n",
    "    # Reshape back to [b, T*scale_time, Nc*scale_freq, N_r, N_t]\n",
    "    b_new, _, T_up, Nc_up = x_up.shape\n",
    "    x_up = x_up.view(b, N_r, N_t, T_up, Nc_up).permute(0, 3, 4, 1, 2).contiguous()\n",
    "    \n",
    "    return x_up\n",
    "def Subcar_Interp(H1, H2, rate1, rate2):\n",
    "    \"\"\"\n",
    "    对下采样后的信道 H1 和 H2 进行时间域和频域的插值上采样，恢复到完整的维度。\n",
    "    \n",
    "    参数:\n",
    "        H1 (torch.Tensor): 下采样后的信道矩阵，形状为 [b, T_down, Nc_down, N_r, N_t]，复数类型。\n",
    "        H2 (torch.Tensor): 下采样后的信道矩阵，形状为 [b, T_down, Nc_down, N_r, N_t]，复数类型。\n",
    "        rate1 (int): 时间域上采样因子（多普勒域）。\n",
    "        rate2 (int): 频域上采样因子（延时域）。\n",
    "    \n",
    "    返回:\n",
    "        H1_up (torch.Tensor): 上采样后的 H1，形状为 [b, T*rate1, Nc*rate2, N_r, N_t]。\n",
    "        H2_up_freq_shifted (torch.Tensor): 上采样并频率偏移后的 H2，形状为 [b, T*rate1, Nc*rate2, N_r, N_t]。\n",
    "    \"\"\"\n",
    "    # 分离实部和虚部进行插值\n",
    "    H1_real = H1.real\n",
    "    H1_imag = H1.imag\n",
    "    H2_real = H2.real\n",
    "    H2_imag = H2.imag\n",
    "    \n",
    "    # Perform interpolation on real and imaginary parts\n",
    "    H1_up_real = interpolate_upsample(H1_real, scale_factors=(rate1, rate2), mode='bilinear', align_corners=False)\n",
    "    H1_up_imag = interpolate_upsample(H1_imag, scale_factors=(rate1, rate2), mode='bilinear', align_corners=False)\n",
    "    H2_up_real = interpolate_upsample(H2_real, scale_factors=(rate1, rate2), mode='bilinear', align_corners=False)\n",
    "    H2_up_imag = interpolate_upsample(H2_imag, scale_factors=(rate1, rate2), mode='bilinear', align_corners=False)\n",
    "    \n",
    "    # Reconstruct complex tensors\n",
    "    H1_up = torch.complex(H1_up_real, H1_up_imag)\n",
    "    H2_up = torch.complex(H2_up_real, H2_up_imag)\n",
    "    \n",
    "    # Frequency shift for H2_up\n",
    "    H1_up = torch.roll(H1_up, shifts=-rate2//2, dims=2)  # Shift along frequency dimension\n",
    "    \n",
    "    return H1_up, H2_up\n",
    "def Pre_WY_DMRS(H1, H2,  H1_UE, H2_UE, H1_base, H2_base, SNR_dB, rate1, rate2, W, F_1, F_2):\n",
    "    \"\"\"\n",
    "    MIMO预编码函数 Pre_PCA\n",
    "\n",
    "    参数:\n",
    "        H1: 张量，形状为 [b, Q, Nc, N_r, N_t]，用户1到基站的信道矩阵\n",
    "        H2: 张量，形状为 [b, Q, Nc, N_r, N_t]，用户2到基站的信道矩阵\n",
    "        H1_UE: 张量，形状为 [b, 1, Nc, N_r, N_t]，用户端信道估计的信道 用户1到基站的信道矩阵\n",
    "        H2_UE: 张量，形状为 [b, 1, Nc, N_r, N_t]，用户端信道估计的信道 用户2到基站的信道矩阵\n",
    "        H1_base: 张量，形状为 [b, 1, Nc, N_r, N_t]，基站端CSI反馈重建的信道 用户1到基站的信道矩阵\n",
    "        H2_base: 张量，形状为 [b, 1, Nc, N_r, N_t]，基站端CSI反馈重建的信道 用户2到基站的信道矩阵\n",
    "    返回:\n",
    "        {\n",
    "            'P_analog1': 用户1模拟预编码器，形状 [b, T, 1, N_t, 2],\n",
    "            'P_analog2': 用户2模拟预编码器，形状 [b, T, 1, N_t, 2],\n",
    "            'C_analog': 基站端模拟合并器，形状 [b, T, 1, 2, N_r],\n",
    "            'P_digital1': 用户1数字预编码器，形状 [b, T, Nc, 2, 1],\n",
    "            'P_digital2': 用户2数字预编码器, 形状 [b, T, Nc, 2, 1],\n",
    "            'C_digital': 基站端数字合并器，形状 [b, T, Nc, 2, 2]\n",
    "        }\n",
    "    \"\"\"\n",
    "    # 获取输入信道矩阵的尺寸信息\n",
    "    b, Q, Nc, N_r, N_t = H1.shape\n",
    "    N_RF = 2  # 射频链路数\n",
    "\n",
    "    \n",
    "\n",
    "    def compute_digital_combiner(W, H, F):\n",
    "        \"\"\"\n",
    "        计算数字合并器的等效信道\n",
    "\n",
    "        输入:\n",
    "            C_analog: 张量，形状为 [b, 1, 1, 2, N_r]\n",
    "            H: 张量，形状为 [b, Q, Nc, N_r, N_t]\n",
    "            P_analog: 张量，形状为 [b, 1, 1, N_t, 2]\n",
    "            P_digital: 张量，形状为 [b, 1, Nc, 2, 1]\n",
    "\n",
    "        输出:\n",
    "            H_eff: 张量，形状为 [b, T, Nc, 2, 1]\n",
    "        \"\"\"\n",
    "       \n",
    "\n",
    "        \n",
    "        norm_factor = torch.sqrt(torch.sum(torch.abs(F)**2, dim=(-2, -1), keepdim=True))\n",
    "        F = F / norm_factor * torch.sqrt(torch.tensor(N_RF, dtype=H1.dtype, device=H1.device))  #[b, 1, 1, N_t, 1]\n",
    "\n",
    "        norm_factor = torch.sqrt(torch.sum(torch.abs(W)**2, dim=(-2, -1), keepdim=True))\n",
    "        W = W / norm_factor * torch.sqrt(torch.tensor(N_RF, dtype=H1.dtype, device=H1.device))\n",
    "\n",
    "        # Calculate effective channel\n",
    "        sigma = 10**(-SNR_dB/10)\n",
    "        n = (torch.randn(b,Q,Nc,N_RF,1).cuda() + 1j*torch.randn(b,Q,Nc,N_RF,1).cuda())/sqrt(2)*sqrt(sigma)\n",
    "        H_eff = W @ H @ F + n  # [b, Q, Nc, 2, 1]\n",
    "        # H_eff = W @ H @ F   # [b, Q, Nc, 2, 1]\n",
    "\n",
    "\n",
    "        return H_eff  # [b, Q, Nc, 2, 1]\n",
    "\n",
    "    # 计算两个用户的等效信道\n",
    "    \n",
    "\n",
    "    norm_factor = torch.sqrt(torch.sum(torch.abs(F_1)**2, dim=(-2, -1), keepdim=True))\n",
    "    F_1 = F_1 / norm_factor * torch.sqrt(torch.tensor(N_RF, dtype=H1.dtype, device=H1.device))\n",
    "    norm_factor = torch.sqrt(torch.sum(torch.abs(F_2)**2, dim=(-2, -1), keepdim=True))\n",
    "    F_2 = F_2 / norm_factor * torch.sqrt(torch.tensor(N_RF, dtype=H1.dtype, device=H1.device))\n",
    "    norm_factor = torch.sqrt(torch.sum(torch.abs(W)**2, dim=(-2, -1), keepdim=True))\n",
    "    W = W / norm_factor * torch.sqrt(torch.tensor(N_RF, dtype=H1.dtype, device=H1.device))\n",
    "\n",
    "    H_eff1 = compute_digital_combiner(W, H1, F_1)  # 用户1等效信道 [b, Q, Nc, 2, 1]\n",
    "    H_eff2 = compute_digital_combiner(W, H2, F_2)  # 用户2等效信道 [b, Q, Nc, 2, 1]\n",
    "\n",
    "    H_eff1_down = H_eff1[:, ::rate1, ::rate2, :, :]\n",
    "    H_eff2_down = H_eff2[:, ::rate1, rate2//2::rate2, :, :]\n",
    "    H_eff1_up, H_eff2_up = Subcar_Interp(H_eff1_down, H_eff2_down, rate1, rate2)\n",
    "\n",
    "    # print(NMSE(H_eff1_up,H_eff1))\n",
    "    # print(NMSE(H_eff2_up,H_eff2))\n",
    "\n",
    "    # 拼接两个用户的等效信道，形成 [b, T, Nc, 2, 2]\n",
    "    H_eff_stack = torch.cat([H_eff1_up, H_eff2_up], dim=-1)  # [b, Q, Nc, 2, 2]\n",
    "\n",
    "    def compute_zf_digital_combiner(H_eff_stack):\n",
    "        T = Q\n",
    "        \"\"\"\n",
    "        计算基站端的数字合并器，使用零迫（ZF）方法\n",
    "\n",
    "        输入:\n",
    "            H_eff_stack: 张量，形状为 [b, T, Nc, 2, 2]\n",
    "\n",
    "        输出:\n",
    "            C_digital: 张量，形状为 [b, T, Nc, 2, 2]\n",
    "        \"\"\"\n",
    "        # 计算数字合并器 W = (H_eff^H * H_eff)^{-1} * H_eff^H\n",
    "        # 首先计算 H_eff^H\n",
    "        H_eff_H = H_eff_stack.conj().transpose(-2, -1)  # [b, T, Nc, 2, 2]\n",
    "\n",
    "        # 计算 H_eff^H * H_eff\n",
    "        H_eff_H_H_eff = torch.matmul(H_eff_H, H_eff_stack)  # [b, T, Nc, 2, 2]\n",
    "\n",
    "        # 计算 (H_eff^H * H_eff)^{-1}\n",
    "        H_eff_H_H_eff_inv = torch.linalg.inv(H_eff_H_H_eff+1)  # [b, T, Nc, 2, 2]\n",
    "\n",
    "        # 计算 W = (H_eff^H * H_eff)^{-1} * H_eff^H\n",
    "        C_digital = torch.matmul(H_eff_H_H_eff_inv, H_eff_H)  # [b, T, Nc, 2, 2]\n",
    "\n",
    "        return C_digital  # [b, T, Nc, 2, 2]\n",
    "\n",
    "    # 计算基站端数字合并器\n",
    "    C_digital = compute_zf_digital_combiner(H_eff_stack)  # [b, Q, Nc, 2, 2]\n",
    "\n",
    "    W = C_digital @ W\n",
    "\n",
    "\n",
    "\n",
    "    # 最终输出\n",
    "    return W[:,0:Q] #b,Q,Nc,2,N_r\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_Precoding_WY(N,Nc,Nr,N_r_RF,Nt,N_t_RF,L,feedback_bits,SNR_dB,v_max_km,feedback_bits_pre = None,v_max_km_pre=None,ITERS=20_000,b=32,acc_num=1):\n",
    "    # N代表路径数\n",
    "    \n",
    "    N_t = Nt[0]*Nt[1]\n",
    "    N_r = Nr[0]*Nr[1]\n",
    "    device=0;\n",
    "    lr=1e-4;\n",
    "    log_interval=100; # 每100个输出保存一下许训练记录\n",
    "    save_interval=10*log_interval; # 每1000个测试一下保存记录\n",
    "    iter_begin=0;   #从第0个开始训练 如果不是0就读取之前训练过的check points\n",
    "    save_path=\"./weights/\";\n",
    "    best_loss=0;\n",
    "    rate1 = 4\n",
    "    rate2 = 2\n",
    "\n",
    "\n",
    "    model_name_CE = 'CE_WY'+'_L' + str(L)+'_v' + str(v_max_km)\n",
    "    model_name_CF = 'CF_WY'+'_bits' + str(feedback_bits)+'_L' + str(L)+'_v' + str(v_max_km)\n",
    "\n",
    "    dec_CE=CE_WY(Nc=Nc,N_r=N_r,N_r_RF=N_r_RF,N_t=N_t,N_t_RF=N_t_RF,L=L).cuda()\n",
    "    dec_CF=CF_WY(Nc=Nc,N_r=N_r,N_t=N_t,feedback_bits=feedback_bits).cuda()\n",
    "    \n",
    "    Q = 12\n",
    "    T = L+Q\n",
    "    load_path_CE=save_path+\"CE_WY\"+\"/\";\n",
    "    load_path_CF=save_path+\"CF_WY\"+\"/\";\n",
    "\n",
    "    dec_dict = dec_CE.state_dict()\n",
    "    dec_load_path=load_path_CE+model_name_CE+\"_model.pth.tar\";\n",
    "    ckpt=torch.load(dec_load_path, map_location=\"cuda:\"+str(device));\n",
    "    pretrained_dict=ckpt['state_dict'];\n",
    "    pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in dec_dict}\n",
    "    dec_dict.update(pretrained_dict);\n",
    "    dec_CE.load_state_dict(dec_dict);\n",
    "    dec_CE.eval()\n",
    "\n",
    "\n",
    "\n",
    "    dec_dict = dec_CF.state_dict()\n",
    "    dec_load_path=load_path_CF+model_name_CF+\"_model.pth.tar\";\n",
    "    ckpt=torch.load(dec_load_path, map_location=\"cuda:\"+str(device));\n",
    "    pretrained_dict=ckpt['state_dict'];\n",
    "    pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in dec_dict}\n",
    "    dec_dict.update(pretrained_dict);\n",
    "    dec_CF.load_state_dict(dec_dict);\n",
    "    dec_CF.eval()\n",
    "\n",
    "\n",
    "    model_name_Precoding = 'Precoding_WY' + str(feedback_bits)+'_L' + str(L)+'_v' + str(v_max_km)\n",
    "    model_name = model_name_Precoding\n",
    "\n",
    "    dec=Precoding_WY(Nc=Nc,N_r=N_r,N_r_RF=N_r_RF,N_t=N_t,N_t_RF=N_t_RF).cuda()\n",
    "    \n",
    "    opt_dec=torch.optim.AdamW(\n",
    "        dec.parameters(), \n",
    "        lr=lr, \n",
    "    )\n",
    "    load_path=save_path+\"Precoding_WY\"+\"/\";\n",
    "    if feedback_bits_pre == None:\n",
    "        print('从头训练')\n",
    "    else:\n",
    "        dec_dict = dec.state_dict()\n",
    "        model_name_pre = 'Precoding_WY' + str(feedback_bits_pre)+'_L' + str(L)+'_v' + str(v_max_km_pre)\n",
    "        dec_load_path=load_path+model_name_pre+\"_model.pth.tar\";\n",
    "        ckpt=torch.load(dec_load_path, map_location=\"cuda:\"+str(device));\n",
    "        pretrained_dict=ckpt['state_dict'];\n",
    "        pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in dec_dict and \".quan\" not in k and \".Dequan\" not in k}\n",
    "        dec_dict.update(pretrained_dict);\n",
    "        dec.load_state_dict(dec_dict);\n",
    "        print('全部预训练参数读取成功')\n",
    "\n",
    "    def step(step_id):\n",
    "        dec.train();\n",
    "        opt_dec.zero_grad();\n",
    "        loss_acc=0;\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        for _ in range(acc_num):\n",
    "            alpha,A_r,A_t,fd,tau = SV_Channel_set(2*b,Nc,N,Nt,Nr,1,v_max_km)\n",
    "            H_batch = torch.zeros(2*b,T, Nc, N_r, N_t).cuda() + 0j\n",
    "\n",
    "            for i in range(T):\n",
    "                t = i*1/14000/8 #i就表示第i个OFDM符号，每个subframe时间是1ms，每个slot包含14个OFDM符号，当子载波间隔15kHz对应一个frame包含1个slot，30kHz对应2个，60kHz->4,120kHz->8,这里采用120kHz间隔所以除以8\n",
    "                H = SV_Channel_final(2*b,Nc,N,Nt,Nr,1,t,alpha,A_r,A_t,fd,tau)\n",
    "                H_batch[:,i] = H\n",
    "            H_batch_1 = H_batch[0:b]\n",
    "            H_batch_2 = H_batch[b:2*b]\n",
    "\n",
    "            \n",
    "\n",
    "            with torch.no_grad():\n",
    "                H_CE=dec_CE(\n",
    "                    H_batch = H_batch,  # b,T, Nc, N_r, N_t 用户1\n",
    "                );\n",
    "                H_CF=dec_CF(\n",
    "                        H = H_CE,  # b,T, Nc, N_r, N_t 用户1\n",
    "                    );\n",
    "                H_CE_1 = H_CE[0:b]\n",
    "                H_CE_2 = H_CE[b:2*b]\n",
    "                H_CF_1 = H_CF[0:b]\n",
    "                H_CF_2 = H_CF[b:2*b]\n",
    "            \n",
    "            W,F_1,F_2=dec(\n",
    "                    H_CE_1 = H_CE_1,  # b, Nc, N_r, N_t 用户1\n",
    "                    H_CE_2 = H_CE_2,  # b, Nc, N_r, N_t 用户2\n",
    "                    H_CF_1 = H_CF_1,  # b, Nc, N_r, N_t 用户1\n",
    "                    H_CF_2 = H_CF_2,  # b, Nc, N_r, N_t 用户2\n",
    "                );\n",
    "\n",
    "\n",
    "\n",
    "            # loss_SE = -calculate_average_channel_capacity(H_DL_batch_beam[:,0:1], F, Pt,N0)/acc_num\n",
    "\n",
    "            loss = -calculate_average_channel_capacity_OMA_woInt(H_batch_1[:,L],H_batch_2[:,L],F_1,F_2,W, SNR_dB)/acc_num\n",
    "            loss_acc += loss.item()\n",
    "\n",
    "            loss.backward();\n",
    "        \n",
    "\n",
    "        opt_dec.step();\n",
    "\n",
    "        return loss_acc\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def evaluate(step_id):\n",
    "        global loader_test;\n",
    "        dec.eval();\n",
    "        loss_acc=0;\n",
    "        loss_acc_CE = 0\n",
    "        loss_acc_CF = 0\n",
    "        R_acc = 0\n",
    "\n",
    "        val_num = 10\n",
    "        b = 64\n",
    "        with torch.no_grad():\n",
    "            for i in range(val_num):\n",
    "\n",
    "                alpha,A_r,A_t,fd,tau = SV_Channel_set(2*b,Nc,N,Nt,Nr,1,v_max_km)\n",
    "                H_batch = torch.zeros(2*b,T, Nc, N_r, N_t).cuda() + 0j\n",
    "\n",
    "                for i in range(T):\n",
    "                    t = i*1/14000/8 #i就表示第i个OFDM符号，每个subframe时间是1ms，每个slot包含14个OFDM符号，当子载波间隔15kHz对应一个frame包含1个slot，30kHz对应2个，60kHz->4,120kHz->8,这里采用120kHz间隔所以除以8\n",
    "                    H = SV_Channel_final(2*b,Nc,N,Nt,Nr,1,t,alpha,A_r,A_t,fd,tau)\n",
    "                    H_batch[:,i] = H\n",
    "                H_batch_1 = H_batch[0:b]\n",
    "                H_batch_2 = H_batch[b:2*b]\n",
    "\n",
    "                H_CE=dec_CE(\n",
    "                    H_batch = H_batch,  # b,T, Nc, N_r, N_t 用户1\n",
    "                );\n",
    "                H_CF=dec_CF(\n",
    "                        H = H_CE,  # b,T, Nc, N_r, N_t 用户1\n",
    "                    );\n",
    "\n",
    "                loss_CE = SGCS_H(H_batch[:,L],H_CE)/val_num\n",
    "                loss_acc_CE += loss_CE.item()\n",
    "\n",
    "                loss_CF = SGCS_H(H_batch[:,L],H_CF)/val_num\n",
    "                loss_acc_CF += loss_CF.item()\n",
    "\n",
    "                H_CE_1 = H_CE[0:b]\n",
    "                H_CE_2 = H_CE[b:2*b]\n",
    "                H_CF_1 = H_CF[0:b]\n",
    "                H_CF_2 = H_CF[b:2*b]\n",
    "            \n",
    "\n",
    "\n",
    "                \n",
    "                W,F_1,F_2=dec(\n",
    "                        H_CE_1 = H_CE_1,  # b, Nc, N_r, N_t 用户1\n",
    "                        H_CE_2 = H_CE_2,  # b, Nc, N_r, N_t 用户2\n",
    "                        H_CF_1 = H_CF_1,  # b, Nc, N_r, N_t 用户1\n",
    "                        H_CF_2 = H_CF_2,  # b, Nc, N_r, N_t 用户2\n",
    "                    );\n",
    "                loss = -calculate_average_channel_capacity_OMA_woInt(H_batch_1[:,L],H_batch_2[:,L],F_1,F_2,W, SNR_dB)/val_num\n",
    "                loss_acc += loss.item()\n",
    "\n",
    "                H1 = H_batch_1[:,L:L+Q] \n",
    "                H2 = H_batch_2[:,L:L+Q] \n",
    "                H1_UE = H_CE_1.reshape(b,1,Nc,N_r,N_t)\n",
    "                H2_UE = H_CE_2.reshape(b,1,Nc,N_r,N_t)\n",
    "                H1_base = H_CF_1.reshape(b,1,Nc,N_r,N_t)\n",
    "                H2_base = H_CF_2.reshape(b,1,Nc,N_r,N_t)\n",
    "                W = W.reshape(b,1,1,N_r_RF,N_r)\n",
    "                F_1 = F_1.reshape(b,1,1,N_t,1)\n",
    "                F_2 = F_2.reshape(b,1,1,N_t,1)\n",
    "                W = Pre_WY_DMRS(H1, H2,  H1_UE, H2_UE, H1_base, H2_base, SNR_dB, rate1, rate2, W, F_1, F_2)\n",
    "\n",
    "                R1 = calculate_average_channel_capacity_T(H1, F_1, W, SNR_dB)\n",
    "                R2 = calculate_average_channel_capacity_T(H2, F_2, W, SNR_dB)\n",
    "                R_acc = R_acc + (R1.mean().item() + R2.mean().item())/2/val_num\n",
    "\n",
    "                \n",
    "\n",
    "        return loss_acc,R_acc,loss_acc_CE,loss_acc_CF\n",
    "\n",
    "    def save_ckpt(folder_name):\n",
    "        folder_path=save_path+folder_name+\"/\";\n",
    "        if not os.path.exists(folder_path):\n",
    "            os.makedirs(folder_path);\n",
    "\n",
    "        torch.save({'state_dict': dec.state_dict()}, folder_path+model_name+\"_model.pth.tar\");\n",
    "        torch.save({'best_loss': best_loss, \n",
    "                    'opt_dec_dict': opt_dec.state_dict(), \n",
    "                    }, folder_path+model_name+\"_opt.pth.tar\");\n",
    "\n",
    "    loss_SE_log=0;\n",
    "    t1=time.time();\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    with trange(iter_begin, iter_begin+ITERS) as t:\n",
    "        for i in t:            \n",
    "            loss_SE = step(i);\n",
    "            loss_SE_log+=loss_SE/log_interval;\n",
    "\n",
    "            if (i+1)%log_interval==0:\n",
    "                loss_SE,R,SGCS_CE,SGCS_CF = evaluate(i);\n",
    "                \n",
    "                logger(\"\");\n",
    "                if loss_SE<best_loss:\n",
    "                    best_loss=loss_SE;\n",
    "                    save_ckpt(\"Precoding_WY\");\n",
    "                    logger(\"\\nbest - SE = {}\".format(-best_loss));\n",
    "                \n",
    "                logger(\"log - iter[{}] - train - SE = {}\".format(i, -loss_SE_log));\n",
    "                logger(\"log - iter[{}] - test - SE = {}\".format(i, -loss_SE));\n",
    "                logger(\"log - iter[{}] - test - ZF_SE = {}\".format(i, R));\n",
    "                logger(\"log - iter[{}] - test - SGCS_CE = {}\".format(i, -SGCS_CE));\n",
    "                logger(\"log - iter[{}] - test - SGCS_CF = {}\".format(i, -SGCS_CF));\n",
    "\n",
    "                \n",
    "\n",
    "                logger(\"time: {} s\".format(time.time()-t1));\n",
    "                t1=time.time();\n",
    "\n",
    "                if (i+1)%save_interval==0:\n",
    "                    logger(\"\");\n",
    "                    logger(\"save - iter[{}] - test - SE = {}\".format(i, -loss_SE));\n",
    "                    logger(\"save - iter[{}] - best - SE = {}\".format(i, -best_loss));\n",
    "\n",
    "                    \n",
    "\n",
    "                t.set_postfix(train_SE=-loss_SE_log,test_SE=-loss_SE,best_SE=-best_loss)\n",
    "\n",
    "                loss_SE_log=0;\n",
    "    rmLogger();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_Precoding_WY_perfect(N,Nc,Nr,N_r_RF,Nt,N_t_RF,SNR_dB,v_max_km,ITERS=20_000,b=32,acc_num=1):\n",
    "    # N代表路径数\n",
    "    \n",
    "    N_t = Nt[0]*Nt[1]\n",
    "    N_r = Nr[0]*Nr[1]\n",
    "    device=0;\n",
    "    lr=1e-4;\n",
    "    log_interval=100; # 每100个输出保存一下许训练记录\n",
    "    save_interval=10*log_interval; # 每1000个测试一下保存记录\n",
    "    iter_begin=0;   #从第0个开始训练 如果不是0就读取之前训练过的check points\n",
    "    save_path=\"./weights/\";\n",
    "    best_loss=0;\n",
    "    rate1 = 4\n",
    "    rate2 = 2\n",
    "\n",
    "\n",
    "    \n",
    "    Q = 12\n",
    "    T = L+Q\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    model_name_Precoding = 'Precoding_WY_perfect' + '_v' + str(v_max_km)\n",
    "    model_name = model_name_Precoding\n",
    "\n",
    "    dec=Precoding_WY(Nc=Nc,N_r=N_r,N_r_RF=N_r_RF,N_t=N_t,N_t_RF=N_t_RF).cuda()\n",
    "    \n",
    "    opt_dec=torch.optim.AdamW(\n",
    "        dec.parameters(), \n",
    "        lr=lr, \n",
    "    )\n",
    "    print('从头训练')\n",
    "\n",
    "\n",
    "    def step(step_id):\n",
    "        dec.train();\n",
    "        opt_dec.zero_grad();\n",
    "        loss_acc=0;\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        for _ in range(acc_num):\n",
    "            alpha,A_r,A_t,fd,tau = SV_Channel_set(2*b,Nc,N,Nt,Nr,1,v_max_km)\n",
    "            H_batch = torch.zeros(2*b,T, Nc, N_r, N_t).cuda() + 0j\n",
    "\n",
    "            for i in range(T):\n",
    "                t = i*1/14000/8 #i就表示第i个OFDM符号，每个subframe时间是1ms，每个slot包含14个OFDM符号，当子载波间隔15kHz对应一个frame包含1个slot，30kHz对应2个，60kHz->4,120kHz->8,这里采用120kHz间隔所以除以8\n",
    "                H = SV_Channel_final(2*b,Nc,N,Nt,Nr,1,t,alpha,A_r,A_t,fd,tau)\n",
    "                H_batch[:,i] = H\n",
    "            H_batch_1 = H_batch[0:b]\n",
    "            H_batch_2 = H_batch[b:2*b]\n",
    "\n",
    "            \n",
    "\n",
    "            with torch.no_grad():\n",
    "\n",
    "                H_CE_1 = H_batch_1[:,L]\n",
    "                H_CE_2 = H_batch_2[:,L]\n",
    "                H_CF_1 = H_batch_1[:,L]\n",
    "                H_CF_2 = H_batch_2[:,L]\n",
    "            \n",
    "            W,F_1,F_2=dec(\n",
    "                    H_CE_1 = H_CE_1,  # b, Nc, N_r, N_t 用户1\n",
    "                    H_CE_2 = H_CE_2,  # b, Nc, N_r, N_t 用户2\n",
    "                    H_CF_1 = H_CF_1,  # b, Nc, N_r, N_t 用户1\n",
    "                    H_CF_2 = H_CF_2,  # b, Nc, N_r, N_t 用户2\n",
    "                );\n",
    "\n",
    "\n",
    "\n",
    "            # loss_SE = -calculate_average_channel_capacity(H_DL_batch_beam[:,0:1], F, Pt,N0)/acc_num\n",
    "\n",
    "            loss = -calculate_average_channel_capacity_OMA_woInt(H_batch_1[:,L],H_batch_2[:,L],F_1,F_2,W, SNR_dB)/acc_num\n",
    "            loss_acc += loss.item()\n",
    "\n",
    "            loss.backward();\n",
    "        \n",
    "\n",
    "        opt_dec.step();\n",
    "\n",
    "        return loss_acc\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def evaluate(step_id):\n",
    "        global loader_test;\n",
    "        dec.eval();\n",
    "        loss_acc=0;\n",
    "        loss_acc_CE = 0\n",
    "        loss_acc_CF = 0\n",
    "        R_acc = 0\n",
    "\n",
    "        val_num = 10\n",
    "        b = 64\n",
    "        with torch.no_grad():\n",
    "            for i in range(val_num):\n",
    "\n",
    "                alpha,A_r,A_t,fd,tau = SV_Channel_set(2*b,Nc,N,Nt,Nr,1,v_max_km)\n",
    "                H_batch = torch.zeros(2*b,T, Nc, N_r, N_t).cuda() + 0j\n",
    "\n",
    "                for i in range(T):\n",
    "                    t = i*1/14000/8 #i就表示第i个OFDM符号，每个subframe时间是1ms，每个slot包含14个OFDM符号，当子载波间隔15kHz对应一个frame包含1个slot，30kHz对应2个，60kHz->4,120kHz->8,这里采用120kHz间隔所以除以8\n",
    "                    H = SV_Channel_final(2*b,Nc,N,Nt,Nr,1,t,alpha,A_r,A_t,fd,tau)\n",
    "                    H_batch[:,i] = H\n",
    "                H_batch_1 = H_batch[0:b]\n",
    "                H_batch_2 = H_batch[b:2*b]\n",
    "\n",
    "\n",
    "                H_CE_1 = H_batch_1[:,L]\n",
    "                H_CE_2 = H_batch_2[:,L]\n",
    "                H_CF_1 = H_batch_1[:,L]\n",
    "                H_CF_2 = H_batch_2[:,L]\n",
    "            \n",
    "\n",
    "\n",
    "                \n",
    "                W,F_1,F_2=dec(\n",
    "                        H_CE_1 = H_CE_1,  # b, Nc, N_r, N_t 用户1\n",
    "                        H_CE_2 = H_CE_2,  # b, Nc, N_r, N_t 用户2\n",
    "                        H_CF_1 = H_CF_1,  # b, Nc, N_r, N_t 用户1\n",
    "                        H_CF_2 = H_CF_2,  # b, Nc, N_r, N_t 用户2\n",
    "                    );\n",
    "                loss = -calculate_average_channel_capacity_OMA_woInt(H_batch_1[:,L],H_batch_2[:,L],F_1,F_2,W, SNR_dB)/val_num\n",
    "                loss_acc += loss.item()\n",
    "\n",
    "                H1 = H_batch_1[:,L:L+Q] \n",
    "                H2 = H_batch_2[:,L:L+Q] \n",
    "                H1_UE = H_CE_1.reshape(b,1,Nc,N_r,N_t)\n",
    "                H2_UE = H_CE_2.reshape(b,1,Nc,N_r,N_t)\n",
    "                H1_base = H_CF_1.reshape(b,1,Nc,N_r,N_t)\n",
    "                H2_base = H_CF_2.reshape(b,1,Nc,N_r,N_t)\n",
    "                W = W.reshape(b,1,1,N_r_RF,N_r)\n",
    "                F_1 = F_1.reshape(b,1,1,N_t,1)\n",
    "                F_2 = F_2.reshape(b,1,1,N_t,1)\n",
    "                W = Pre_WY_DMRS(H1, H2,  H1_UE, H2_UE, H1_base, H2_base, SNR_dB, rate1, rate2, W, F_1, F_2)\n",
    "\n",
    "                R1 = calculate_average_channel_capacity_T(H1, F_1, W, SNR_dB)\n",
    "                R2 = calculate_average_channel_capacity_T(H2, F_2, W, SNR_dB)\n",
    "                R_acc = R_acc + (R1.mean().item() + R2.mean().item())/2/val_num\n",
    "\n",
    "                \n",
    "\n",
    "        return loss_acc,R_acc\n",
    "\n",
    "    def save_ckpt(folder_name):\n",
    "        folder_path=save_path+folder_name+\"/\";\n",
    "        if not os.path.exists(folder_path):\n",
    "            os.makedirs(folder_path);\n",
    "\n",
    "        torch.save({'state_dict': dec.state_dict()}, folder_path+model_name+\"_model.pth.tar\");\n",
    "        torch.save({'best_loss': best_loss, \n",
    "                    'opt_dec_dict': opt_dec.state_dict(), \n",
    "                    }, folder_path+model_name+\"_opt.pth.tar\");\n",
    "\n",
    "    loss_SE_log=0;\n",
    "    t1=time.time();\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    with trange(iter_begin, iter_begin+ITERS) as t:\n",
    "        for i in t:            \n",
    "            loss_SE = step(i);\n",
    "            loss_SE_log+=loss_SE/log_interval;\n",
    "\n",
    "            if (i+1)%log_interval==0:\n",
    "                loss_SE,R = evaluate(i);\n",
    "                \n",
    "                logger(\"\");\n",
    "                if loss_SE<best_loss:\n",
    "                    best_loss=loss_SE;\n",
    "                    save_ckpt(\"Precoding_WY\");\n",
    "                    logger(\"\\nbest - SE = {}\".format(-best_loss));\n",
    "                \n",
    "                logger(\"log - iter[{}] - train - SE = {}\".format(i, -loss_SE_log));\n",
    "                logger(\"log - iter[{}] - test - SE = {}\".format(i, -loss_SE));\n",
    "                logger(\"log - iter[{}] - test - ZF_SE = {}\".format(i, R));\n",
    "\n",
    "                \n",
    "\n",
    "                logger(\"time: {} s\".format(time.time()-t1));\n",
    "                t1=time.time();\n",
    "\n",
    "                if (i+1)%save_interval==0:\n",
    "                    logger(\"\");\n",
    "                    logger(\"save - iter[{}] - test - SE = {}\".format(i, -loss_SE));\n",
    "                    logger(\"save - iter[{}] - best - SE = {}\".format(i, -best_loss));\n",
    "\n",
    "                    \n",
    "\n",
    "                t.set_postfix(train_SE=-loss_SE_log,test_SE=-loss_SE,best_SE=-best_loss)\n",
    "\n",
    "                loss_SE_log=0;\n",
    "    rmLogger();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_Precoding_WY(N,Nc,Nr,N_r_RF,Nt,N_t_RF,L,feedback_bits,SNR_dB,v_max_km,flag_DL='DL'):\n",
    "    # N代表路径数\n",
    "    \n",
    "    N_t = Nt[0]*Nt[1]\n",
    "    N_r = Nr[0]*Nr[1]\n",
    "    device=0;\n",
    "    lr=1e-4;\n",
    "    log_interval=100; # 每100个输出保存一下许训练记录\n",
    "    save_interval=10*log_interval; # 每1000个测试一下保存记录\n",
    "    iter_begin=0;   #从第0个开始训练 如果不是0就读取之前训练过的check points\n",
    "    save_path=\"./weights/\";\n",
    "    best_loss=0;\n",
    "    rate1 = 4\n",
    "    rate2 = 2\n",
    "\n",
    "\n",
    "    model_name_CE = 'CE_WY'+'_L' + str(L)+'_v' + str(v_max_km)\n",
    "    model_name_CF = 'CF_WY'+'_bits' + str(feedback_bits)+'_L' + str(L)+'_v' + str(v_max_km)\n",
    "    model_name_Pre = 'Precoding_WY' + str(feedback_bits)+'_L' + str(L)+'_v' + str(v_max_km)\n",
    "\n",
    "    dec_CE=CE_WY(Nc=Nc,N_r=N_r,N_r_RF=N_r_RF,N_t=N_t,N_t_RF=N_t_RF,L=L).cuda()\n",
    "    dec_CF=CF_WY(Nc=Nc,N_r=N_r,N_t=N_t,feedback_bits=feedback_bits).cuda()\n",
    "    dec_Pre=Precoding_WY(Nc=Nc,N_r=N_r,N_r_RF=N_r_RF,N_t=N_t,N_t_RF=N_t_RF).cuda()\n",
    "    \n",
    "    Q = 12\n",
    "    T = L+Q\n",
    "    load_path_CE=save_path+\"CE_WY\"+\"/\";\n",
    "    load_path_CF=save_path+\"CF_WY\"+\"/\";\n",
    "    load_path_Pre=save_path+\"Precoding_WY\"+\"/\";\n",
    "\n",
    "    dec_dict = dec_CE.state_dict()\n",
    "    dec_load_path=load_path_CE+model_name_CE+\"_model.pth.tar\";\n",
    "    ckpt=torch.load(dec_load_path, map_location=\"cuda:\"+str(device));\n",
    "    pretrained_dict=ckpt['state_dict'];\n",
    "    pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in dec_dict}\n",
    "    dec_dict.update(pretrained_dict);\n",
    "    dec_CE.load_state_dict(dec_dict);\n",
    "    dec_CE.eval()\n",
    "\n",
    "\n",
    "\n",
    "    dec_dict = dec_CF.state_dict()\n",
    "    dec_load_path=load_path_CF+model_name_CF+\"_model.pth.tar\";\n",
    "    ckpt=torch.load(dec_load_path, map_location=\"cuda:\"+str(device));\n",
    "    pretrained_dict=ckpt['state_dict'];\n",
    "    pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in dec_dict}\n",
    "    dec_dict.update(pretrained_dict);\n",
    "    dec_CF.load_state_dict(dec_dict);\n",
    "    dec_CF.eval()\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    dec_dict = dec_Pre.state_dict()\n",
    "    dec_load_path=load_path_Pre+model_name_Pre+\"_model.pth.tar\";\n",
    "    ckpt=torch.load(dec_load_path, map_location=\"cuda:\"+str(device));\n",
    "    pretrained_dict=ckpt['state_dict'];\n",
    "    pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in dec_dict}\n",
    "    dec_dict.update(pretrained_dict);\n",
    "    dec_Pre.load_state_dict(dec_dict);\n",
    "    dec_Pre.eval()\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def evaluate(step_id):\n",
    "        global loader_test;\n",
    "        loss_acc=0;\n",
    "        loss_acc_CE = 0\n",
    "        loss_acc_CF = 0\n",
    "        R_acc = 0\n",
    "\n",
    "        val_num = 10\n",
    "        b = 64\n",
    "        with torch.no_grad():\n",
    "            for i in range(val_num):\n",
    "\n",
    "                alpha,A_r,A_t,fd,tau = SV_Channel_set(2*b,Nc,N,Nt,Nr,1,v_max_km)\n",
    "                H_batch = torch.zeros(2*b,T, Nc, N_r, N_t).cuda() + 0j\n",
    "\n",
    "                for i in range(T):\n",
    "                    t = i*1/14000/8 #i就表示第i个OFDM符号，每个subframe时间是1ms，每个slot包含14个OFDM符号，当子载波间隔15kHz对应一个frame包含1个slot，30kHz对应2个，60kHz->4,120kHz->8,这里采用120kHz间隔所以除以8\n",
    "                    H = SV_Channel_final(2*b,Nc,N,Nt,Nr,1,t,alpha,A_r,A_t,fd,tau)\n",
    "                    H_batch[:,i] = H\n",
    "                H_batch_1 = H_batch[0:b]\n",
    "                H_batch_2 = H_batch[b:2*b]\n",
    "\n",
    "                H_CE=dec_CE(\n",
    "                    H_batch = H_batch,  # b,T, Nc, N_r, N_t 用户1\n",
    "                );\n",
    "                H_CF=dec_CF(\n",
    "                        H = H_CE,  # b,T, Nc, N_r, N_t 用户1\n",
    "                    );\n",
    "\n",
    "                loss_CE = SGCS_H(H_batch[:,L],H_CE)/val_num\n",
    "                loss_acc_CE += loss_CE.item()\n",
    "\n",
    "                loss_CF = SGCS_H(H_batch[:,L],H_CF)/val_num\n",
    "                loss_acc_CF += loss_CF.item()\n",
    "\n",
    "                H_CE_1 = H_CE[0:b]\n",
    "                H_CE_2 = H_CE[b:2*b]\n",
    "                H_CF_1 = H_CF[0:b]\n",
    "                H_CF_2 = H_CF[b:2*b]\n",
    "            \n",
    "\n",
    "\n",
    "                \n",
    "                # W,F_1,F_2=dec_Pre(\n",
    "                #         H_CE_1 = H_CE_1,  # b, Nc, N_r, N_t 用户1\n",
    "                #         H_CE_2 = H_CE_2,  # b, Nc, N_r, N_t 用户2\n",
    "                #         H_CF_1 = H_CF_1,  # b, Nc, N_r, N_t 用户1\n",
    "                #         H_CF_2 = H_CF_2,  # b, Nc, N_r, N_t 用户2\n",
    "                #     );\n",
    "                # # loss = -calculate_average_channel_capacity_OMA_woInt(H_batch_1[:,L],H_batch_2[:,L],F_1,F_2,W, SNR_dB)/val_num\n",
    "                # # loss_acc += loss.item()\n",
    "\n",
    "                # H1 = H_batch_1[:,L:L+Q] \n",
    "                # H2 = H_batch_2[:,L:L+Q] \n",
    "                # H1_UE = H_CE_1.reshape(b,1,Nc,N_r,N_t)\n",
    "                # H2_UE = H_CE_2.reshape(b,1,Nc,N_r,N_t)\n",
    "                # H1_base = H_CF_1.reshape(b,1,Nc,N_r,N_t)\n",
    "                # H2_base = H_CF_2.reshape(b,1,Nc,N_r,N_t)\n",
    "                # W = W.reshape(b,1,1,N_r_RF,N_r)\n",
    "                # F_1 = F_1.reshape(b,1,1,N_t,1)\n",
    "                # F_2 = F_2.reshape(b,1,1,N_t,1)\n",
    "                # W = Pre_WY_DMRS(H1, H2,  H1_UE, H2_UE, H1_base, H2_base, SNR_dB, rate1, rate2, W, F_1, F_2)\n",
    "\n",
    "\n",
    "                if flag_DL == 'DL':\n",
    "                    W,F_1,F_2=dec_Pre(\n",
    "                            H_CE_1 = H_CE_1,  # b, Nc, N_r, N_t 用户1\n",
    "                            H_CE_2 = H_CE_2,  # b, Nc, N_r, N_t 用户2\n",
    "                            H_CF_1 = H_CF_1,  # b, Nc, N_r, N_t 用户1\n",
    "                            H_CF_2 = H_CF_2,  # b, Nc, N_r, N_t 用户2\n",
    "                        );\n",
    "                    loss = -calculate_average_channel_capacity_OMA_woInt(H_batch_1[:,L],H_batch_2[:,L],F_1,F_2,W, SNR_dB)/val_num\n",
    "                    loss_acc += loss.item()\n",
    "\n",
    "\n",
    "                    H1 = H_batch_1[:,L:L+Q] \n",
    "                    H2 = H_batch_2[:,L:L+Q] \n",
    "                    H1_UE = H_CE_1.reshape(b,1,Nc,N_r,N_t)\n",
    "                    H2_UE = H_CE_2.reshape(b,1,Nc,N_r,N_t)\n",
    "                    H1_base = H_CF_1.reshape(b,1,Nc,N_r,N_t)\n",
    "                    H2_base = H_CF_2.reshape(b,1,Nc,N_r,N_t)\n",
    "                    W = W.reshape(b,1,1,N_r_RF,N_r)\n",
    "                    F_1 = F_1.reshape(b,1,1,N_t,1)\n",
    "                    F_2 = F_2.reshape(b,1,1,N_t,1)\n",
    "                    W = Pre_WY_DMRS(H1, H2,  H1_UE, H2_UE, H1_base, H2_base, SNR_dB, rate1, rate2, W, F_1, F_2) #b,Q,Nc,2,N_r\n",
    "                elif flag_DL == 'PCA':\n",
    "                    H1 = H_batch_1[:,L:L+Q] \n",
    "                    H2 = H_batch_2[:,L:L+Q] \n",
    "                    H1_UE = H_CE_1.reshape(b,1,Nc,N_r,N_t)\n",
    "                    H2_UE = H_CE_2.reshape(b,1,Nc,N_r,N_t)\n",
    "                    H1_base = H_CF_1.reshape(b,1,Nc,N_r,N_t)\n",
    "                    H2_base = H_CF_2.reshape(b,1,Nc,N_r,N_t)\n",
    "                    P_analog1,P_analog2,C_analog,C_digital,F_1, F_2, W = Pre_PCA_total_analog(H1, H2,  H1_UE, H2_UE, H1_base, H2_base, SNR_dB, rate1, rate2)\n",
    "\n",
    "                    loss = -calculate_average_channel_capacity_OMA_woInt(H_batch_1[:,L],H_batch_2[:,L],F_1.reshape(b,1,N_t,1),F_2.reshape(b,1,N_t,1),C_analog.reshape(b,1,N_r_RF,N_r), SNR_dB)/val_num\n",
    "                    loss_acc += loss.item()\n",
    "\n",
    "\n",
    "\n",
    "                R1 = calculate_average_channel_capacity_T(H1, F_1, W, SNR_dB)\n",
    "                R2 = calculate_average_channel_capacity_T(H2, F_2, W, SNR_dB)\n",
    "                R_acc = R_acc + (R1.mean().item() + R2.mean().item())/2/val_num\n",
    "\n",
    "                \n",
    "\n",
    "        return loss_acc,R_acc,loss_acc_CE,loss_acc_CF\n",
    "\n",
    "    \n",
    "    loss_SE,R,SGCS_CE,SGCS_CF = evaluate(0);\n",
    "    print(\"SGCS_CE: \",-SGCS_CE,\"    SGCS_CF: \",-SGCS_CF,\"    SE: \",loss_SE,\"    ZF_SE: \",R)\n",
    "                \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 0\n",
    "Nc = 100\n",
    "N = 2\n",
    "Nt = [1,8]\n",
    "Nr = [1,64]\n",
    "N_r_RF = 2\n",
    "N_t_RF = 2\n",
    "\n",
    "\n",
    "SNR_dB = 10\n",
    "v_max_km = 120\n",
    "# train_Precoding_WY(N,Nc,Nr,N_r_RF,Nt,N_r_RF,L,feedback_bits,SNR_dB,v_max_km,feedback_bits_pre,v_max_km_pre,ITERS=20_000,b=64,acc_num=1)\n",
    "\n",
    "train_Precoding_WY_perfect(N,Nc,Nr,N_r_RF,Nt,N_t_RF,SNR_dB,v_max_km,ITERS=40_000,b=64,acc_num=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t = 0\n",
    "# Nc = 100\n",
    "# N = 2\n",
    "# Nt = [1,8]\n",
    "# Nr = [1,64]\n",
    "# N_r_RF = 2\n",
    "# N_t_RF = 2\n",
    "\n",
    "# L = 8\n",
    "\n",
    "# feedback_bits_pre = None\n",
    "# v_max_km_pre = None\n",
    "\n",
    "# feedback_bits = 1024\n",
    "# SNR_dB = 10\n",
    "# v_max_km = 120\n",
    "# for L in [16]:\n",
    "#     train_Precoding_WY(N,Nc,Nr,N_r_RF,Nt,N_r_RF,L,feedback_bits,SNR_dB,v_max_km,feedback_bits_pre,v_max_km_pre,ITERS=20_000,b=64,acc_num=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 0\n",
    "Nc = 100\n",
    "N = 2\n",
    "Nt = [1,8]\n",
    "Nr = [1,64]\n",
    "N_r_RF = 2\n",
    "N_t_RF = 2\n",
    "\n",
    "L = 8\n",
    "\n",
    "feedback_bits_pre = None\n",
    "v_max_km_pre = None\n",
    "\n",
    "feedback_bits = 1024\n",
    "SNR_dB = 10\n",
    "v_max_km = 120\n",
    "for feedback_bits in [256]:\n",
    "# for feedback_bits in [256,4096]:\n",
    "    train_Precoding_WY(N,Nc,Nr,N_r_RF,Nt,N_r_RF,L,feedback_bits,SNR_dB,v_max_km,feedback_bits_pre,v_max_km_pre,ITERS=10_000,b=64,acc_num=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 开始测试"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 0\n",
    "Nc = 100\n",
    "N = 2\n",
    "Nt = [1,8]\n",
    "Nr = [1,64]\n",
    "N_r_RF = 2\n",
    "N_t_RF = 2\n",
    "\n",
    "L = 8\n",
    "\n",
    "feedback_bits_pre = None\n",
    "v_max_km_pre = None\n",
    "\n",
    "feedback_bits = 1024\n",
    "SNR_dB = 10\n",
    "v_max_km = 120\n",
    "for L in [1,2,4,8,16]:\n",
    "    test_Precoding_WY(N,Nc,Nr,N_r_RF,Nt,N_r_RF,L,feedback_bits,SNR_dB,v_max_km)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 0\n",
    "Nc = 100\n",
    "N = 2\n",
    "Nt = [1,8]\n",
    "Nr = [1,64]\n",
    "N_r_RF = 2\n",
    "N_t_RF = 2\n",
    "\n",
    "L = 8\n",
    "\n",
    "feedback_bits_pre = None\n",
    "v_max_km_pre = None\n",
    "\n",
    "feedback_bits = 1024\n",
    "SNR_dB = 10\n",
    "v_max_km = 120\n",
    "for feedback_bits in [4,16,64,256,1024]:\n",
    "    test_Precoding_WY(N,Nc,Nr,N_r_RF,Nt,N_r_RF,L,feedback_bits,SNR_dB,v_max_km)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 0\n",
    "Nc = 100\n",
    "N = 2\n",
    "Nt = [1,8]\n",
    "Nr = [1,64]\n",
    "N_r_RF = 2\n",
    "N_t_RF = 2\n",
    "\n",
    "L = 8\n",
    "\n",
    "feedback_bits_pre = None\n",
    "v_max_km_pre = None\n",
    "\n",
    "flag_DL = 'PCA'\n",
    "\n",
    "feedback_bits = 1024\n",
    "SNR_dB = 10\n",
    "v_max_km = 120\n",
    "for L in [1,2,4,8,16]:\n",
    "    test_Precoding_WY(N,Nc,Nr,N_r_RF,Nt,N_r_RF,L,feedback_bits,SNR_dB,v_max_km,flag_DL=flag_DL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 0\n",
    "Nc = 100\n",
    "N = 2\n",
    "Nt = [1,8]\n",
    "Nr = [1,64]\n",
    "N_r_RF = 2\n",
    "N_t_RF = 2\n",
    "\n",
    "L = 8\n",
    "\n",
    "feedback_bits_pre = None\n",
    "v_max_km_pre = None\n",
    "\n",
    "flag_DL = 'PCA'\n",
    "\n",
    "feedback_bits = 1024\n",
    "SNR_dB = 10\n",
    "v_max_km = 120\n",
    "for feedback_bits in [4,16,64,256,1024]:\n",
    "    test_Precoding_WY(N,Nc,Nr,N_r_RF,Nt,N_r_RF,L,feedback_bits,SNR_dB,v_max_km,flag_DL=flag_DL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 端到端预编码"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class E2E_base(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            Nc,     #子载波数\n",
    "            N_r,    #基站接收天线数\n",
    "            N_r_RF, #基站射频数\n",
    "            N_t,    #用户发送天线数\n",
    "            N_t_RF, #用户发送射频数\n",
    "            L,      #导频OFDM符号数\n",
    "            feedback_bits, # 反馈比特数\n",
    "        ):\n",
    "        super().__init__();\n",
    "\n",
    "        \n",
    "        dec_CE=CE_WY(Nc=Nc,N_r=N_r,N_r_RF=N_r_RF,N_t=N_t,N_t_RF=N_t_RF,L=L).cuda()\n",
    "        dec_CF=CF_WY(Nc=Nc,N_r=N_r,N_t=N_t,feedback_bits=feedback_bits).cuda()\n",
    "        dec_Pre=Precoding_WY(Nc=Nc,N_r=N_r,N_r_RF=N_r_RF,N_t=N_t,N_t_RF=N_t_RF).cuda()\n",
    "\n",
    "       \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    def forward(\n",
    "            self, \n",
    "            H_batch,  # b,T, Nc, N_r, N_t 用户1\n",
    "        ):\n",
    "        received_pilot = self.Pilot_trans(H_batch)\n",
    "        H_hat = self.pilot2H(received_pilot)\n",
    "        return H_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 含噪语义分割"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBnLeakyRelu2d(nn.Module):\n",
    "    # convolution\n",
    "    # batch normalization\n",
    "    # leaky relu\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, padding=1, stride=1, dilation=1, groups=1):\n",
    "        super(ConvBnLeakyRelu2d, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, padding=padding, stride=stride, dilation=dilation, groups=groups)\n",
    "        self.bn   = nn.BatchNorm2d(out_channels)\n",
    "    def forward(self, x):\n",
    "        return F.leaky_relu(self.bn(self.conv(x)), negative_slope=0.2)\n",
    "\n",
    "\n",
    "class MiniInception(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(MiniInception, self).__init__()\n",
    "        self.conv1_left  = ConvBnLeakyRelu2d(in_channels,   out_channels//2)\n",
    "        self.conv1_right = ConvBnLeakyRelu2d(in_channels,   out_channels//2, padding=2, dilation=2)\n",
    "        self.conv2_left  = ConvBnLeakyRelu2d(out_channels,  out_channels//2)\n",
    "        self.conv2_right = ConvBnLeakyRelu2d(out_channels,  out_channels//2, padding=2, dilation=2)\n",
    "        self.conv3_left  = ConvBnLeakyRelu2d(out_channels,  out_channels//2)\n",
    "        self.conv3_right = ConvBnLeakyRelu2d(out_channels,  out_channels//2, padding=2, dilation=2)\n",
    "    def forward(self,x):\n",
    "        x = torch.cat((self.conv1_left(x), self.conv1_right(x)), dim=1)\n",
    "        x = torch.cat((self.conv2_left(x), self.conv2_right(x)), dim=1)\n",
    "        x = torch.cat((self.conv3_left(x), self.conv3_right(x)), dim=1)\n",
    "        return x\n",
    "\n",
    "\n",
    "class MFNet_Enc_rgb_noise(nn.Module):\n",
    "\n",
    "    def __init__(self, Q_ini):\n",
    "        super(MFNet_Enc_rgb_noise, self).__init__()\n",
    "        rgb_ch = [16,48,48,96,192]\n",
    "        # self.pho = 2\n",
    "        # inf_ch = [16,48,48,96,96]\n",
    "        # 压缩后的每个样本维度为[2，30，40]我们正好可以设置为单流2个实虚部组成的2、30个子载波和40个OFDM符号\n",
    "        compress_ch = [192,96,96,2*Q_ini]\n",
    "        self.compress_ch = compress_ch\n",
    "        out_dim = 2400\n",
    "\n",
    "        self.conv1_rgb   = ConvBnLeakyRelu2d(3, rgb_ch[0])\n",
    "        self.conv2_1_rgb = ConvBnLeakyRelu2d(rgb_ch[0], rgb_ch[1])\n",
    "        self.conv2_2_rgb = ConvBnLeakyRelu2d(rgb_ch[1], rgb_ch[1])\n",
    "        self.conv3_1_rgb = ConvBnLeakyRelu2d(rgb_ch[1], rgb_ch[2])\n",
    "        self.conv3_2_rgb = ConvBnLeakyRelu2d(rgb_ch[2], rgb_ch[2])\n",
    "        self.conv4_rgb   = MiniInception(rgb_ch[2], rgb_ch[3])\n",
    "        self.conv5_rgb   = MiniInception(rgb_ch[3], rgb_ch[4])\n",
    "        self.compress_1_rgb = ConvBnLeakyRelu2d(compress_ch[0], compress_ch[1])\n",
    "        self.compress_2_rgb = ConvBnLeakyRelu2d(compress_ch[1], compress_ch[2])\n",
    "        self.compress_3_rgb = ConvBnLeakyRelu2d(compress_ch[2], compress_ch[3])\n",
    "    def forward(self, x):\n",
    "        # split data into RGB and INF\n",
    "        x_rgb = x[:,:3]\n",
    "\n",
    "        # encode\n",
    "        x_rgb    = self.conv1_rgb(x_rgb)\n",
    "        x_rgb    = F.max_pool2d(x_rgb, kernel_size=2, stride=2) # pool1\n",
    "        x_rgb    = self.conv2_1_rgb(x_rgb)\n",
    "        x_rgb_p2 = self.conv2_2_rgb(x_rgb)\n",
    "        x_rgb    = F.max_pool2d(x_rgb_p2, kernel_size=2, stride=2) # pool2\n",
    "        x_rgb    = self.conv3_1_rgb(x_rgb)\n",
    "        x_rgb_p3 = self.conv3_2_rgb(x_rgb)\n",
    "        x_rgb    = F.max_pool2d(x_rgb_p3, kernel_size=2, stride=2) # pool3\n",
    "        x_rgb_p4 = self.conv4_rgb(x_rgb)\n",
    "        x_rgb    = F.max_pool2d(x_rgb_p4, kernel_size=2, stride=2) # pool4 #[batch,2,30,40]\n",
    "        x_rgb    = self.conv5_rgb(x_rgb)  #[batch,96,30,40]\n",
    "        x_rgb    = F.max_pool2d(x_rgb, kernel_size=(3,4), stride=(3,4)) # pool5  \n",
    "\n",
    "        x_rgb    = self.compress_1_rgb(x_rgb)  \n",
    "        x_rgb    = self.compress_2_rgb(x_rgb)\n",
    "        x_rgb    = self.compress_3_rgb(x_rgb) #[batch,2*Q_ini,10,10]\n",
    "        return x_rgb\n",
    "\n",
    "\n",
    "class MFNet_Enc_inf_noise(nn.Module):\n",
    "\n",
    "    def __init__(self, Q_ini):\n",
    "        super(MFNet_Enc_inf_noise, self).__init__()\n",
    "        rgb_ch = [16,48,48,96,192]\n",
    "        # self.pho = 2\n",
    "        # inf_ch = [16,48,48,96,96]\n",
    "        # 压缩后的每个样本维度为[2，30，40]我们正好可以设置为单流2个实虚部组成的2、30个子载波和40个OFDM符号\n",
    "        compress_ch = [192,96,96,2*Q_ini]\n",
    "        self.compress_ch = compress_ch\n",
    "        out_dim = 2400\n",
    "\n",
    "        self.conv1_inf   = ConvBnLeakyRelu2d(1, rgb_ch[0])\n",
    "        self.conv2_1_inf = ConvBnLeakyRelu2d(rgb_ch[0], rgb_ch[1])\n",
    "        self.conv2_2_inf = ConvBnLeakyRelu2d(rgb_ch[1], rgb_ch[1])\n",
    "        self.conv3_1_inf = ConvBnLeakyRelu2d(rgb_ch[1], rgb_ch[2])\n",
    "        self.conv3_2_inf = ConvBnLeakyRelu2d(rgb_ch[2], rgb_ch[2])\n",
    "        self.conv4_inf   = MiniInception(rgb_ch[2], rgb_ch[3])\n",
    "        self.conv5_inf   = MiniInception(rgb_ch[3], rgb_ch[4])\n",
    "        self.compress_1_inf = ConvBnLeakyRelu2d(compress_ch[0], compress_ch[1])\n",
    "        self.compress_2_inf = ConvBnLeakyRelu2d(compress_ch[1], compress_ch[2])\n",
    "        self.compress_3_inf = ConvBnLeakyRelu2d(compress_ch[2], compress_ch[3])\n",
    "    def forward(self, x):\n",
    "        # split data into RGB and INF\n",
    "        x_inf = x[:,3:]\n",
    "\n",
    "        # encode\n",
    "        x_inf    = self.conv1_inf(x_inf)\n",
    "        x_inf    = F.max_pool2d(x_inf, kernel_size=2, stride=2) # pool1\n",
    "        x_inf    = self.conv2_1_inf(x_inf)\n",
    "        x_inf_p2 = self.conv2_2_inf(x_inf)\n",
    "        x_inf    = F.max_pool2d(x_inf_p2, kernel_size=2, stride=2) # pool2\n",
    "        x_inf    = self.conv3_1_inf(x_inf)\n",
    "        x_inf_p3 = self.conv3_2_inf(x_inf)\n",
    "        x_inf    = F.max_pool2d(x_inf_p3, kernel_size=2, stride=2) # pool3\n",
    "        x_inf_p4 = self.conv4_inf(x_inf)\n",
    "        x_inf    = F.max_pool2d(x_inf_p4, kernel_size=2, stride=2) # pool4 #[batch,96,30,40]\n",
    "        x_inf    = self.conv5_inf(x_inf)\n",
    "        x_inf    = F.max_pool2d(x_inf, kernel_size=(3,4), stride=(3,4)) # pool5  \n",
    "\n",
    "        x_inf    = self.compress_1_inf(x_inf)  \n",
    "        x_inf    = self.compress_2_inf(x_inf)  \n",
    "        x_inf    = self.compress_3_inf(x_inf)    #[batch,2*Q_ini,10,10]\n",
    "        return x_inf\n",
    "\n",
    "class MFNet_Dec_noise(nn.Module):\n",
    "\n",
    "    def __init__(self, n_class,Q_ini):\n",
    "        super(MFNet_Dec_noise, self).__init__()\n",
    "        rgb_ch = [16,48,48,96,192]\n",
    "        # self.pho = 2\n",
    "        # inf_ch = [16,48,48,96,96]\n",
    "        # 压缩后的每个样本维度为 #[2*Q_ini,10,10]我们keyi\n",
    "        compress_ch = [192,96,96,2*Q_ini]\n",
    "        self.compress_ch = compress_ch\n",
    "        out_dim = 2400\n",
    "\n",
    "        self.decompress_3 = ConvBnLeakyRelu2d(compress_ch[3], compress_ch[2])\n",
    "        self.decompress_2 = ConvBnLeakyRelu2d(compress_ch[2], compress_ch[1])\n",
    "        self.decompress_1 = ConvBnLeakyRelu2d(compress_ch[1], compress_ch[0])\n",
    "\n",
    "\n",
    "        self.decode5     = ConvBnLeakyRelu2d(rgb_ch[4], rgb_ch[3])\n",
    "        self.decode4     = ConvBnLeakyRelu2d(rgb_ch[3], rgb_ch[2])\n",
    "        self.decode3     = ConvBnLeakyRelu2d(rgb_ch[2], rgb_ch[1])\n",
    "        self.decode2     = ConvBnLeakyRelu2d(rgb_ch[1], rgb_ch[0])\n",
    "        self.decode1     = ConvBnLeakyRelu2d(rgb_ch[0], n_class)\n",
    "    def forward(self, x):\n",
    "        #[batch,8,30,40]\n",
    "        # x = self.decompress_4(x)\n",
    "        # x = x.reshape(-1,8,self.pho,15,20).permute(0,2,1,3,4)\n",
    "        # x = x.reshape(-1,self.pho*8,15,20)\n",
    "        # x = self.decompress_4(x.permute(0,1,3,2)).permute(0,1,3,2)\n",
    "        x = self.decompress_3(x)\n",
    "        x = self.decompress_2(x)\n",
    "        x = self.decompress_1(x) #[batch,96,30,40]\n",
    "\n",
    "        # decode\n",
    "        x = F.interpolate(x, scale_factor=(3,4), mode='nearest')# unpool5\n",
    "        x = self.decode5(x)\n",
    "        x = F.upsample(x, scale_factor=2, mode='nearest') # unpool4\n",
    "        x = self.decode4(x)\n",
    "        x = F.upsample(x, scale_factor=2, mode='nearest') # unpool3\n",
    "        x = self.decode3(x)\n",
    "        x = F.upsample(x, scale_factor=2, mode='nearest') # unpool2\n",
    "        x = self.decode2(x)\n",
    "        x = F.upsample(x, scale_factor=2, mode='nearest') # unpool1\n",
    "        x = self.decode1(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "#我这里Q_ini是假设不DMRS的导频开销数，实际的Q需要再乘上插值的系数，为了方便考虑就不完全模拟插值的过程了直接在Q_ini这个维度传输吧\n",
    "class MFNet_noise(nn.Module):\n",
    "\n",
    "    def __init__(self, n_class, Q_ini):\n",
    "        super(MFNet_noise, self).__init__()\n",
    "        self.enc_rgb = MFNet_Enc_rgb_noise(Q_ini)\n",
    "        self.enc_inf = MFNet_Enc_inf_noise(Q_ini)\n",
    "        self.dec = MFNet_Dec_noise(n_class,Q_ini)\n",
    "        self.Q_ini = Q_ini\n",
    "        \n",
    "        \n",
    "\n",
    "    def forward(self, x, snr_min, snr_max):\n",
    "        b = x.shape[0]\n",
    "        Q_ini = self.Q_ini\n",
    "        x_rgb = self.enc_rgb(x)  #[batch,2*Q_ini,10,10]\n",
    "        x_inf = self.enc_inf(x)  #[batch,2*Q_ini,10,10]\n",
    "\n",
    "\n",
    "        x_rgb = x_rgb[:,0:Q_ini,:,:] + 1j*x_rgb[:,Q_ini:2*Q_ini,:,:] #[batch,Q_ini,10,10]\n",
    "        norm_factor = torch.sqrt(torch.sum(torch.abs(x_rgb)**2, dim=(-3,-2, -1), keepdim=True))\n",
    "        x_rgb = x_rgb / norm_factor * torch.sqrt(torch.tensor(100*Q_ini, dtype=x.dtype, device=x.device))\n",
    "\n",
    "        x_inf = x_inf[:,0:Q_ini,:,:] + 1j*x_inf[:,Q_ini:2*Q_ini,:,:] #[batch,Q_ini,10,10]\n",
    "        norm_factor = torch.sqrt(torch.sum(torch.abs(x_inf)**2, dim=(-3,-2, -1), keepdim=True))\n",
    "        x_inf = x_inf / norm_factor * torch.sqrt(torch.tensor(100*Q_ini, dtype=x.dtype, device=x.device))\n",
    "\n",
    "        ########## 接下来需要加个噪声，每个样本各自加不同的噪声，两个用户也加不同的，给x_rgb和x_inf各自加\n",
    "        snr1 = snr_min + (snr_max - snr_min) * torch.rand(b).cuda()  # [b]\n",
    "        snr2 = snr_min + (snr_max - snr_min) * torch.rand(b).cuda()  # [b]\n",
    "        snr1_linear = 10**(snr1 / 10.0) # [b]\n",
    "        snr2_linear = 10**(snr2 / 10.0) # [b]\n",
    "        # 已知信号功率为1，根据SNR计算噪声功率\n",
    "        noise_power_for_x1 = 1.0 / snr1_linear\n",
    "        noise_power_for_x2 = 1.0 / snr2_linear\n",
    "        # 为每个样本生成复噪声\n",
    "        # 噪声为复高斯噪声：real和imag独立且都为N(0, noise_power/2)\n",
    "        noise_x1_real = torch.randn_like(x_rgb.real) * torch.sqrt(noise_power_for_x1[:, None, None, None] / 2.0)\n",
    "        noise_x1_imag = torch.randn_like(x_rgb.imag) * torch.sqrt(noise_power_for_x1[:, None, None, None] / 2.0)\n",
    "        noise_x1 = noise_x1_real + 1j * noise_x1_imag\n",
    "        noise_x2_real = torch.randn_like(x_inf.real) * torch.sqrt(noise_power_for_x2[:, None, None, None] / 2.0)\n",
    "        noise_x2_imag = torch.randn_like(x_inf.imag) * torch.sqrt(noise_power_for_x2[:, None, None, None] / 2.0)\n",
    "        noise_x2 = noise_x2_real + 1j * noise_x2_imag\n",
    "        x_rgb = x_rgb + noise_x1\n",
    "        x_inf = x_inf + noise_x2\n",
    "\n",
    "        x = x_rgb + x_inf        #[batch,Q_ini,10,10]\n",
    "        norm_factor = torch.sqrt(torch.sum(torch.abs(x)**2, dim=(-3,-2, -1), keepdim=True))\n",
    "        x = x / norm_factor * torch.sqrt(torch.tensor(100*Q_ini, dtype=x.dtype, device=x.device))\n",
    "        x=torch.cat([x.real, x.imag], dim=1);  # batch,2*Q_ini,10,10\n",
    "        \n",
    "        x = self.dec(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding:utf-8\n",
    "import os\n",
    "import argparse\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from util.MF_dataset import MF_dataset\n",
    "from util.util import calculate_accuracy, calculate_result\n",
    "from util.augmentation import RandomFlip, RandomCrop, RandomCropOut, RandomBrightness, RandomNoise\n",
    "from model import MFNet, SegNet\n",
    "\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# config\n",
    "n_class   = 9\n",
    "data_dir  = './ir_seg_dataset/'\n",
    "model_dir = 'weights/'\n",
    "augmentation_methods = [\n",
    "    RandomFlip(prob=0.5),\n",
    "    RandomCrop(crop_rate=0.1, prob=1.0), \n",
    "    # RandomCropOut(crop_rate=0.2, prob=1.0),\n",
    "    # RandomBrightness(bright_range=0.15, prob=0.9),\n",
    "    # RandomNoise(noise_range=5, prob=0.9),\n",
    "]\n",
    "lr_start  = 0.01\n",
    "lr_decay  = 0.95\n",
    "\n",
    "\n",
    "def train(args, epo, model, train_loader, optimizer, snr_min, snr_max):\n",
    "\n",
    "    lr_this_epo = lr_start * lr_decay**(epo-1)\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr_this_epo\n",
    "\n",
    "    loss_avg = 0.\n",
    "    acc_avg  = 0.\n",
    "    start_t = t = time.time()\n",
    "    model.train()\n",
    "\n",
    "    for it, (images, labels, names) in enumerate(train_loader):\n",
    "        images = Variable(images).cuda(args.gpu) \n",
    "        labels = Variable(labels).cuda(args.gpu)\n",
    "        # if args.gpu >= 0:\n",
    "        #     images = images.cuda(args.gpu)\n",
    "        #     labels = labels.cuda(args.gpu)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(images, snr_min, snr_max)\n",
    "        # print(labels.min(), labels.max())\n",
    "\n",
    "        loss = F.cross_entropy(logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        acc = calculate_accuracy(logits, labels)\n",
    "        loss_avg += float(loss.item())\n",
    "        acc_avg  += float(acc)\n",
    "\n",
    "        # cur_t = time.time()\n",
    "        # if cur_t-t > 5:\n",
    "        #     print('|- epo %s/%s. train iter %s/%s. %.2f img/sec loss: %.4f, acc: %.4f' \\\n",
    "        #         % (epo, args.epoch_max, it+1, train_loader.n_iter, (it+1)*args.batch_size/(cur_t-start_t), float(loss), float(acc)))\n",
    "        #     t += 5\n",
    "\n",
    "    content = '| epo:%s/%s lr:%.4f train_loss_avg:%.4f train_acc_avg:%.4f ' \\\n",
    "            % (epo, args.epoch_max, lr_this_epo, loss_avg/train_loader.n_iter, acc_avg/train_loader.n_iter)\n",
    "    print(content)\n",
    "    # with open(log_file, 'a') as appender:\n",
    "    #     appender.write(content)\n",
    "\n",
    "\n",
    "def validation(args, epo, model, val_loader, snr_min, snr_max):\n",
    "\n",
    "    loss_avg = 0.\n",
    "    acc_avg  = 0.\n",
    "    start_t = time.time()\n",
    "    model.eval()\n",
    "\n",
    "    cf = np.zeros((n_class, n_class))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for it, (images, labels, names) in enumerate(val_loader):\n",
    "            images = Variable(images)\n",
    "            labels = Variable(labels)\n",
    "            if args.gpu >= 0:\n",
    "                images = images.cuda(args.gpu)\n",
    "                labels = labels.cuda(args.gpu)\n",
    "\n",
    "            logits = model(images, snr_min, snr_max)\n",
    "            loss = F.cross_entropy(logits, labels)\n",
    "            acc = calculate_accuracy(logits, labels)\n",
    "            loss_avg += float(loss)\n",
    "            acc_avg  += float(acc)\n",
    "\n",
    "            # cur_t = time.time()\n",
    "            # print('|- epo %s/%s. val iter %s/%s. %.2f img/sec loss: %.4f, acc: %.4f' \\\n",
    "            #         % (epo, args.epoch_max, it+1, val_loader.n_iter, (it+1)*args.batch_size/(cur_t-start_t), float(loss), float(acc)))\n",
    "\n",
    "            predictions = logits.argmax(1)\n",
    "            for gtcid in range(n_class): \n",
    "                for pcid in range(n_class):\n",
    "                    gt_mask      = labels == gtcid \n",
    "                    pred_mask    = predictions == pcid\n",
    "                    intersection = gt_mask * pred_mask\n",
    "                    cf[gtcid, pcid] += int(intersection.sum())\n",
    "        overall_acc, acc, IoU = calculate_result(cf)\n",
    "\n",
    "    content = '| val_loss_avg:%.4f val_acc_avg:%.4f' \\\n",
    "            % (loss_avg/val_loader.n_iter, acc_avg/val_loader.n_iter)\n",
    "    print(content)\n",
    "    content = '| class accuracy avg:%.4f class IoU avg:%.4f\\n' \\\n",
    "                % (acc.mean(), IoU.mean())\n",
    "    print(content)\n",
    "    \n",
    "    # with open(log_file, 'a') as appender:\n",
    "    #     appender.write(content)\n",
    "\n",
    "\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "from ipdb import set_trace as st\n",
    "class MF_dataset(Dataset):\n",
    "\n",
    "    def __init__(self, data_dir, split, have_label, input_h=480, input_w=640 ,transform=[]):\n",
    "        super(MF_dataset, self).__init__()\n",
    "\n",
    "        # assert split in ['train', 'val', 'test'], 'split must be \"train\"|\"val\"|\"test\"'\n",
    "\n",
    "        with open(os.path.join(data_dir, split+'.txt'), 'r') as f:\n",
    "            self.names = [name.strip() for name in f.readlines()]\n",
    "\n",
    "        self.data_dir  = data_dir\n",
    "        self.split     = split\n",
    "        self.input_h   = input_h\n",
    "        self.input_w   = input_w\n",
    "        self.transform = transform\n",
    "        self.is_train  = have_label\n",
    "        self.n_data    = len(self.names)\n",
    "\n",
    "\n",
    "    def read_image(self, name, folder):\n",
    "        file_path = os.path.join(self.data_dir, '%s/%s.png' % (folder, name))\n",
    "        image     = np.asarray(Image.open(file_path)) # (w,h,c)\n",
    "        image = np.require(image, dtype='f4', requirements=['O', 'W'])\n",
    "        image.flags.writeable = True\n",
    "        return image\n",
    "\n",
    "    def get_train_item(self, index):\n",
    "        name  = self.names[index]\n",
    "        image = self.read_image(name, 'images')\n",
    "        label = self.read_image(name, 'labels')\n",
    "\n",
    "        for func in self.transform:\n",
    "            image, label = func(image, label)\n",
    "\n",
    "        image = np.asarray(Image.fromarray(np.uint8(image)).resize((self.input_w, self.input_h)), dtype=np.float32).transpose((2,0,1))/255\n",
    "        # label = np.asarray(Image.fromarray(label).resize((self.input_w, self.input_h)), dtype=np.int64)\n",
    "        label = np.asarray(Image.fromarray(label).resize((self.input_w, self.input_h), Image.NEAREST), dtype=np.int64)\n",
    "\n",
    "        return torch.tensor(image), torch.tensor(label), name\n",
    "\n",
    "    def get_test_item(self, index):\n",
    "        name  = self.names[index]\n",
    "        image = self.read_image(name, 'images')\n",
    "        image = np.asarray(Image.fromarray(image).resize((self.input_w, self.input_h)), dtype=np.float32).transpose((2,0,1))/255\n",
    "\n",
    "        return torch.tensor(image), name\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        if self.is_train is True:\n",
    "            return self.get_train_item(index)\n",
    "        else: \n",
    "            return self.get_test_item (index)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_Sem_noise(Q_ini,snr_max,snr_min):\n",
    "    import sys\n",
    "    sys.argv = ['run.py']\n",
    "    parser = argparse.ArgumentParser(description='Train MFNet with pytorch')\n",
    "    parser.add_argument('--model_name',  '-M',  type=str, default='MFNet_noise')\n",
    "    parser.add_argument('--batch_size',  '-B',  type=int, default=8)\n",
    "\n",
    "    parser.add_argument('--epoch_max' ,  '-E',  type=int, default=100)\n",
    "    # parser.add_argument('--epoch_max' ,  '-E',  type=int, default=2)\n",
    "\n",
    "    parser.add_argument('--epoch_from',  '-EF', type=int, default=1)\n",
    "    parser.add_argument('--gpu',         '-G',  type=int, default=0)\n",
    "    parser.add_argument('--num_workers', '-j',  type=int, default=0)\n",
    "    args = parser.parse_args()\n",
    "    model_dir = 'weights/'\n",
    "    model_dir = os.path.join(model_dir, args.model_name)\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    checkpoint_model_file = os.path.join(model_dir, 'tmp_pretrain1_Qini'+str(Q_ini)+'.pth')\n",
    "    checkpoint_optim_file = os.path.join(model_dir, 'tmp_pretrain1_Qini'+str(Q_ini)+'.optim')\n",
    "    final_model_file      = os.path.join(model_dir, 'final_pretrain1_Qini'+str(Q_ini)+'.pth')\n",
    "    log_file              = os.path.join(model_dir, 'log_pretrain1_Qini'+str(Q_ini)+'.txt')\n",
    "\n",
    "    print('| training %s on GPU #%d with pytorch' % (args.model_name, args.gpu))\n",
    "    print('| from epoch %d / %s' % (args.epoch_from, args.epoch_max))\n",
    "    print('| model will be saved in: %s' % model_dir)\n",
    "\n",
    "\n",
    "    model = eval(args.model_name)(n_class=n_class,Q_ini=Q_ini)\n",
    "    if args.gpu >= 0: model.cuda(args.gpu)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr_start, momentum=0.9, weight_decay=0.0005) \n",
    "    # optimizer = torch.optim.Adam(model.parameters(), lr=lr_start)\n",
    "\n",
    "    if args.epoch_from > 1:\n",
    "        print('| loading checkpoint file %s... ' % checkpoint_model_file, end='')\n",
    "        model.load_state_dict(torch.load(checkpoint_model_file, map_location='cuda:0'))\n",
    "        optimizer.load_state_dict(torch.load(checkpoint_optim_file))\n",
    "        print('done!')\n",
    "\n",
    "    train_dataset = MF_dataset(data_dir, 'train', have_label=True, transform=augmentation_methods)\n",
    "    val_dataset  = MF_dataset(data_dir, 'val', have_label=True)\n",
    "\n",
    "    train_loader  = DataLoader(\n",
    "        dataset     = train_dataset,\n",
    "        batch_size  = args.batch_size,\n",
    "        shuffle     = True,\n",
    "        num_workers = args.num_workers,\n",
    "        pin_memory  = True,\n",
    "        drop_last   = True\n",
    "    )\n",
    "    val_loader  = DataLoader(\n",
    "        dataset     = val_dataset,\n",
    "        batch_size  = args.batch_size,\n",
    "        shuffle     = False,\n",
    "        num_workers = args.num_workers,\n",
    "        pin_memory  = True,\n",
    "        drop_last   = False\n",
    "    )\n",
    "    train_loader.n_iter = len(train_loader)\n",
    "    val_loader.n_iter   = len(val_loader)\n",
    "\n",
    "    for epo in (range(args.epoch_from, args.epoch_max+1)):\n",
    "        print('\\n| epo #%s begin...' % epo)\n",
    "\n",
    "        train(args,epo, model, train_loader, optimizer, snr_min, snr_max)\n",
    "        validation(args,epo, model, val_loader, snr_min, snr_max)\n",
    "\n",
    "        # save check point model\n",
    "        # print('| saving check point model file... ', end='')\n",
    "        torch.save(model.state_dict(), checkpoint_model_file)\n",
    "        torch.save(optimizer.state_dict(), checkpoint_optim_file)\n",
    "        # print('done!')\n",
    "    if os.path.exists(final_model_file):\n",
    "        os.remove(final_model_file) # 删除已存在的文件\n",
    "    os.rename(checkpoint_model_file, final_model_file)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_ini = 12\n",
    "snr_max = 0\n",
    "snr_min = -20\n",
    "for Q_ini in [1,2,4,6,9,12]:  #由于插入了导频，实际上开销应当是Q_ini*4/3\n",
    "    train_Sem_noise(Q_ini,snr_max,snr_min)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_ini = 12\n",
    "snr_max = 0\n",
    "snr_min = -20\n",
    "for Q_ini in [3,5]:  #由于插入了导频，实际上开销应当是Q_ini*4/3\n",
    "    train_Sem_noise(Q_ini,snr_max,snr_min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 测试"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snr_max = 0\n",
    "snr_min = 0\n",
    "Q_ini = 12\n",
    "\n",
    "\n",
    "from util.util import visualize\n",
    "import sys\n",
    "\n",
    "sys.argv = ['run.py']\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Run MFNet demo with pytorch')\n",
    "parser.add_argument('--model_name', '-M',  type=str, default='MFNet_noise')\n",
    "parser.add_argument('--gpu',        '-G',  type=int, default=0)\n",
    "args = parser.parse_args()\n",
    "model_dir = 'weights/'\n",
    "model_dir = os.path.join(model_dir, args.model_name)\n",
    "\n",
    "checkpoint_model_file = os.path.join(model_dir, 'tmp_pretrain1_Qini'+str(Q_ini)+'.pth')\n",
    "final_model_file      = os.path.join(model_dir, 'final_pretrain1_Qini'+str(Q_ini)+'.pth')\n",
    "print('| running %s demo on GPU #%d with pytorch' % (args.model_name, args.gpu))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = eval(args.model_name)(n_class=n_class,Q_ini=Q_ini)\n",
    "if args.gpu >= 0: model.cuda(args.gpu)\n",
    "if os.path.exists(final_model_file):\n",
    "    model.load_state_dict(torch.load(final_model_file, map_location='cuda:0'))\n",
    "elif os.path.exists(checkpoint_model_file):\n",
    "    model.load_state_dict(torch.load(checkpoint_model_file, map_location='cuda:0'))\n",
    "else:\n",
    "    raise Exception('| model file do not exists in %s' % model_dir)\n",
    "print('| model loaded!')\n",
    "\n",
    "files = os.listdir('image')\n",
    "images = []\n",
    "fpath  = []\n",
    "for file in files:\n",
    "    if file[-3:] != 'png': continue\n",
    "    fpath.append('image/'+file)\n",
    "    images.append( np.asarray(Image.open('image/'+file)) )\n",
    "images = np.asarray(images, dtype=np.float32).transpose((0,3,1,2))/255.\n",
    "images = Variable(torch.tensor(images))\n",
    "if args.gpu >= 0: images = images.cuda(args.gpu)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    logits = model(images, snr_min, snr_max)\n",
    "    predictions = logits.argmax(1)\n",
    "    visualize(fpath, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 性能指标"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def test_noise_sem(Q_ini,snr_max,snr_min):\n",
    "\n",
    "    from util.util import calculate_accuracy, calculate_result\n",
    "    import sys\n",
    "\n",
    "    sys.argv = ['run.py']\n",
    "\n",
    "\n",
    "    cf = np.zeros((n_class, n_class))\n",
    "\n",
    "\n",
    "    parser = argparse.ArgumentParser(description='Test MFNet with pytorch')\n",
    "    parser.add_argument('--model_name', '-M',  type=str, default='MFNet_noise')\n",
    "    parser.add_argument('--batch_size',  '-B',  type=int, default=16)\n",
    "    parser.add_argument('--gpu',        '-G',  type=int, default=0)\n",
    "    parser.add_argument('--num_workers', '-j',  type=int, default=0)\n",
    "\n",
    "\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    model_dir = 'weights/'\n",
    "    model_dir = os.path.join(model_dir, args.model_name)\n",
    "\n",
    "    checkpoint_model_file = os.path.join(model_dir, 'tmp_pretrain1_Qini'+str(Q_ini)+'.pth')\n",
    "    final_model_file      = os.path.join(model_dir, 'final_pretrain1_Qini'+str(Q_ini)+'.pth')\n",
    "    # print('| testing %s on GPU #%d with pytorch' % (args.model_name, args.gpu))\n",
    "\n",
    "    model = eval(args.model_name)(n_class=n_class,Q_ini=Q_ini)\n",
    "    if args.gpu >= 0: model.cuda(args.gpu)\n",
    "    if os.path.exists(final_model_file):\n",
    "        model.load_state_dict(torch.load(final_model_file, map_location='cuda:0'))\n",
    "    elif os.path.exists(checkpoint_model_file):\n",
    "        model.load_state_dict(torch.load(checkpoint_model_file, map_location='cuda:0'))\n",
    "    else:\n",
    "        raise Exception('| model file do not exists in %s' % model_dir)\n",
    "    # print('| model loaded!')\n",
    "\n",
    "\n",
    "    test_dataset  = MF_dataset(data_dir, 'test', have_label=True)\n",
    "    test_loader  = DataLoader(\n",
    "        dataset     = test_dataset,\n",
    "        batch_size  = args.batch_size,\n",
    "        shuffle     = False,\n",
    "        num_workers = args.num_workers,\n",
    "        pin_memory  = True,\n",
    "        drop_last   = False\n",
    "    )\n",
    "    test_loader.n_iter = len(test_loader)\n",
    "\n",
    "    loss_avg = 0.\n",
    "    acc_avg  = 0.\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for it, (images, labels, names) in enumerate(test_loader):\n",
    "            images = Variable(images)\n",
    "            labels = Variable(labels)\n",
    "            if args.gpu >= 0:\n",
    "                images = images.cuda(args.gpu)\n",
    "                labels = labels.cuda(args.gpu)\n",
    "\n",
    "            logits = model(images, snr_min, snr_max)\n",
    "            loss = F.cross_entropy(logits, labels)\n",
    "            acc = calculate_accuracy(logits, labels)\n",
    "            loss_avg += float(loss)\n",
    "            acc_avg  += float(acc)\n",
    "\n",
    "            # print('|- test iter %s/%s. loss: %.4f, acc: %.4f' \\\n",
    "            #         % (it+1, test_loader.n_iter, float(loss), float(acc)))\n",
    "\n",
    "            predictions = logits.argmax(1)\n",
    "            for gtcid in range(n_class): \n",
    "                for pcid in range(n_class):\n",
    "                    gt_mask      = labels == gtcid \n",
    "                    pred_mask    = predictions == pcid\n",
    "                    intersection = gt_mask * pred_mask\n",
    "                    cf[gtcid, pcid] += int(intersection.sum())\n",
    "\n",
    "    overall_acc, acc, IoU = calculate_result(cf)\n",
    "\n",
    "    # print('| overall accuracy:', overall_acc)\n",
    "    # print('| accuracy of each class:', acc)\n",
    "    # print('| class accuracy avg:', acc.mean())\n",
    "    # print('| IoU:', IoU)\n",
    "    print('| class IoU avg:', IoU.mean())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snr_max = 0\n",
    "snr_min = 0\n",
    "Q_ini = 12\n",
    "for Q_ini in [1,2,3,4,5]: #由于插入了导频，实际上开销应当是Q_ini*4/3\n",
    "    test_noise_sem(Q_ini,snr_max,snr_min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 分离模块连起来"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_seprate(N,Nc,Nr,N_r_RF,Nt,N_t_RF,L,feedback_bits,SNR_dB,v_max_km,Q_ini,flag_DL='DL',flag_csi='imperfect'):\n",
    "    # N代表路径数\n",
    "    n_class   = 9\n",
    "    \n",
    "    N_t = Nt[0]*Nt[1]\n",
    "    N_r = Nr[0]*Nr[1]\n",
    "    device=0;\n",
    "    lr=1e-4;\n",
    "    log_interval=100; # 每100个输出保存一下许训练记录\n",
    "    save_interval=10*log_interval; # 每1000个测试一下保存记录\n",
    "    iter_begin=0;   #从第0个开始训练 如果不是0就读取之前训练过的check points\n",
    "    save_path=\"./weights/\";\n",
    "    best_loss=0;\n",
    "    rate1 = 4\n",
    "    rate2 = 2\n",
    "\n",
    "\n",
    "    model_name_CE = 'CE_WY'+'_L' + str(L)+'_v' + str(v_max_km)\n",
    "    model_name_CF = 'CF_WY'+'_bits' + str(feedback_bits)+'_L' + str(L)+'_v' + str(v_max_km)\n",
    "    model_name_Pre = 'Precoding_WY' + str(feedback_bits)+'_L' + str(L)+'_v' + str(v_max_km)\n",
    "    if flag_csi == 'perfect':\n",
    "        model_name_Pre = 'Precoding_WY_perfect' + '_v' + str(v_max_km)\n",
    "\n",
    "    dec_CE=CE_WY(Nc=Nc,N_r=N_r,N_r_RF=N_r_RF,N_t=N_t,N_t_RF=N_t_RF,L=L).cuda()\n",
    "    dec_CF=CF_WY(Nc=Nc,N_r=N_r,N_t=N_t,feedback_bits=feedback_bits).cuda()\n",
    "    dec_Pre=Precoding_WY(Nc=Nc,N_r=N_r,N_r_RF=N_r_RF,N_t=N_t,N_t_RF=N_t_RF).cuda()\n",
    "    Q=Q_ini\n",
    "    T = L+Q_ini\n",
    "    load_path_CE=save_path+\"CE_WY\"+\"/\";\n",
    "    load_path_CF=save_path+\"CF_WY\"+\"/\";\n",
    "    load_path_Pre=save_path+\"Precoding_WY\"+\"/\";\n",
    "\n",
    "    dec_dict = dec_CE.state_dict()\n",
    "    dec_load_path=load_path_CE+model_name_CE+\"_model.pth.tar\";\n",
    "    ckpt=torch.load(dec_load_path, map_location=\"cuda:\"+str(device));\n",
    "    pretrained_dict=ckpt['state_dict'];\n",
    "    pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in dec_dict}\n",
    "    dec_dict.update(pretrained_dict);\n",
    "    dec_CE.load_state_dict(dec_dict);\n",
    "    dec_CE.eval()\n",
    "\n",
    "\n",
    "\n",
    "    dec_dict = dec_CF.state_dict()\n",
    "    dec_load_path=load_path_CF+model_name_CF+\"_model.pth.tar\";\n",
    "    ckpt=torch.load(dec_load_path, map_location=\"cuda:\"+str(device));\n",
    "    pretrained_dict=ckpt['state_dict'];\n",
    "    pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in dec_dict}\n",
    "    dec_dict.update(pretrained_dict);\n",
    "    dec_CF.load_state_dict(dec_dict);\n",
    "    dec_CF.eval()\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    dec_dict = dec_Pre.state_dict()\n",
    "    dec_load_path=load_path_Pre+model_name_Pre+\"_model.pth.tar\";\n",
    "    ckpt=torch.load(dec_load_path, map_location=\"cuda:\"+str(device));\n",
    "    pretrained_dict=ckpt['state_dict'];\n",
    "    pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in dec_dict}\n",
    "    dec_dict.update(pretrained_dict);\n",
    "    dec_Pre.load_state_dict(dec_dict);\n",
    "    dec_Pre.eval()\n",
    "\n",
    "    \n",
    "    from util.util import calculate_accuracy, calculate_result\n",
    "    import sys\n",
    "    sys.argv = ['run.py']\n",
    "    cf = np.zeros((n_class, n_class))\n",
    "    parser = argparse.ArgumentParser(description='Test MFNet with pytorch')\n",
    "    parser.add_argument('--model_name', '-M',  type=str, default='MFNet_noise')\n",
    "    parser.add_argument('--batch_size',  '-B',  type=int, default=16)\n",
    "    parser.add_argument('--gpu',        '-G',  type=int, default=0)\n",
    "    parser.add_argument('--num_workers', '-j',  type=int, default=0)\n",
    "    args = parser.parse_args()\n",
    "    model_dir = 'weights/'\n",
    "    model_dir = os.path.join(model_dir, args.model_name)\n",
    "    checkpoint_model_file = os.path.join(model_dir, 'tmp_pretrain1_Qini'+str(Q_ini)+'.pth')\n",
    "    final_model_file      = os.path.join(model_dir, 'final_pretrain1_Qini'+str(Q_ini)+'.pth')\n",
    "    # print('| testing %s on GPU #%d with pytorch' % (args.model_name, args.gpu))\n",
    "    dec_sem = eval(args.model_name)(n_class=n_class,Q_ini=Q_ini)\n",
    "    if args.gpu >= 0: dec_sem.cuda(args.gpu)\n",
    "    if os.path.exists(final_model_file):\n",
    "        dec_sem.load_state_dict(torch.load(final_model_file, map_location='cuda:0'))\n",
    "    elif os.path.exists(checkpoint_model_file):\n",
    "        dec_sem.load_state_dict(torch.load(checkpoint_model_file, map_location='cuda:0'))\n",
    "    else:\n",
    "        raise Exception('| model file do not exists in %s' % model_dir)\n",
    "\n",
    "    \n",
    "            \n",
    "    test_dataset  = MF_dataset(data_dir, 'test', have_label=True)\n",
    "    test_loader  = DataLoader(\n",
    "        dataset     = test_dataset,\n",
    "        batch_size  = args.batch_size,\n",
    "        shuffle     = False,\n",
    "        num_workers = args.num_workers,\n",
    "        pin_memory  = True,\n",
    "        drop_last   = False\n",
    "    )\n",
    "    test_loader.n_iter = len(test_loader)\n",
    "\n",
    "    loss_avg = 0.\n",
    "    acc_avg  = 0.\n",
    "    dec_sem.eval()\n",
    "    with torch.no_grad():\n",
    "        for it, (images, labels, names) in enumerate(test_loader):\n",
    "            images = Variable(images)\n",
    "            labels = Variable(labels)\n",
    "            if args.gpu >= 0:\n",
    "                images = images.cuda(args.gpu)\n",
    "                labels = labels.cuda(args.gpu)\n",
    "\n",
    "            b = images.shape[0]\n",
    "            \n",
    "            alpha,A_r,A_t,fd,tau = SV_Channel_set(2*b,Nc,N,Nt,Nr,1,v_max_km)\n",
    "            H_batch = torch.zeros(2*b,T, Nc, N_r, N_t).cuda() + 0j\n",
    "\n",
    "            for i in range(T):\n",
    "                t = i*1/14000/8 #i就表示第i个OFDM符号，每个subframe时间是1ms，每个slot包含14个OFDM符号，当子载波间隔15kHz对应一个frame包含1个slot，30kHz对应2个，60kHz->4,120kHz->8,这里采用120kHz间隔所以除以8\n",
    "                H = SV_Channel_final(2*b,Nc,N,Nt,Nr,1,t,alpha,A_r,A_t,fd,tau)\n",
    "                H_batch[:,i] = H\n",
    "            H_batch_1 = H_batch[0:b]\n",
    "            H_batch_2 = H_batch[b:2*b]\n",
    "\n",
    "            H_CE=dec_CE(\n",
    "                H_batch = H_batch,  # b,T, Nc, N_r, N_t 用户1\n",
    "            );\n",
    "            H_CF=dec_CF(\n",
    "                    H = H_CE,  # b,T, Nc, N_r, N_t 用户1\n",
    "                );\n",
    "\n",
    "            H_CE_1 = H_CE[0:b]\n",
    "            H_CE_2 = H_CE[b:2*b]\n",
    "            H_CF_1 = H_CF[0:b]\n",
    "            H_CF_2 = H_CF[b:2*b]\n",
    "\n",
    "            if flag_csi == 'perfect':\n",
    "                H_CE_1 = H_batch[0:b,L]\n",
    "                H_CE_2 = H_batch[b:2*b,L]\n",
    "                H_CF_1 = H_batch[0:b,L]\n",
    "                H_CF_2 = H_batch[b:2*b,L]\n",
    "            elif flag_csi == 'imperfect':\n",
    "                pass\n",
    "\n",
    "            # loss_CE = SGCS_H(H_batch[:,L],H_CE)\n",
    "\n",
    "            # loss_CF = SGCS_H(H_batch[:,L],H_CF)\n",
    "            # print(loss_CE,loss_CF)\n",
    "    \n",
    "\n",
    "            if flag_DL == 'DL':\n",
    "                W,F_1,F_2=dec_Pre(\n",
    "                        H_CE_1 = H_CE_1,  # b, Nc, N_r, N_t 用户1\n",
    "                        H_CE_2 = H_CE_2,  # b, Nc, N_r, N_t 用户2\n",
    "                        H_CF_1 = H_CF_1,  # b, Nc, N_r, N_t 用户1\n",
    "                        H_CF_2 = H_CF_2,  # b, Nc, N_r, N_t 用户2\n",
    "                    );\n",
    "\n",
    "\n",
    "                H1 = H_batch_1[:,L:L+Q] \n",
    "                H2 = H_batch_2[:,L:L+Q] \n",
    "                H1_UE = H_CE_1.reshape(b,1,Nc,N_r,N_t)\n",
    "                H2_UE = H_CE_2.reshape(b,1,Nc,N_r,N_t)\n",
    "                H1_base = H_CF_1.reshape(b,1,Nc,N_r,N_t)\n",
    "                H2_base = H_CF_2.reshape(b,1,Nc,N_r,N_t)\n",
    "                W = W.reshape(b,1,1,N_r_RF,N_r)\n",
    "                F_1 = F_1.reshape(b,1,1,N_t,1)\n",
    "                F_2 = F_2.reshape(b,1,1,N_t,1)\n",
    "                W = Pre_WY_DMRS(H1, H2,  H1_UE, H2_UE, H1_base, H2_base, SNR_dB, rate1, rate2, W, F_1, F_2) #b,Q,Nc,2,N_r\n",
    "            elif flag_DL == 'PCA':\n",
    "                H1 = H_batch_1[:,L:L+Q] \n",
    "                H2 = H_batch_2[:,L:L+Q] \n",
    "                H1_UE = H_CE_1.reshape(b,1,Nc,N_r,N_t)\n",
    "                H2_UE = H_CE_2.reshape(b,1,Nc,N_r,N_t)\n",
    "                H1_base = H_CF_1.reshape(b,1,Nc,N_r,N_t)\n",
    "                H2_base = H_CF_2.reshape(b,1,Nc,N_r,N_t)\n",
    "                P_analog1,P_analog2,C_analog,C_digital,F_1, F_2, W = Pre_PCA_total_analog(H1, H2,  H1_UE, H2_UE, H1_base, H2_base, SNR_dB, rate1, rate2)\n",
    "\n",
    "\n",
    "            norm_factor_W = torch.sqrt(torch.sum(torch.abs(W)**2, dim=(-4,-3,-2, -1), keepdim=True))/torch.sqrt(torch.tensor(Q*Nc*N_r_RF, dtype=H.dtype, device=H.device))#1,1,1,1,1\n",
    "\n",
    "            \n",
    "            # norm_factor_W = 1\n",
    "\n",
    "            \n",
    "            # Calculate effective channel\n",
    "            H_eff_1 = W @ H1 @ F_1  #H [batch,Q, Nc,N_r_RF,1]\n",
    "            H_eff_2 = W @ H2 @ F_2  #H [batch,Q, Nc,N_r_RF,1]\n",
    "\n",
    "            # H_eff_1[:,:,:,0,:] = 1\n",
    "            # H_eff_1[:,:,:,1,:] = 0\n",
    "\n",
    "            # H_eff_2[:,:,:,0,:] = 0\n",
    "            # H_eff_2[:,:,:,1,:] = 1\n",
    "\n",
    "            ################################################################\n",
    "\n",
    "            x = images\n",
    "\n",
    "            x_rgb = dec_sem.enc_rgb(x)  #[batch,2*Q_ini,10,10]\n",
    "            x_inf = dec_sem.enc_inf(x)  #[batch,2*Q_ini,10,10]\n",
    "\n",
    "\n",
    "            x_rgb = x_rgb[:,0:Q_ini,:,:] + 1j*x_rgb[:,Q_ini:2*Q_ini,:,:] #[batch,Q_ini,10,10]\n",
    "            norm_factor = torch.sqrt(torch.sum(torch.abs(x_rgb)**2, dim=(-3,-2, -1), keepdim=True))\n",
    "            x_rgb = x_rgb / norm_factor * torch.sqrt(torch.tensor(Q*Nc*1, dtype=x.dtype, device=x.device))\n",
    "\n",
    "            x1 = x_rgb.reshape(b,Q,Nc,1,1) #b,Nc,Q,1,1\n",
    "            x1 = H_eff_1 @ x1           #b,Q,Nc,N_r_RF,1\n",
    "            # x_rgb = x_rgb[:,:,:,0:1,:].reshape(b,Q,10,10)\n",
    "\n",
    "            \n",
    "\n",
    "            x_inf = x_inf[:,0:Q_ini,:,:] + 1j*x_inf[:,Q_ini:2*Q_ini,:,:] #[batch,Q_ini,10,10]\n",
    "            norm_factor = torch.sqrt(torch.sum(torch.abs(x_inf)**2, dim=(-3,-2, -1), keepdim=True))\n",
    "            x_inf = x_inf / norm_factor * torch.sqrt(torch.tensor(Q*Nc*1, dtype=x.dtype, device=x.device))\n",
    "\n",
    "            x2 = x_inf.reshape(b,Q,Nc,1,1) #b,Nc,Q,1,1\n",
    "            x2 = H_eff_2 @ x2           #b,Q,Nc,N_r_RF,1\n",
    "            # x_inf = x_inf[:,:,:,1:2,:].reshape(b,Q,10,10)\n",
    "\n",
    "            sigma = 10**(-SNR_dB/10)\n",
    "            n = (torch.randn(b,Q,Nc,2,1).cuda() + 1j*torch.randn(b,Q,Nc,2,1).cuda())/sqrt(2)*sqrt(sigma)*norm_factor_W\n",
    "\n",
    "            x = x1 + x2 + n # b,Q,Nc,N_r_RF,1\n",
    "            x = x[:,:,:,0:1,:] + x[:,:,:,1:2,:]\n",
    "            x = x.reshape(b,Q,10,10)\n",
    "\n",
    "            norm_factor = torch.sqrt(torch.sum(torch.abs(x)**2, dim=(-3,-2, -1), keepdim=True))\n",
    "            x = x / norm_factor * torch.sqrt(torch.tensor(Q*Nc*1, dtype=x.dtype, device=x.device))\n",
    "            x=torch.cat([x.real, x.imag], dim=1);  # batch,2*Q_ini,10,10\n",
    "            logits = dec_sem.dec(x)\n",
    "\n",
    "            \n",
    "            loss = F.cross_entropy(logits, labels)\n",
    "            acc = calculate_accuracy(logits, labels)\n",
    "            loss_avg += float(loss)\n",
    "            acc_avg  += float(acc)\n",
    "\n",
    "            # print('|- test iter %s/%s. loss: %.4f, acc: %.4f' \\\n",
    "            #         % (it+1, test_loader.n_iter, float(loss), float(acc)))\n",
    "\n",
    "            predictions = logits.argmax(1)\n",
    "            for gtcid in range(n_class): \n",
    "                for pcid in range(n_class):\n",
    "                    gt_mask      = labels == gtcid \n",
    "                    pred_mask    = predictions == pcid\n",
    "                    intersection = gt_mask * pred_mask\n",
    "                    cf[gtcid, pcid] += int(intersection.sum())\n",
    "\n",
    "    overall_acc, acc, IoU = calculate_result(cf)\n",
    "\n",
    "    # print('| overall accuracy:', overall_acc)\n",
    "    # print('| accuracy of each class:', acc)\n",
    "    # print('| class accuracy avg:', acc.mean())\n",
    "    # print('| IoU:', IoU)\n",
    "    print('| class IoU avg:', IoU.mean())\n",
    "\n",
    "                \n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def demo_seprate(N,Nc,Nr,N_r_RF,Nt,N_t_RF,L,feedback_bits,SNR_dB,v_max_km,Q_ini,flag_DL='DL',flag_csi='imperfect'):\n",
    "    # N代表路径数\n",
    "    \n",
    "    \n",
    "    N_t = Nt[0]*Nt[1]\n",
    "    N_r = Nr[0]*Nr[1]\n",
    "    device=0;\n",
    "    lr=1e-4;\n",
    "    log_interval=100; # 每100个输出保存一下许训练记录\n",
    "    save_interval=10*log_interval; # 每1000个测试一下保存记录\n",
    "    iter_begin=0;   #从第0个开始训练 如果不是0就读取之前训练过的check points\n",
    "    save_path=\"./weights/\";\n",
    "    best_loss=0;\n",
    "    rate1 = 4\n",
    "    rate2 = 2\n",
    "\n",
    "\n",
    "    model_name_CE = 'CE_WY'+'_L' + str(L)+'_v' + str(v_max_km)\n",
    "    model_name_CF = 'CF_WY'+'_bits' + str(feedback_bits)+'_L' + str(L)+'_v' + str(v_max_km)\n",
    "    model_name_Pre = 'Precoding_WY' + str(feedback_bits)+'_L' + str(L)+'_v' + str(v_max_km)\n",
    "    if flag_csi == 'perfect':\n",
    "        model_name_Pre = 'Precoding_WY_perfect' + '_v' + str(v_max_km)\n",
    "\n",
    "    dec_CE=CE_WY(Nc=Nc,N_r=N_r,N_r_RF=N_r_RF,N_t=N_t,N_t_RF=N_t_RF,L=L).cuda()\n",
    "    dec_CF=CF_WY(Nc=Nc,N_r=N_r,N_t=N_t,feedback_bits=feedback_bits).cuda()\n",
    "    dec_Pre=Precoding_WY(Nc=Nc,N_r=N_r,N_r_RF=N_r_RF,N_t=N_t,N_t_RF=N_t_RF).cuda()\n",
    "    Q=Q_ini\n",
    "    T = L+Q_ini\n",
    "    load_path_CE=save_path+\"CE_WY\"+\"/\";\n",
    "    load_path_CF=save_path+\"CF_WY\"+\"/\";\n",
    "    load_path_Pre=save_path+\"Precoding_WY\"+\"/\";\n",
    "\n",
    "    dec_dict = dec_CE.state_dict()\n",
    "    dec_load_path=load_path_CE+model_name_CE+\"_model.pth.tar\";\n",
    "    ckpt=torch.load(dec_load_path, map_location=\"cuda:\"+str(device));\n",
    "    pretrained_dict=ckpt['state_dict'];\n",
    "    pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in dec_dict}\n",
    "    dec_dict.update(pretrained_dict);\n",
    "    dec_CE.load_state_dict(dec_dict);\n",
    "    dec_CE.eval()\n",
    "\n",
    "\n",
    "\n",
    "    dec_dict = dec_CF.state_dict()\n",
    "    dec_load_path=load_path_CF+model_name_CF+\"_model.pth.tar\";\n",
    "    ckpt=torch.load(dec_load_path, map_location=\"cuda:\"+str(device));\n",
    "    pretrained_dict=ckpt['state_dict'];\n",
    "    pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in dec_dict}\n",
    "    dec_dict.update(pretrained_dict);\n",
    "    dec_CF.load_state_dict(dec_dict);\n",
    "    dec_CF.eval()\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    dec_dict = dec_Pre.state_dict()\n",
    "    dec_load_path=load_path_Pre+model_name_Pre+\"_model.pth.tar\";\n",
    "    ckpt=torch.load(dec_load_path, map_location=\"cuda:\"+str(device));\n",
    "    pretrained_dict=ckpt['state_dict'];\n",
    "    pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in dec_dict}\n",
    "    dec_dict.update(pretrained_dict);\n",
    "    dec_Pre.load_state_dict(dec_dict);\n",
    "    dec_Pre.eval()\n",
    "\n",
    "    \n",
    "    from util.util import calculate_accuracy, calculate_result\n",
    "    import sys\n",
    "    sys.argv = ['run.py']\n",
    "    cf = np.zeros((n_class, n_class))\n",
    "    parser = argparse.ArgumentParser(description='Test MFNet with pytorch')\n",
    "    parser.add_argument('--model_name', '-M',  type=str, default='MFNet_noise')\n",
    "    parser.add_argument('--batch_size',  '-B',  type=int, default=16)\n",
    "    parser.add_argument('--gpu',        '-G',  type=int, default=0)\n",
    "    parser.add_argument('--num_workers', '-j',  type=int, default=0)\n",
    "    args = parser.parse_args()\n",
    "    model_dir = 'weights/'\n",
    "    model_dir = os.path.join(model_dir, args.model_name)\n",
    "    checkpoint_model_file = os.path.join(model_dir, 'tmp_pretrain1_Qini'+str(Q_ini)+'.pth')\n",
    "    final_model_file      = os.path.join(model_dir, 'final_pretrain1_Qini'+str(Q_ini)+'.pth')\n",
    "    # print('| testing %s on GPU #%d with pytorch' % (args.model_name, args.gpu))\n",
    "    dec_sem = eval(args.model_name)(n_class=n_class,Q_ini=Q_ini)\n",
    "    if args.gpu >= 0: dec_sem.cuda(args.gpu)\n",
    "    if os.path.exists(final_model_file):\n",
    "        dec_sem.load_state_dict(torch.load(final_model_file, map_location='cuda:0'))\n",
    "    elif os.path.exists(checkpoint_model_file):\n",
    "        dec_sem.load_state_dict(torch.load(checkpoint_model_file, map_location='cuda:0'))\n",
    "    else:\n",
    "        raise Exception('| model file do not exists in %s' % model_dir)\n",
    "\n",
    "    \n",
    "            \n",
    "    files = os.listdir('image')\n",
    "    images = []\n",
    "    fpath  = []\n",
    "    fpath_out = []\n",
    "    fpath_original = []\n",
    "    for file in files:\n",
    "        if file[-3:] != 'png': continue\n",
    "        fpath.append('image/'+file)\n",
    "        fpath_out.append('seg_seprate_'+str(flag_csi)+'_'+str(flag_DL)+'/'+file)\n",
    "        fpath_original.append('image_original/'+file)\n",
    "        images.append( np.asarray(Image.open('image/'+file)) )\n",
    "    images = np.asarray(images, dtype=np.float32).transpose((0,3,1,2))/255.\n",
    "    images = Variable(torch.tensor(images))\n",
    "    if args.gpu >= 0: images = images.cuda(args.gpu)\n",
    "\n",
    "    loss_avg = 0.\n",
    "    acc_avg  = 0.\n",
    "    dec_sem.eval()\n",
    "    with torch.no_grad():\n",
    "\n",
    "        b = images.shape[0]\n",
    "        \n",
    "        alpha,A_r,A_t,fd,tau = SV_Channel_set(2*b,Nc,N,Nt,Nr,1,v_max_km)\n",
    "        H_batch = torch.zeros(2*b,T, Nc, N_r, N_t).cuda() + 0j\n",
    "\n",
    "        for i in range(T):\n",
    "            t = i*1/14000/8 #i就表示第i个OFDM符号，每个subframe时间是1ms，每个slot包含14个OFDM符号，当子载波间隔15kHz对应一个frame包含1个slot，30kHz对应2个，60kHz->4,120kHz->8,这里采用120kHz间隔所以除以8\n",
    "            H = SV_Channel_final(2*b,Nc,N,Nt,Nr,1,t,alpha,A_r,A_t,fd,tau)\n",
    "            H_batch[:,i] = H\n",
    "        H_batch_1 = H_batch[0:b]\n",
    "        H_batch_2 = H_batch[b:2*b]\n",
    "\n",
    "        H_CE=dec_CE(\n",
    "            H_batch = H_batch,  # b,T, Nc, N_r, N_t 用户1\n",
    "        );\n",
    "        H_CF=dec_CF(\n",
    "                H = H_CE,  # b,T, Nc, N_r, N_t 用户1\n",
    "            );\n",
    "\n",
    "        H_CE_1 = H_CE[0:b]\n",
    "        H_CE_2 = H_CE[b:2*b]\n",
    "        H_CF_1 = H_CF[0:b]\n",
    "        H_CF_2 = H_CF[b:2*b]\n",
    "\n",
    "        if flag_csi == 'perfect':\n",
    "            H_CE_1 = H_batch[0:b,L]\n",
    "            H_CE_2 = H_batch[b:2*b,L]\n",
    "            H_CF_1 = H_batch[0:b,L]\n",
    "            H_CF_2 = H_batch[b:2*b,L]\n",
    "        elif flag_csi == 'imperfect':\n",
    "            pass\n",
    "\n",
    "        # loss_CE = SGCS_H(H_batch[:,L],H_CE)\n",
    "\n",
    "        # loss_CF = SGCS_H(H_batch[:,L],H_CF)\n",
    "        # print(loss_CE,loss_CF)\n",
    "\n",
    "\n",
    "        if flag_DL == 'DL':\n",
    "            W,F_1,F_2=dec_Pre(\n",
    "                    H_CE_1 = H_CE_1,  # b, Nc, N_r, N_t 用户1\n",
    "                    H_CE_2 = H_CE_2,  # b, Nc, N_r, N_t 用户2\n",
    "                    H_CF_1 = H_CF_1,  # b, Nc, N_r, N_t 用户1\n",
    "                    H_CF_2 = H_CF_2,  # b, Nc, N_r, N_t 用户2\n",
    "                );\n",
    "\n",
    "\n",
    "            H1 = H_batch_1[:,L:L+Q] \n",
    "            H2 = H_batch_2[:,L:L+Q] \n",
    "            H1_UE = H_CE_1.reshape(b,1,Nc,N_r,N_t)\n",
    "            H2_UE = H_CE_2.reshape(b,1,Nc,N_r,N_t)\n",
    "            H1_base = H_CF_1.reshape(b,1,Nc,N_r,N_t)\n",
    "            H2_base = H_CF_2.reshape(b,1,Nc,N_r,N_t)\n",
    "            W = W.reshape(b,1,1,N_r_RF,N_r)\n",
    "            F_1 = F_1.reshape(b,1,1,N_t,1)\n",
    "            F_2 = F_2.reshape(b,1,1,N_t,1)\n",
    "            W = Pre_WY_DMRS(H1, H2,  H1_UE, H2_UE, H1_base, H2_base, SNR_dB, rate1, rate2, W, F_1, F_2) #b,Q,Nc,2,N_r\n",
    "        elif flag_DL == 'PCA':\n",
    "            H1 = H_batch_1[:,L:L+Q] \n",
    "            H2 = H_batch_2[:,L:L+Q] \n",
    "            H1_UE = H_CE_1.reshape(b,1,Nc,N_r,N_t)\n",
    "            H2_UE = H_CE_2.reshape(b,1,Nc,N_r,N_t)\n",
    "            H1_base = H_CF_1.reshape(b,1,Nc,N_r,N_t)\n",
    "            H2_base = H_CF_2.reshape(b,1,Nc,N_r,N_t)\n",
    "            P_analog1,P_analog2,C_analog,C_digital,F_1, F_2, W = Pre_PCA_total_analog(H1, H2,  H1_UE, H2_UE, H1_base, H2_base, SNR_dB, rate1, rate2)\n",
    "\n",
    "\n",
    "        norm_factor_W = torch.sqrt(torch.sum(torch.abs(W)**2, dim=(-4,-3,-2, -1), keepdim=True))/torch.sqrt(torch.tensor(Q*Nc*N_r_RF, dtype=H.dtype, device=H.device))#1,1,1,1,1\n",
    "\n",
    "        \n",
    "        # norm_factor_W = 1\n",
    "\n",
    "        \n",
    "        # Calculate effective channel\n",
    "        H_eff_1 = W @ H1 @ F_1  #H [batch,Q, Nc,N_r_RF,1]\n",
    "        H_eff_2 = W @ H2 @ F_2  #H [batch,Q, Nc,N_r_RF,1]\n",
    "\n",
    "        # H_eff_1[:,:,:,0,:] = 1\n",
    "        # H_eff_1[:,:,:,1,:] = 0\n",
    "\n",
    "        # H_eff_2[:,:,:,0,:] = 0\n",
    "        # H_eff_2[:,:,:,1,:] = 1\n",
    "\n",
    "        ################################################################\n",
    "\n",
    "        x = images\n",
    "\n",
    "        x_rgb = dec_sem.enc_rgb(x)  #[batch,2*Q_ini,10,10]\n",
    "        x_inf = dec_sem.enc_inf(x)  #[batch,2*Q_ini,10,10]\n",
    "\n",
    "\n",
    "        x_rgb = x_rgb[:,0:Q_ini,:,:] + 1j*x_rgb[:,Q_ini:2*Q_ini,:,:] #[batch,Q_ini,10,10]\n",
    "        norm_factor = torch.sqrt(torch.sum(torch.abs(x_rgb)**2, dim=(-3,-2, -1), keepdim=True))\n",
    "        x_rgb = x_rgb / norm_factor * torch.sqrt(torch.tensor(Q*Nc*1, dtype=x.dtype, device=x.device))\n",
    "\n",
    "        x1 = x_rgb.reshape(b,Q,Nc,1,1) #b,Nc,Q,1,1\n",
    "        x1 = H_eff_1 @ x1           #b,Q,Nc,N_r_RF,1\n",
    "        # x_rgb = x_rgb[:,:,:,0:1,:].reshape(b,Q,10,10)\n",
    "\n",
    "        \n",
    "\n",
    "        x_inf = x_inf[:,0:Q_ini,:,:] + 1j*x_inf[:,Q_ini:2*Q_ini,:,:] #[batch,Q_ini,10,10]\n",
    "        norm_factor = torch.sqrt(torch.sum(torch.abs(x_inf)**2, dim=(-3,-2, -1), keepdim=True))\n",
    "        x_inf = x_inf / norm_factor * torch.sqrt(torch.tensor(Q*Nc*1, dtype=x.dtype, device=x.device))\n",
    "\n",
    "        x2 = x_inf.reshape(b,Q,Nc,1,1) #b,Nc,Q,1,1\n",
    "        x2 = H_eff_2 @ x2           #b,Q,Nc,N_r_RF,1\n",
    "        # x_inf = x_inf[:,:,:,1:2,:].reshape(b,Q,10,10)\n",
    "\n",
    "        sigma = 10**(-SNR_dB/10)\n",
    "        n = (torch.randn(b,Q,Nc,2,1).cuda() + 1j*torch.randn(b,Q,Nc,2,1).cuda())/sqrt(2)*sqrt(sigma)*norm_factor_W\n",
    "\n",
    "        x = x1 + x2 + n # b,Q,Nc,N_r_RF,1\n",
    "        x = x[:,:,:,0:1,:] + x[:,:,:,1:2,:]\n",
    "        x = x.reshape(b,Q,10,10)\n",
    "\n",
    "        norm_factor = torch.sqrt(torch.sum(torch.abs(x)**2, dim=(-3,-2, -1), keepdim=True))\n",
    "        x = x / norm_factor * torch.sqrt(torch.tensor(Q*Nc*1, dtype=x.dtype, device=x.device))\n",
    "        x=torch.cat([x.real, x.imag], dim=1);  # batch,2*Q_ini,10,10\n",
    "        logits = dec_sem.dec(x)\n",
    "\n",
    "        files = os.listdir('image')\n",
    "        images = []\n",
    "        fpath  = []\n",
    "        fpath_out = []\n",
    "        fpath_original = []\n",
    "        for file in files:\n",
    "            if file[-3:] != 'png': continue\n",
    "            fpath.append('image/'+file)\n",
    "            fpath_out.append('seprate_'+flag_DL+'_'+flag_csi+'/'+file)\n",
    "            fpath_original.append('image_original/'+file)\n",
    "            images.append( np.asarray(Image.open('image/'+file)) )\n",
    "        images = np.asarray(images, dtype=np.float32).transpose((0,3,1,2))/255.\n",
    "        images = Variable(torch.tensor(images))\n",
    "        if args.gpu >= 0: images = images.cuda(args.gpu)\n",
    "        \n",
    "        predictions = logits.argmax(1)\n",
    "        # save_images(images, fpath_original)  #保存原始图像\n",
    "        visualize(fpath_out, predictions)\n",
    "                \n",
    "                \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 开始测试"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### demo画图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 0\n",
    "Nc = 100\n",
    "N = 2\n",
    "Nt = [1,8]\n",
    "Nr = [1,64]\n",
    "N_r_RF = 2\n",
    "N_t_RF = 2\n",
    "\n",
    "L = 8\n",
    "\n",
    "feedback_bits_pre = None\n",
    "v_max_km_pre = None\n",
    "\n",
    "# flag_csi = 'perfect'\n",
    "# flag_DL = 'DL'\n",
    "\n",
    "feedback_bits = 1024\n",
    "SNR_dB = -25\n",
    "v_max_km = 120\n",
    "Q_ini = 3\n",
    "\n",
    "demo_seprate(N,Nc,Nr,N_r_RF,Nt,N_t_RF,L,feedback_bits,SNR_dB,v_max_km,Q_ini,flag_DL='DL',flag_csi='perfect')\n",
    "demo_seprate(N,Nc,Nr,N_r_RF,Nt,N_t_RF,L,feedback_bits,SNR_dB,v_max_km,Q_ini,flag_DL='DL',flag_csi='imperfect')\n",
    "demo_seprate(N,Nc,Nr,N_r_RF,Nt,N_t_RF,L,feedback_bits,SNR_dB,v_max_km,Q_ini,flag_DL='PCA',flag_csi='perfect')\n",
    "demo_seprate(N,Nc,Nr,N_r_RF,Nt,N_t_RF,L,feedback_bits,SNR_dB,v_max_km,Q_ini,flag_DL='PCA',flag_csi='imperfect')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 不完美CSI+DL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 0\n",
    "Nc = 100\n",
    "N = 2\n",
    "Nt = [1,8]\n",
    "Nr = [1,64]\n",
    "N_r_RF = 2\n",
    "N_t_RF = 2\n",
    "\n",
    "L = 8\n",
    "\n",
    "feedback_bits_pre = None\n",
    "v_max_km_pre = None\n",
    "\n",
    "feedback_bits = 1024\n",
    "SNR_dB = -25\n",
    "v_max_km = 120\n",
    "Q_ini = 3\n",
    "for Q_ini in [1,2,3,4,5]:\n",
    "    test_seprate(N,Nc,Nr,N_r_RF,Nt,N_t_RF,L,feedback_bits,SNR_dB,v_max_km,Q_ini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 0\n",
    "Nc = 100\n",
    "N = 2\n",
    "Nt = [1,8]\n",
    "Nr = [1,64]\n",
    "N_r_RF = 2\n",
    "N_t_RF = 2\n",
    "\n",
    "L = 8\n",
    "\n",
    "feedback_bits_pre = None\n",
    "v_max_km_pre = None\n",
    "\n",
    "feedback_bits = 1024\n",
    "SNR_dB = -25\n",
    "v_max_km = 120\n",
    "Q_ini = 3\n",
    "for L in [1,2,4,8]:\n",
    "    test_seprate(N,Nc,Nr,N_r_RF,Nt,N_t_RF,L,feedback_bits,SNR_dB,v_max_km,Q_ini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 0\n",
    "Nc = 100\n",
    "N = 2\n",
    "Nt = [1,8]\n",
    "Nr = [1,64]\n",
    "N_r_RF = 2\n",
    "N_t_RF = 2\n",
    "\n",
    "L = 8\n",
    "\n",
    "feedback_bits_pre = None\n",
    "v_max_km_pre = None\n",
    "\n",
    "feedback_bits = 1024\n",
    "SNR_dB = -25\n",
    "v_max_km = 120\n",
    "Q_ini = 1\n",
    "for L in [1,2,4,8]:\n",
    "    test_seprate(N,Nc,Nr,N_r_RF,Nt,N_t_RF,L,feedback_bits,SNR_dB,v_max_km,Q_ini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 0\n",
    "Nc = 100\n",
    "N = 2\n",
    "Nt = [1,8]\n",
    "Nr = [1,64]\n",
    "N_r_RF = 2\n",
    "N_t_RF = 2\n",
    "\n",
    "L = 8\n",
    "\n",
    "feedback_bits_pre = None\n",
    "v_max_km_pre = None\n",
    "\n",
    "feedback_bits = 1024\n",
    "SNR_dB = -25\n",
    "v_max_km = 120\n",
    "Q_ini = 3\n",
    "for feedback_bits in [4,16,64,256,1024]:\n",
    "    test_seprate(N,Nc,Nr,N_r_RF,Nt,N_t_RF,L,feedback_bits,SNR_dB,v_max_km,Q_ini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 0\n",
    "Nc = 100\n",
    "N = 2\n",
    "Nt = [1,8]\n",
    "Nr = [1,64]\n",
    "N_r_RF = 2\n",
    "N_t_RF = 2\n",
    "\n",
    "L = 8\n",
    "\n",
    "feedback_bits_pre = None\n",
    "v_max_km_pre = None\n",
    "\n",
    "feedback_bits = 1024\n",
    "SNR_dB = -25\n",
    "v_max_km = 120\n",
    "Q_ini = 1\n",
    "for feedback_bits in [4,16,64,256,1024]:\n",
    "    test_seprate(N,Nc,Nr,N_r_RF,Nt,N_t_RF,L,feedback_bits,SNR_dB,v_max_km,Q_ini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 0\n",
    "Nc = 100\n",
    "N = 2\n",
    "Nt = [1,8]\n",
    "Nr = [1,64]\n",
    "N_r_RF = 2\n",
    "N_t_RF = 2\n",
    "\n",
    "L = 8\n",
    "\n",
    "feedback_bits_pre = None\n",
    "v_max_km_pre = None\n",
    "\n",
    "feedback_bits = 1024\n",
    "SNR_dB = -25\n",
    "v_max_km = 120\n",
    "Q_ini = 3\n",
    "for SNR_dB in [-40,-35,-30,-25,-20,-15,-10,-5,0]:\n",
    "    test_seprate(N,Nc,Nr,N_r_RF,Nt,N_t_RF,L,feedback_bits,SNR_dB,v_max_km,Q_ini)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 不完美CSI+PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 0\n",
    "Nc = 100\n",
    "N = 2\n",
    "Nt = [1,8]\n",
    "Nr = [1,64]\n",
    "N_r_RF = 2\n",
    "N_t_RF = 2\n",
    "\n",
    "L = 8\n",
    "\n",
    "feedback_bits_pre = None\n",
    "v_max_km_pre = None\n",
    "\n",
    "flag_csi = 'imperfect'\n",
    "flag_DL = 'PCA'\n",
    "\n",
    "feedback_bits = 1024\n",
    "SNR_dB = -25\n",
    "v_max_km = 120\n",
    "Q_ini = 3\n",
    "for Q_ini in [1,2,3,4,5]:\n",
    "    test_seprate(N,Nc,Nr,N_r_RF,Nt,N_t_RF,L,feedback_bits,SNR_dB,v_max_km,Q_ini,flag_csi=flag_csi,flag_DL=flag_DL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 0\n",
    "Nc = 100\n",
    "N = 2\n",
    "Nt = [1,8]\n",
    "Nr = [1,64]\n",
    "N_r_RF = 2\n",
    "N_t_RF = 2\n",
    "\n",
    "L = 8\n",
    "\n",
    "feedback_bits_pre = None\n",
    "v_max_km_pre = None\n",
    "\n",
    "flag_csi = 'imperfect'\n",
    "flag_DL = 'PCA'\n",
    "\n",
    "feedback_bits = 1024\n",
    "SNR_dB = -25\n",
    "v_max_km = 120\n",
    "Q_ini = 3\n",
    "for L in [1,2,4,8]:\n",
    "    test_seprate(N,Nc,Nr,N_r_RF,Nt,N_t_RF,L,feedback_bits,SNR_dB,v_max_km,Q_ini,flag_csi=flag_csi,flag_DL=flag_DL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 0\n",
    "Nc = 100\n",
    "N = 2\n",
    "Nt = [1,8]\n",
    "Nr = [1,64]\n",
    "N_r_RF = 2\n",
    "N_t_RF = 2\n",
    "\n",
    "L = 8\n",
    "\n",
    "feedback_bits_pre = None\n",
    "v_max_km_pre = None\n",
    "\n",
    "flag_csi = 'imperfect'\n",
    "flag_DL = 'PCA'\n",
    "\n",
    "feedback_bits = 1024\n",
    "SNR_dB = -25\n",
    "v_max_km = 120\n",
    "Q_ini = 1\n",
    "for L in [1,2,4,8]:\n",
    "    test_seprate(N,Nc,Nr,N_r_RF,Nt,N_t_RF,L,feedback_bits,SNR_dB,v_max_km,Q_ini,flag_csi=flag_csi,flag_DL=flag_DL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 0\n",
    "Nc = 100\n",
    "N = 2\n",
    "Nt = [1,8]\n",
    "Nr = [1,64]\n",
    "N_r_RF = 2\n",
    "N_t_RF = 2\n",
    "\n",
    "L = 8\n",
    "\n",
    "feedback_bits_pre = None\n",
    "v_max_km_pre = None\n",
    "\n",
    "flag_csi = 'imperfect'\n",
    "flag_DL = 'PCA'\n",
    "\n",
    "feedback_bits = 1024\n",
    "SNR_dB = -25\n",
    "v_max_km = 120\n",
    "Q_ini = 3\n",
    "for feedback_bits in [4,16,64,256,1024]:\n",
    "    test_seprate(N,Nc,Nr,N_r_RF,Nt,N_t_RF,L,feedback_bits,SNR_dB,v_max_km,Q_ini,flag_csi=flag_csi,flag_DL=flag_DL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 0\n",
    "Nc = 100\n",
    "N = 2\n",
    "Nt = [1,8]\n",
    "Nr = [1,64]\n",
    "N_r_RF = 2\n",
    "N_t_RF = 2\n",
    "\n",
    "L = 8\n",
    "\n",
    "feedback_bits_pre = None\n",
    "v_max_km_pre = None\n",
    "\n",
    "flag_csi = 'imperfect'\n",
    "flag_DL = 'PCA'\n",
    "\n",
    "feedback_bits = 1024\n",
    "SNR_dB = -25\n",
    "v_max_km = 120\n",
    "Q_ini = 1\n",
    "for feedback_bits in [4,16,64,256,1024]:\n",
    "    test_seprate(N,Nc,Nr,N_r_RF,Nt,N_t_RF,L,feedback_bits,SNR_dB,v_max_km,Q_ini,flag_csi=flag_csi,flag_DL=flag_DL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 0\n",
    "Nc = 100\n",
    "N = 2\n",
    "Nt = [1,8]\n",
    "Nr = [1,64]\n",
    "N_r_RF = 2\n",
    "N_t_RF = 2\n",
    "\n",
    "L = 8\n",
    "\n",
    "feedback_bits_pre = None\n",
    "v_max_km_pre = None\n",
    "\n",
    "flag_csi = 'imperfect'\n",
    "flag_DL = 'PCA'\n",
    "\n",
    "feedback_bits = 1024\n",
    "SNR_dB = -25\n",
    "v_max_km = 120\n",
    "Q_ini = 3\n",
    "for SNR_dB in [-40,-35,-30,-25,-20,-15,-10,-5,0]:\n",
    "    test_seprate(N,Nc,Nr,N_r_RF,Nt,N_t_RF,L,feedback_bits,SNR_dB,v_max_km,Q_ini,flag_csi=flag_csi,flag_DL=flag_DL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 完美CSI+DL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 0\n",
    "Nc = 100\n",
    "N = 2\n",
    "Nt = [1,8]\n",
    "Nr = [1,64]\n",
    "N_r_RF = 2\n",
    "N_t_RF = 2\n",
    "\n",
    "L = 8\n",
    "\n",
    "feedback_bits_pre = None\n",
    "v_max_km_pre = None\n",
    "\n",
    "flag_csi = 'perfect'\n",
    "flag_DL = 'DL'\n",
    "\n",
    "feedback_bits = 1024\n",
    "SNR_dB = -25\n",
    "v_max_km = 120\n",
    "Q_ini = 3\n",
    "for Q_ini in [1,2,3,4,5]:\n",
    "    test_seprate(N,Nc,Nr,N_r_RF,Nt,N_t_RF,L,feedback_bits,SNR_dB,v_max_km,Q_ini,flag_csi=flag_csi,flag_DL=flag_DL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 0\n",
    "Nc = 100\n",
    "N = 2\n",
    "Nt = [1,8]\n",
    "Nr = [1,64]\n",
    "N_r_RF = 2\n",
    "N_t_RF = 2\n",
    "\n",
    "L = 8\n",
    "\n",
    "feedback_bits_pre = None\n",
    "v_max_km_pre = None\n",
    "\n",
    "flag_csi = 'perfect'\n",
    "flag_DL = 'DL'\n",
    "\n",
    "feedback_bits = 1024\n",
    "SNR_dB = -25\n",
    "v_max_km = 120\n",
    "Q_ini = 3\n",
    "for SNR_dB in [-40,-35,-30,-25,-20,-15,-10,-5,0]:\n",
    "    test_seprate(N,Nc,Nr,N_r_RF,Nt,N_t_RF,L,feedback_bits,SNR_dB,v_max_km,Q_ini,flag_csi=flag_csi,flag_DL=flag_DL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 完美CSI+PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 0\n",
    "Nc = 100\n",
    "N = 2\n",
    "Nt = [1,8]\n",
    "Nr = [1,64]\n",
    "N_r_RF = 2\n",
    "N_t_RF = 2\n",
    "\n",
    "L = 8\n",
    "\n",
    "feedback_bits_pre = None\n",
    "v_max_km_pre = None\n",
    "\n",
    "flag_csi = 'perfect'\n",
    "flag_DL = 'PCA'\n",
    "\n",
    "feedback_bits = 1024\n",
    "SNR_dB = -25\n",
    "v_max_km = 120\n",
    "Q_ini = 3\n",
    "for Q_ini in [1,2,3,4,5]:\n",
    "    test_seprate(N,Nc,Nr,N_r_RF,Nt,N_t_RF,L,feedback_bits,SNR_dB,v_max_km,Q_ini,flag_csi=flag_csi,flag_DL=flag_DL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 0\n",
    "Nc = 100\n",
    "N = 2\n",
    "Nt = [1,8]\n",
    "Nr = [1,64]\n",
    "N_r_RF = 2\n",
    "N_t_RF = 2\n",
    "\n",
    "L = 8\n",
    "\n",
    "feedback_bits_pre = None\n",
    "v_max_km_pre = None\n",
    "\n",
    "flag_csi = 'perfect'\n",
    "flag_DL = 'PCA'\n",
    "\n",
    "feedback_bits = 1024\n",
    "SNR_dB = -25\n",
    "v_max_km = 120\n",
    "Q_ini = 3\n",
    "for SNR_dB in [-40,-35,-30,-25,-20,-15,-10,-5,0]:\n",
    "    test_seprate(N,Nc,Nr,N_r_RF,Nt,N_t_RF,L,feedback_bits,SNR_dB,v_max_km,Q_ini,flag_csi=flag_csi,flag_DL=flag_DL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
